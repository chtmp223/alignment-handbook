loading libiconv version 1.16
loading xz version 5.2.5
loading zlib version 1.2.11
loading libxml2 version 2.9.12
loading cuda version 11.8.0
loading bzip2 version 1.0.8
loading libmd version 1.0.3
loading libbsd version 0.11.3
loading expat version 2.4.1
loading ncurses version 6.2
loading readline version 8.1
loading gdbm version 1.19
loading tar version 1.34
loading gettext version 0.21
loading libffi version 3.3
loading openssl version 1.1.1l
loading sqlite version 3.36.0
loading util-linux-uuid version 2.36.2
loading python version 3.11.0
Python 3.11.0
Name: torch
Version: 2.1.2
Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration
Home-page: https://pytorch.org/
Author: PyTorch Team
Author-email: packages@pytorch.org
License: BSD-3
Location: /home/ctpham_umass_edu/.local/lib/python3.11/site-packages
Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions
Required-by: accelerate, bitsandbytes, deepspeed, flash-attn, peft, trl
[2024-06-02 18:42:59,113] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
INFO:root:Using nproc_per_node=8.
[2024-06-02 18:43:01,589] torch.distributed.run: [WARNING] 
[2024-06-02 18:43:01,589] torch.distributed.run: [WARNING] *****************************************
[2024-06-02 18:43:01,589] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-06-02 18:43:01,589] torch.distributed.run: [WARNING] *****************************************
[2024-06-02 18:43:09,735] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-02 18:43:09,756] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-02 18:43:10,017] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-02 18:43:10,038] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-02 18:43:10,049] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-02 18:43:10,049] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-02 18:43:10,064] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-02 18:43:10,099] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-06-02 18:43:10,761] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-02 18:43:10,763] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-02 18:43:11,148] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-02 18:43:11,163] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-02 18:43:11,163] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-06-02 18:43:11,167] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-02 18:43:11,167] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-02 18:43:11,168] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-06-02 18:43:11,172] [INFO] [comm.py:637:init_distributed] cdb=None
2024-06-02 18:43:11 - INFO - __main__ - Model parameters ModelArguments(base_model_revision=None, model_name_or_path='mistralai/Mistral-7B-Instruct-v0.2', model_revision='main', model_code_revision=None, torch_dtype='bfloat16', tokenizer_name_or_path=None, trust_remote_code=False, use_flash_attention_2=True, use_peft=True, lora_r=16, lora_alpha=16, lora_dropout=0.05, lora_target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'], lora_modules_to_save=None, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False, bnb_4bit_quant_storage='uint8')
2024-06-02 18:43:11 - INFO - __main__ - Data parameters DataArguments(chat_template="{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'system' %}\n{{ '<|system|>\n' + message['content'] + eos_token }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last and add_generation_prompt %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}", dataset_mixer={'chtmp223/suri': 1.0}, text_column='text', dataset_splits=['train'], dataset_configs=None, preprocessing_num_workers=48, truncation_side=None, auto_insert_empty_system_msg=True)
2024-06-02 18:43:11 - INFO - __main__ - Training/evaluation parameters ORPOConfig(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
batch_eval_metrics=False,
beta=0.4,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
dataset_num_proc=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_dropout=True,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_steps=None,
eval_strategy=IntervalStrategy.NO,
evaluation_strategy=None,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generate_during_eval=False,
gradient_accumulation_steps=1,
gradient_checkpointing=True,
gradient_checkpointing_kwargs={'use_reentrant': True},
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=True,
hub_model_id=suri-orpo-curr,
hub_private_repo=True,
hub_strategy=HubStrategy.ALL_CHECKPOINTS,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
is_encoder_decoder=None,
jit_mode_eval=False,
label_names=None,
label_pad_token_id=-100,
label_smoothing_factor=0.0,
learning_rate=5e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=info,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/runs/Jun02_18-43-10_gpu020,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.COSINE,
max_completion_length=15000,
max_grad_norm=1.0,
max_length=15024,
max_prompt_length=5000,
max_steps=-1,
metric_for_best_model=None,
model_init_kwargs=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=2,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
output_dir=/scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr,
overwrite_output_dir=False,
padding_value=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
prediction_loss_only=False,
push_to_hub=True,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=orpo-lora-curr,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=2,
save_strategy=IntervalStrategy.EPOCH,
save_total_limit=2,
seed=42,
skip_memory_metrics=True,
split_batches=None,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
truncation_mode=keep_end,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
2024-06-02 18:43:11 - INFO - __main__ - Checkpoint detected, resuming training at last_checkpoint='/scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-1250'.
2024-06-02 18:43:13 - INFO - __main__ - Training on the following splits: ['train : 10000']
[INFO|tokenization_utils_base.py:2108] 2024-06-02 18:43:13,570 >> loading file tokenizer.model from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/tokenizer.model
[INFO|tokenization_utils_base.py:2108] 2024-06-02 18:43:13,570 >> loading file tokenizer.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/tokenizer.json
[INFO|tokenization_utils_base.py:2108] 2024-06-02 18:43:13,570 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2108] 2024-06-02 18:43:13,570 >> loading file special_tokens_map.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/special_tokens_map.json
[INFO|tokenization_utils_base.py:2108] 2024-06-02 18:43:13,570 >> loading file tokenizer_config.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/tokenizer_config.json
[INFO|configuration_utils.py:733] 2024-06-02 18:43:13,658 >> loading configuration file config.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/config.json
[INFO|configuration_utils.py:796] 2024-06-02 18:43:13,659 >> Model config MistralConfig {
  "_name_or_path": "mistralai/Mistral-7B-Instruct-v0.2",
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.1",
  "use_cache": false,
  "vocab_size": 32000
}

[INFO|modeling_utils.py:3474] 2024-06-02 18:43:13,663 >> loading weights file model.safetensors from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/model.safetensors.index.json
[INFO|modeling_utils.py:1519] 2024-06-02 18:43:13,664 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.
[INFO|modeling_utils.py:3614] 2024-06-02 18:43:13,664 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model
[WARNING|logging.py:329] 2024-06-02 18:43:13,665 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-06-02 18:43:13,666 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-06-02 18:43:13,666 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-06-02 18:43:13,667 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-06-02 18:43:13,667 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-06-02 18:43:13,667 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-06-02 18:43:13,667 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-06-02 18:43:13,668 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-06-02 18:43:13,668 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-06-02 18:43:13,670 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-06-02 18:43:13,670 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-06-02 18:43:13,670 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-06-02 18:43:13,671 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[WARNING|logging.py:329] 2024-06-02 18:43:13,672 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[INFO|configuration_utils.py:962] 2024-06-02 18:43:13,672 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2,
  "use_cache": false
}

[WARNING|logging.py:329] 2024-06-02 18:43:13,673 >> The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation="flash_attention_2"` instead.
[WARNING|logging.py:329] 2024-06-02 18:43:13,675 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2024-06-02 18:43:17,648] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 291, num_elems = 7.24B
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.95it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.62it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.43it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.42it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.31it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.35it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:00,  3.25it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.12s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.41it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.40it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.40it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.40it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.40it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.33it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.33it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.31it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.29it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.38it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]
Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.30it/s]
Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]
[INFO|modeling_utils.py:4280] 2024-06-02 18:43:21,079 >> All model checkpoint weights were used when initializing MistralForCausalLM.

[INFO|modeling_utils.py:4288] 2024-06-02 18:43:21,079 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at mistralai/Mistral-7B-Instruct-v0.2.
If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.
[INFO|configuration_utils.py:917] 2024-06-02 18:43:21,118 >> loading configuration file generation_config.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/generation_config.json
[INFO|configuration_utils.py:962] 2024-06-02 18:43:21,118 >> Generate config GenerationConfig {
  "bos_token_id": 1,
  "eos_token_id": 2
}

2024-06-02 18:43:21 - INFO - __main__ - Accepted prompt 0 of the raw training set:

<|system|>
Here is a constraint you must follow to complete the task. Please read it carefully and incorporate it into your work, ensuring the final text is natural, coherent, and engaging.</s>
<|user|>
- Use dialogue to explore the characters' vulnerabilities and mutual respect, culminating in a physical demonstration of trust and learning.</s>

2024-06-02 18:43:21 - INFO - __main__ - Rejected prompt 0 of the raw training set:

<|system|>
Here is a constraint you must follow to complete the task. Please read it carefully and incorporate it into your work, ensuring the final text is natural, coherent, and engaging.</s>
<|user|>
- Use dialogue to explore the characters' competitiveness and mutual disdain, culminating in a physical confrontation that emphasizes distrust and rivalry.</s>

2024-06-02 18:43:21 - INFO - __main__ - First response of the raw training set:

<|assistant|>
chapter_1

	1. A Root by Any Other Name



You’re curious about the name, aren’t you? Of course you are. If I had a galleon for every time someone asked me about my name I could buy my way into the noble caste in Orzammar and retire in style.  

Here’s the story. My mother got herself knocked up. No big deal, happens every day to casteless dwarves. Most women get rid of the baby or hope it’s the right sex so they can move up in rank.

My mum? She decides having a kid is the best thing to ever happen to her. So much so that she decides she’s not willing to risk having a baby in Orzammar and takes every copper she’s ever earned and smuggles herself out. The gold wasn’t enough, so she agreed to work for the Carta until her debts were paid off.

She’s always had a knack for healing, so they sent her to work with an old apostate who patched up any of the poor fighters who somehow managed to make it back to base alive. But let me come back to that.

So she’s in the Marches, and decides she wants to make things easy on her kid by giving her a human name. Maybe Mum thought it would make people like me more or I’d do better in trade, I don’t know. And she’s not around anymore for me to ask.

There was a trend when I was born, I guess, where women named their daughters after flowers and plants. So everywhere my mum looked there was a ‘Rose’ or a ‘Lily’ or a ‘Poppy.’ And my mum decides there and then that she wants to do the same with her brat.

Then one day, a kid comes into the warehouse. Little dwarven boy who the Carta used to run messages once in a while. No parents that anyone knows about. He’s miserable and my mum realizes he’s pretty damn sick.

The mage is nowhere to be found, so she does whatever she can think of to keep this kid alive until he’s back. And one of the main things she does is mix the herb Bethroot with milk and makes him drink the whole damn thing.

A couple of hours later, the mage came back to the warehouse and did his magic, and the boy was right as rain. But the mage told my mum that she saved his life, that if she hadn’t worked as hard as she did, he would have died.

Right chuffed my mum was, and two days later, she went into labor and had a daughter. A daughter who would have been branded casteless just like her mother if they hadn’t left Orzammar.

She told me once that the moment they put me in her arms, she knew I couldn’t have any other name. My namesake saved a life once. My mum hoped my name would inspire me to do the same.

For a while I was determined to prove her wrong, and I broke her heart, running with the Carta, not caring who got hurt as long as I got my gold. Took losing all I had worked for to realize I actually didn’t have anything to lose but instead everything to gain.

And now the Inquisition is giving me a chance to finally make my mum proud.

 

 




chapter_2

	2. The is the Hour of Lead



“You want me to what?” Blackwall asks, sure that he heard the Herald incorrectly.

He watches the Herald’s face as she stares down at the ground, her hands curled into fists. They stand in the training yard, far from the rest of the soldiers Cullen is running through drills. The Haven air is cool and crisp, but having worked on his endurance for the last hour, Blackwall is sweating. So he runs the back of his hand across his brow to wipe away the worst of it, trying to process what the Herald just asked.

She looks up, raising her chin as if to ward off any chance of rejection. “I want you to hit me,” she repeats. “Spar with me and I’ll lose on purpose.”

Blackwall looks away, and lets out a breath. That’s what he feared he heard the first time. “I can’t… I mean, I don’t want…” Crossing his arms over his chest, he asks, his voice gruff, “Maker why?”

Her mouth opens and closes with no sound. Blackwall cocks his head, trying to figure out exactly what might be wrong. Speechless is not something he would ever describe the Herald, but that's exactly her state.

Just when he thinks she's changed her mind, Cadash takes a breath and he sees the determination on her face. "Because humans scare me."

The words take the breath out of him and causes his gut to tangle up. Silly as the idea is, he thought they’d become friends a bit. Since he joined the Inquisition, he’s fought by her side more often than not, and back here at Haven, several times she joined him at the tavern on her own accord, where they talked over tactics and the future. Never their pasts.

To realize all this time she was afraid of him hurts more than he cares to admit. But if she feels true fear, his pain doesn’t matter. So he does his best to keep his voice level as he asks, “I frighten you?”

The Herald’s eyes widened. “No. No.” She reaches out and places her hand on his forearm, which is bare, thanks to the plain tunic he wore for his workout. She wears fingerless gloves and the brief contact startles him. He’s not used to being touched, not anymore, unless it’s a slap on the back or an armored hand helping someone up off the ground. To feel skin against skin…

“Blackwall, I trust you,” she says, truth ringing in every word. The words warm him almost as much as the way her fingers slide against his forearm as she removes her hand does. He looks down and she meets his gaze. “I’m not afraid of you.”

The tangle in his stomach is gone, replaced by an entirely different sort of ache, an impossible one. He forces himself to set it aside, to deal with it later and concentrate on the Herald. “Then what are you afraid of?” he asks, hating the tenderness he hears slip into his voice. She deserves so much more than a few soft words from the likes of him.

“Remember when you had to rest your knee at camp for a night in the Hinterlands and Cassandra took your place?”

Blackwall nods, thinking of that last night in the Hinterlands before they came back to Haven. His left knee acts up every so often thanks to a fight from his mercenary days, after Callier but before he met the Warden-Constable. He hated he needed to take a break, but after all these years, he understands and respects his body’s limits. If he hadn’t stopped for the night, he would have done serious damage and been no help to anyone.

“An outlaw slipped by Cassandra. The maul he had…” Cadash sighs, putting her hands behind her back as if bracing herself. “It was as big as me, Blackwall, and I froze. I couldn’t make myself move, because all I could think of was how much it was going to hurt.”

“What happened?” he asks, his voice quiet. 

“Solas managed to kill him before he got too close, but it doesn’t matter. I still froze,” the Herald says, shaking her head. He hears the frustration in her voice. “And I don’t think it was the first time. I never fought humans before I joined the Inquisition.”

“Never?” Blackwall asks.

She shakes her head. "Never. I've fought plenty of other dwarves, but never humans. Dwarven weapons… Well, there’s a pretty big difference getting stabbed with a dwarven dagger and hit with a human great sword.”

He grunts in agreement, having dealt with both those wounds before.

“And I’m not looking to get stabbed, just... I guess I hoped if we sparred and you hit me, I'll feel the pain and know I can survive it. Then maybe I won't freeze next time."

It's a sound strategy and one he understands. Orleasian soldiers go through much the same thing with magic. After he enlisted, he and other soldiers were hit with magic: fire, ice and lightning, so they could process each sensation and understand how they will react in battle. Fire causes him to panic slightly. Ice makes him nauseous and lightning just pisses him off. 

He picks up a nearby practice shield and slips his arm through the enarmes. He’s watched the Herald spar a few times and honestly, he’s not been impressed. Cadash might be good with a bow and quick enough to escape trouble, but if it came down to her life in a fight without weapons? She didn’t stand a chance. He’d just have to make sure she never found herself in that position.

Her face lights up once she realizes he’s acquiesced and Blackwall gives himself just a moment to reflect on how lovely her smile is. But then he steps back and evaluates her like he would any sparring partner. Her leathers are well worn. They’d protect her from magic and arrows a bit, but a shield?

The noise in the training yard has softened. The soldiers and recruits are behind him, but Blackwall doesn’t have to turn around to know most of their attention is on the Herald. She comes to the yard every day to practice with her bow, and spars so little it’s almost seen as an event when she does. He hopes the lads won’t be too disappointed when he takes her down.

He readies himself, shield in front - holding not hiding - and rests his weight on the balls of his feet. He’ll make this quick. One Shield Bash will be enough to knock her flat on her arse, hopefully providing the Herald with the tools she needs.

The Herald’s eyes look past him and he furrows his brow, asking an unspoken question. “We have an audience,” she says in a low voice.

He lets out a chuckle. “Want to give them a good show?”

She raises her arms high above her head and he tries to ignore the curve of her hips. “Pride is on the line now, Blackwall,” she says with a grin. “You understand.”

“Of course, Herald,” he says with a dip of his head.

She settles into a fighting stance and just by how she holds herself he knows that the moment he lunges, she’ll do that fancy back flip of hers. But while he’s not as quick as he used to be, he could still catch her off guard on the way down.

So he decides not to lunge and slaps the front of his shield with an open palm. The move causes his hand to sting, but is enough to startle the Herald and instead of a back flip, she dodges to the right.

She’s up on her feet almost at once and they start circling. As he waits for his chance, Cadash rolls her left shoulder. “You really need to get that shoulder looked at, my lady,” he says.

The words are enough to surprise her. “How did you-”

Blackwall takes the chance to lunge. The Herald reacts, doing her flip and landing easily. The soldiers behind them let out a cheer. “You have some admirers,” Blackwall says. He’s always enjoyed the give and take of a good spar and this is no exception.

Her breathing is slightly labored now as she sprints behind him. “Probably more of a curiosity to them," she says. "The dwarf who closes rifts. I could be part of a traveling circus."

There's something in her voice that rings true to him and Blackwall wonders if that's how she sees herself. The thought saddens him. He knows she doesn't believe she's the Herald, but he's starting to and she deserves more than self-doubt.

He feints to the right, taking advantage of her shoulder and she scurries out of the way. "I think that could be true for most of us," he says, thinking of her inner circle, a more eclectic group he'd ever met.

She says nothing in response and Blackwall notices how her eyes keep darting to his shield. There’s a real fear now in her eyes, a wild type of fear, one he’s far too familiar with. No point dragging this out any further; he’s in her head. And there he will stay until he ends this.

One simple step back and she provides him with his opportunity. Launching from his legs, he lowers his shield and aims for her stomach. With a quick thrust of his arm, he hits the Herald right in the midsection. It’s not as hard of a hit as he’d use with Cassandra, but more forceful than he’d use with a new recruit.

She lets out a gasp of surprise as she topples over. Letting go of the shield at once, Blackwall drops to his knees, next to the Herald, who isn’t moving. “My lady,” he says quietly, ignoring the cheers of the soldiers behind him. “My lady, are you alright?”

The Herald rolls onto her back, clutching her stomach. “That fucking hurt,” she says, a hint of a pout on her lips as she stares up at the sky.

Resting a forearm on his bended knee, he looks her over, making sure she’s no worse for wear. “But survivable?” he asks, holding out his hand.

A grimace crosses her face as she puts her hand in his. Her fingers are warm against his palm. Maker, her hands are small. Yet he’s seen how capable they are, whether closing rifts or fletching arrows.

“Survivable,” she says decisively with a nod of the head as he helps her up.

Their hands linger together for just a moment too long before she places both hands on her stomach. He can still feel the warmth from her fingertips ghosting over his skin as he looks up at her from his knees.

“Let’s just not make it a habit,” she says, laughing as she rubs her belly. “I see you get hit like that all the time. How do you handle it?”

He hoists himself up and lets out a laugh. “Heavy plate helps a great deal, Herald.”

“Point.”

There’s a whistle from the soldiers and Cadash turns and waves to them all. A cheer rings out and she bows from the waist before looking back at him. “Told you you had admirers,” Blackwall says, crossing his arms over his chest.

Her cheeks redden slightly before she waves the praise away. “Well, who wouldn’t want to see the so-called Herald get her ass kicked?”

“You did ask for it, if I recall,” Blackwall says, arching a brow.

“You just had to remind me,” she says, shaking her head. She starts to walk over to her bow, but stops and turns. “Thank you. I mean it.”

He dips his head, accepting her thanks. Every passing day affirms his decision to forgo his life as a recruiter and join the Inquisition. He couldn’t imagine not being a part of this, making things right, helping good people, with her.

“When we’re in a real fight, I’ll do whatever I can to keep you safe,” he says suddenly.

Bending down, she picks up her quiver and hoists it on her back. She tilts her head and a sad smile crosses her lips as she looks up at him. “Even you can’t be everywhere at once, Blackwall,” she says.

“I can damn well try,” he says, the words soft, an oath. To himself or to her he cannot say. “I can damn well try.”

Cadash looks like she’s about to speak when a messenger runs up to them. “Herald, forgive me. Lady Montilyet requests your presence. Something about signatures.”

The Herald’s shoulders slump. “I forgot about those,” she says, sounding sheepish. “I best get back to the Chantry.” He watches as she picks up her bow and straps it to her back. She hesitates for just a moment before meeting his gaze again. “Will you be at the tavern tonight?”

He hadn’t planned on it. Earlier that day, Sister Leliana gave him a batch of reports to look through. He asked for them on the pretense of finding the Grey Wardens when in truth he wants to make sure there is nothing that might give him away. But those can wait for another night.

Instead of answering, he simply nods and his chest constricts when she grins in response. He watches as she jogs off with the messenger and wonders how much trouble he’s going to be in if he keeps walking this path.

But as she turns back towards him and gives one last wave, he realizes it doesn’t matter. His path, his resolve, is set.

She leads and he will follow. 




chapter_3

	3. Follow the Leader



She looks exactly like he remembers.

Her face, the Herald’s face, has haunted his dreams since the day he watched her die, three hundred and eighty-one days ago. The Herald is dead, of this is he sure, yet she stands in front of  _him_ , her blue eyes piercing his soul, and says it isn’t so.

He wants to believe. He wants it so badly he bites his tongue to keep himself from reaching out and feeling her hand under his. She is not for the likes of  _him_ , he remembers this now, the taste of copper on his lips.

But then it’s her hand that reaches out, fingers curled just so as she places her hand on his forearm. He twitches at her touch and jerks his arm away as she apologizes for not being there. Yet he would not have her here in this world, this world of red lyrium and lies, where nothing is real, not even time.

He is a champion, a protector, and Maker help him, he would protect her from this.

She keeps speaking and her voice is a balm, easing its way into his bones. His eyes close as he listens to what she is offering. The last year could be erased. Everything he has been forced to do in The Elder One’s name as he hoped for escape, some way to make things right… And now she tells him he can go back, and this past year will never have existed. It doesn’t seem possible, yet he hears the truth in her voice.

He chooses to believe. He trusts the Herald. Trusts  _her_.

She will help him chisel away the worst parts of himself until only his true self remains.

_You are who you choose to follow._

He is  _Blackwall_. Not Rainier.

And he is hers. She leads and he follows, off to battle the very essence of time itself.

#

He looks nothing like she remembers.

The man in front of her is broken. Certainly not the same one she called oddly charming only a few days ago. Red lyrium radiates from his skin and clouds his blue-grey eyes and for the first time since she fell out of the Fade she feels rage. Oh she had moments of anger before, but nothing like the coil of smoke slithering through her belly, demanding she make The Elder One pay.

Then find a safe place for her friend to rest.

But there is no time for rest as they find him armor to wear and a sword to wield. She is the one who discovers a shield and holds it up for him as if in offering. As he puts his forearm through the enarmes, she doesn’t imagine how his shoulders straighten, like he’s been given purpose again at last.

They fight through Redcliffe. Alexius is killed. The Elder one arrives.

Time. There’s never enough in the end. Her heart constricts, realizing what they must do, what  _he_  must do. She meets his steady gaze and with one look, they promise each other the world. One breath and they’ve placed their lives in each other’s hands.

And then he dies.

She wants to cry out as the demons pour through, bringing proof of his death. But as the magic cackles around her and she hears the familiar song of arrows being loosed, she finds her resolve and doesn’t stray.

_There_ _’s a reason people have been following our Herald._

Less than a week has passed since he spoke those words to the Avvar. She had simply closed a passing rift, nothing special, she thought. But now another rift opens and she feels the power tingling in the palm of her hand, running down to the tips of her fingers.

Blackwall thinks she’s someone worthy to follow.

And now she will show the world why.




chapter_4

	4. Offer Me



She sits in the ambassador’s office, trying to concentrate on the paperwork in front of her. Instead her mind keeps wandering, remembering the evening prior, her certainty Blackwall would arrive in her quarters and her utter sense of relief when he finally did.

How could Josephine and Leliana expect her signature almost four dozen times over when all she wants to dwell on, is even with their difference in size, how perfectly her hips cradled his?

They didn’t speak much this morning. Blackwall left early, concerned about her reputation if too many people saw him leaving her quarters. She wanted to tell him it didn’t matter, she cares for him and will happily share that with the world, but worries he wants to be a secret instead.

A messenger enters as Bethroot stares at the parchment as she signs her name once again.

“Josephine, do you have a secret admirer?” Leliana says, her voice full of curiosity.

Bethroot looks up at that, and sees the messenger is carrying a small bouquet of flowers. But instead of Josephine, the messenger walks over to her and bows low. He hands her the flowers and says, “From the Warden, your Worship.”

The flowers smell of spring and possibilities and as she buries her nose in them, she hears Josephine’s delighted clap of her hands but misses the shadow that falls on Leliana’s face.

#

She hasn’t let an arrow loose in three days.

Bethroot skips down the stairs of the keep, feeling like a bird experiencing flight for the first time. She has two full hours of freedom before she needs to meet Cullen to discuss the troops, and she knows exactly what to do with them.

The training yard is packed today, full of both new recruits and veterans alike. The Grey Wardens staying at Skyhold are holding a clinic of sorts. Somewhere among them is Blackwall. She’s been surprised he hasn’t been more friendly towards the Grey Wardens, but supposes there’s a reason he calls himself a loner. 

Stopping outside the small room where she and her companions keep their gear at Skyhold, Bethroot stretches her arms high over her head, trying to dislodge the feeling of disuse. But then she steps inside and looks towards her things.

Her eyes narrow, seeing some sort of mark around the top of her favorite quiver. It’s a simple quiver, leather over a wooden frame, with a wooden lip to keep the shape. She picks it up and realizes that it’s not a mark at all, but words carved around the edge.

_Atrast nal tunsha_

“May you always find your way in the dark,” Bethroot whispers, thinking how she taught Blackwall the dwarven phase a week ago, explaining how her mother would say that to her each time Bethroot left on Carta business.

She hugs the quiver to her close. “I have, Mam. I finally have.”

#

Blackwall turns away, still in chains, and Bethroot tries to get her heart to stop stammering.

Too many people are staring, watching the spectacle she’s created. If she could have only stayed in her damn chair, they could have had their first reconciliation in private.

But her eyes are on his back as a guard steps forward, ready to remove the cuffs. Within moments, it’s done and Blackwall rubs his wrists, saying something to the guard she can’t hear over the crowd.

She steps off the platform, not wanting to be elevated above anyone any longer. He walks up to her then, his face still open and raw. “I meant it,” he says, leaning forward and kissing her brow. “Forever in your hands.”

And he slips her the key that gave him his freedom.




chapter_5

	5. Scars

She should be sleeping.

Beside her, Blackwall is on his back, breathing slowly and evenly, as only those deep in slumber can. Bethroot is propped up on her side, her fingers lightly running over his chest.

It's only their second night together and her first chance to study him closely. Last night, between exhaustion from traveling back from the Storm Coast and nerves, hoping and wondering if Blackwall would say anything, she fell asleep almost immediately after their passions were spent.

He promised answers from their journey, but the trip only left her with more questions. The badge was key; she saw him take it out and stare at it more than once on the wagon ride back to Skyhold. But she could ponder the mystery later. Right now, she just wanted to look.

Even after sharing plenty of campsites and watching him spar and train over the past six months, Bethroot had never seen him without a shirt until last night. Her hand drifts lower, sliding over his belly, and curling her fingers through his soft chest hair. He’s not as lean as some of the other humans she's seen shirtless; a few of her soldiers looked for any excuse not to wear a shirt. But he's plenty strong underneath it all, and that's all that matters.

A patchwork of scars decorate the right side of his torso, shoulder and arm included. She wonders the story behind them. She wonders how soon she’ll have the right to ask and find out.

Blackwall jerks his head suddenly and makes a small noise which comes from the back of his throat. He shakes his head, eyes closed tight, and Bethroot holds her breath as she continues to lightly stroke his stomach.

He stills not long after and Bethroot lets out her breath, sure he’s awake. She says nothing, in case she’s wrong. He deserves his rest.

"That feels nice," Blackwall mutters, his eyes still closed.

Bethroot jerks her hand away, but he catches it and puts it back on his stomach. "I thought you were sleeping," she says, keeping her voice soft, not wanting to break the magic of her quarters, with the crackling fire and the autumn wind breezing through the open balcony doors, as she starts up the caress again.

“Were you watching me sleep?” he asks, brow furrowing slightly as he opens his eyes. There’s a raspiness in his voice that makes her curl up to him closer. She nods and he raises a hand, dragging a knuckle across her cheek. “You need your rest, my lady. Don’t waste your time staring at me.”

“You were moving,” Bethroot says, hearing the shyness in her voice. Why is this so hard to ask about? “Were… were you dreaming?”

A look she doesn’t recognize crosses his face. After six months of friendship, she thought she had a handle on most of his moods. Not all of them, though. He’s such a private man and offers so little about himself, not even his given name.

“I was.”

She rests her chin on his chest and the words come out before she can stop herself. “What’s it like?” she asks, more eagerly than she'd hope. “Dreaming?”

"Thought you dreamt once," Blackwall says, running his hand through her hair, "with Solas."

"True," she concedes, remembering the strangeness of being in Haven yet not being there. Even after all of Dagna’s questions about the experience, she couldn’t quite describe it. Perhaps dwarves just truly weren’t meant to dream. "But I didn't realize it was a dream until I woke up."

A silence settles over them and Bethroot resigns herself to yet another question unanswered. There is so much she wants to learn about him, yet so much he won’t say. She worries she'll start to fill in the empty spaces with ideas of her own. If she does, will he still be the man she cares for now or just a construct in her head?

He told her once, "it's what you do and how you do it that’s important." But what happens if that's not enough? Everyone has a foundation of which their lives are built. The past shapes them all, like chisel against stone, even if one refuses to look back.

She knows from their previous conversations, she figures he's either a soldier turned criminal or criminal turned soldier. Deciding which tale she prefers isn’t easy, so she’ll wait until he lets something slip, handing her a clue which she weaves into the tapestry of everything she’s learned.

Bethroot is an archer. Patience is key; she doesn’t need to know everything at once as long as her target is getting closer to her mark. Someday she’ll have her answers and for now, that’s enough.

“Not all dreams are good, you know,” he says, darkness clouding his voice.

“You had a nightmare?” she asks.

He nods and brings her hand up to his lips, kissing the inside of her wrist. It’s so tempting to ask for more details, more something, more anything, just _more_. But she doesn’t want to appear greedy.

“I’d meet you there in the Fade if I could,” she says, an invitation if he’d like to talk more, as she leans forward and rests her hand on his shoulder, tracing the scars. Her lips brush his; she meant it to be more of a peck, for comfort, but Blackwall has different ideas.

He kisses her hard and deep, waking up every nerve in her body.</s>

/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:246: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:246: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:246: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:246: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:246: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:246: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:246: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/trl/trainer/orpo_trainer.py:246: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.
  warnings.warn(
2024-06-02 18:43:22 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:641] 2024-06-02 18:43:22,883 >> Using auto half precision backend
[2024-06-02 18:43:23,187] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.2, git-hash=unknown, git-branch=unknown
[2024-06-02 18:43:23,219] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-06-02 18:43:23,222] [INFO] [logging.py:96:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2024-06-02 18:43:23,222] [INFO] [logging.py:96:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2024-06-02 18:43:23,249] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2024-06-02 18:43:23,249] [INFO] [utils.py:56:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2024-06-02 18:43:23,249] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False
[2024-06-02 18:43:23,249] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer
[2024-06-02 18:43:23,407] [INFO] [utils.py:802:see_memory_usage] Stage 3 initialize beginning
[2024-06-02 18:43:23,408] [INFO] [utils.py:803:see_memory_usage] MA 2.27 GB         Max_MA 2.68 GB         CA 2.44 GB         Max_CA 4 GB 
[2024-06-02 18:43:23,408] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.14 GB, percent = 1.2%
[2024-06-02 18:43:23,417] [INFO] [stage3.py:126:__init__] Reduce bucket size 500,000,000
[2024-06-02 18:43:23,417] [INFO] [stage3.py:127:__init__] Prefetch bucket size 50,000,000
[2024-06-02 18:43:23,630] [INFO] [utils.py:802:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]
[2024-06-02 18:43:23,631] [INFO] [utils.py:803:see_memory_usage] MA 2.27 GB         Max_MA 2.27 GB         CA 2.44 GB         Max_CA 2 GB 
[2024-06-02 18:43:23,631] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.14 GB, percent = 1.2%
Parameter Offload: Total persistent parameters: 20189184 in 417 params
[2024-06-02 18:43:23,872] [INFO] [utils.py:802:see_memory_usage] DeepSpeedZeRoOffload initialize [end]
[2024-06-02 18:43:23,872] [INFO] [utils.py:803:see_memory_usage] MA 2.2 GB         Max_MA 2.27 GB         CA 2.44 GB         Max_CA 2 GB 
[2024-06-02 18:43:23,872] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.15 GB, percent = 1.2%
[2024-06-02 18:43:23,971] [INFO] [utils.py:802:see_memory_usage] Before creating fp16 partitions
[2024-06-02 18:43:23,971] [INFO] [utils.py:803:see_memory_usage] MA 2.2 GB         Max_MA 2.2 GB         CA 2.44 GB         Max_CA 2 GB 
[2024-06-02 18:43:23,972] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.15 GB, percent = 1.2%
[2024-06-02 18:43:24,284] [INFO] [utils.py:802:see_memory_usage] After creating fp16 partitions: 1
[2024-06-02 18:43:24,284] [INFO] [utils.py:803:see_memory_usage] MA 2.2 GB         Max_MA 2.2 GB         CA 2.36 GB         Max_CA 2 GB 
[2024-06-02 18:43:24,285] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.2 GB, percent = 1.3%
[2024-06-02 18:43:24,388] [INFO] [utils.py:802:see_memory_usage] Before creating fp32 partitions
[2024-06-02 18:43:24,388] [INFO] [utils.py:803:see_memory_usage] MA 2.2 GB         Max_MA 2.2 GB         CA 2.36 GB         Max_CA 2 GB 
[2024-06-02 18:43:24,388] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.2 GB, percent = 1.3%
[2024-06-02 18:43:24,488] [INFO] [utils.py:802:see_memory_usage] After creating fp32 partitions
[2024-06-02 18:43:24,488] [INFO] [utils.py:803:see_memory_usage] MA 2.22 GB         Max_MA 2.23 GB         CA 2.36 GB         Max_CA 2 GB 
[2024-06-02 18:43:24,488] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.2 GB, percent = 1.3%
[2024-06-02 18:43:24,594] [INFO] [utils.py:802:see_memory_usage] Before initializing optimizer states
[2024-06-02 18:43:24,595] [INFO] [utils.py:803:see_memory_usage] MA 2.22 GB         Max_MA 2.22 GB         CA 2.36 GB         Max_CA 2 GB 
[2024-06-02 18:43:24,595] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.33 GB, percent = 1.3%
[2024-06-02 18:43:24,749] [INFO] [utils.py:802:see_memory_usage] After initializing optimizer states
[2024-06-02 18:43:24,749] [INFO] [utils.py:803:see_memory_usage] MA 2.26 GB         Max_MA 2.3 GB         CA 2.4 GB         Max_CA 2 GB 
[2024-06-02 18:43:24,750] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.36 GB, percent = 1.3%
[2024-06-02 18:43:24,750] [INFO] [stage3.py:460:_setup_for_real_optimizer] optimizer state initialized
[2024-06-02 18:43:25,076] [INFO] [utils.py:802:see_memory_usage] After initializing ZeRO optimizer
[2024-06-02 18:43:25,077] [INFO] [utils.py:803:see_memory_usage] MA 3.2 GB         Max_MA 3.2 GB         CA 3.33 GB         Max_CA 3 GB 
[2024-06-02 18:43:25,077] [INFO] [utils.py:810:see_memory_usage] CPU Virtual Memory:  used = 25.49 GB, percent = 1.3%
[2024-06-02 18:43:25,077] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2024-06-02 18:43:25,077] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using client LR scheduler
[2024-06-02 18:43:25,077] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-06-02 18:43:25,077] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[(0.9, 0.999)]
[2024-06-02 18:43:25,083] [INFO] [config.py:972:print] DeepSpeedEngine configuration:
[2024-06-02 18:43:25,084] [INFO] [config.py:976:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-06-02 18:43:25,084] [INFO] [config.py:976:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-06-02 18:43:25,084] [INFO] [config.py:976:print]   amp_enabled .................. False
[2024-06-02 18:43:25,084] [INFO] [config.py:976:print]   amp_params ................... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   bfloat16_enabled ............. True
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   checkpoint_parallel_write_pipeline  False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   checkpoint_tag_validation_enabled  True
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   checkpoint_tag_validation_fail  False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f9db663fa90>
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   communication_data_type ...... None
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   curriculum_enabled_legacy .... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   curriculum_params_legacy ..... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   data_efficiency_enabled ...... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   dataloader_drop_last ......... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   disable_allgather ............ False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   dump_state ................... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   dynamic_loss_scale_args ...... None
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   eigenvalue_enabled ........... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   eigenvalue_gas_boundary_resolution  1
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   eigenvalue_layer_num ......... 0
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   eigenvalue_max_iter .......... 100
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   eigenvalue_stability ......... 1e-06
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   eigenvalue_tol ............... 0.01
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   eigenvalue_verbose ........... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   elasticity_enabled ........... False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   fp16_auto_cast ............... None
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   fp16_enabled ................. False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   fp16_master_weights_and_gradients  False
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   global_rank .................. 0
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   grad_accum_dtype ............. None
[2024-06-02 18:43:25,085] [INFO] [config.py:976:print]   gradient_accumulation_steps .. 1
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   gradient_clipping ............ 1.0
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   gradient_predivide_factor .... 1.0
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   initial_dynamic_scale ........ 1
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   load_universal_checkpoint .... False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   loss_scale ................... 1.0
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   memory_breakdown ............. False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   mics_hierarchial_params_gather  False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   mics_shard_size .............. -1
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   optimizer_legacy_fusion ...... False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   optimizer_name ............... None
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   optimizer_params ............. None
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   pld_enabled .................. False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   pld_params ................... False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   prescale_gradients ........... False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   scheduler_name ............... None
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   scheduler_params ............. None
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   seq_parallel_communication_data_type  torch.float32
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   sparse_attention ............. None
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   sparse_gradients_enabled ..... False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   steps_per_print .............. inf
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   train_batch_size ............. 8
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   train_micro_batch_size_per_gpu  1
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   use_node_local_storage ....... False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   wall_clock_breakdown ......... False
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   weight_quantization_config ... None
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   world_size ................... 8
[2024-06-02 18:43:25,086] [INFO] [config.py:976:print]   zero_allow_untested_optimizer  True
[2024-06-02 18:43:25,087] [INFO] [config.py:976:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-06-02 18:43:25,087] [INFO] [config.py:976:print]   zero_enabled ................. True
[2024-06-02 18:43:25,087] [INFO] [config.py:976:print]   zero_force_ds_cpu_optimizer .. True
[2024-06-02 18:43:25,087] [INFO] [config.py:976:print]   zero_optimization_stage ...... 3
[2024-06-02 18:43:25,087] [INFO] [config.py:962:print_user_config]   json = {
    "train_batch_size": 8, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 1, 
    "zero_optimization": {
        "stage": 3, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": true
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "zero_allow_untested_optimizer": true
}
[INFO|deepspeed.py:430] 2024-06-02 18:43:25,091 >> Attempting to resume from /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-1250
[2024-06-02 18:43:25,119] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-1250/global_step1250/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-06-02 18:43:25,160] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-1250/global_step1250/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-06-02 18:43:25,161] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-1250/global_step1250/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-06-02 18:43:25,177] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-1250/global_step1250/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-06-02 18:43:25,201] [INFO] [torch_checkpoint_engine.py:27:load] [Torch] Loading checkpoint from /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-1250/global_step1250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-06-02 18:43:25,312] [INFO] [torch_checkpoint_engine.py:29:load] [Torch] Loaded checkpoint from /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-1250/global_step1250/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-06-02 18:43:25,312] [INFO] [engine.py:2949:_get_all_zero_checkpoint_state_dicts] successfully read 8 ZeRO state_dicts for rank 0
[2024-06-02 18:43:25,322] [INFO] [engine.py:2899:_load_zero_checkpoint] loading 8 zero partition checkpoints for rank 0
[INFO|trainer.py:2078] 2024-06-02 18:43:25,341 >> ***** Running training *****
[INFO|trainer.py:2079] 2024-06-02 18:43:25,341 >>   Num examples = 10,000
[INFO|trainer.py:2080] 2024-06-02 18:43:25,341 >>   Num Epochs = 2
[INFO|trainer.py:2081] 2024-06-02 18:43:25,341 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2084] 2024-06-02 18:43:25,341 >>   Total train batch size (w. parallel, distributed & accumulation) = 8
[INFO|trainer.py:2085] 2024-06-02 18:43:25,341 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:2086] 2024-06-02 18:43:25,341 >>   Total optimization steps = 2,500
[INFO|trainer.py:2087] 2024-06-02 18:43:25,345 >>   Number of trainable parameters = 41,943,040
[WARNING|logging.py:329] 2024-06-02 18:43:25,346 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 2 (from args) != 3 (from trainer_state.json)
[WARNING|logging.py:329] 2024-06-02 18:43:25,346 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 2 (from args) != 3 (from trainer_state.json)
[INFO|trainer.py:2109] 2024-06-02 18:43:25,346 >>   Continuing training from checkpoint, will skip to saved global_step
[INFO|trainer.py:2110] 2024-06-02 18:43:25,346 >>   Continuing training from epoch 1
[WARNING|logging.py:329] 2024-06-02 18:43:25,346 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 2 (from args) != 3 (from trainer_state.json)
[INFO|trainer.py:2111] 2024-06-02 18:43:25,346 >>   Continuing training from global step 1250
[INFO|trainer.py:2113] 2024-06-02 18:43:25,346 >>   Will skip the first 1 epochs then the first 0 batches in the first epoch.
[WARNING|logging.py:329] 2024-06-02 18:43:25,347 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 2 (from args) != 3 (from trainer_state.json)
[WARNING|logging.py:329] 2024-06-02 18:43:25,347 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 2 (from args) != 3 (from trainer_state.json)
[WARNING|logging.py:329] 2024-06-02 18:43:25,347 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 2 (from args) != 3 (from trainer_state.json)
[WARNING|logging.py:329] 2024-06-02 18:43:25,347 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 2 (from args) != 3 (from trainer_state.json)
[WARNING|logging.py:329] 2024-06-02 18:43:25,347 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: 
	save_steps: 2 (from args) != 3 (from trainer_state.json)
[INFO|integration_utils.py:723] 2024-06-02 18:43:25,350 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: chtmp223. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /work/pi_miyyer_umass_edu/ctpham/alignment-handbook/wandb/run-20240602_184326-aaq3gynb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run orpo-lora-curr
wandb: ⭐️ View project at https://wandb.ai/chtmp223/huggingface
wandb: 🚀 View run at https://wandb.ai/chtmp223/huggingface/runs/aaq3gynb
  0%|          | 0/2500 [00:00<?, ?it/s][WARNING|modeling_utils.py:1190] 2024-06-02 18:43:37,234 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1190] 2024-06-02 18:43:37,234 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1190] 2024-06-02 18:43:37,234 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1190] 2024-06-02 18:43:37,234 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1190] 2024-06-02 18:43:37,234 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1190] 2024-06-02 18:43:37,234 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1190] 2024-06-02 18:43:37,234 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1190] 2024-06-02 18:43:37,234 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
 50%|█████     | 1251/2500 [00:09<00:09, 126.53it/s] 50%|█████     | 1253/2500 [00:26<00:09, 126.53it/s] 50%|█████     | 1254/2500 [00:29<00:37, 33.46it/s]  50%|█████     | 1255/2500 [00:36<00:52, 23.67it/s] 50%|█████     | 1256/2500 [00:48<00:52, 23.67it/s] 50%|█████     | 1257/2500 [00:49<01:27, 14.15it/s] 50%|█████     | 1258/2500 [00:55<01:52, 11.00it/s] 50%|█████     | 1259/2500 [01:06<01:52, 11.00it/s] 50%|█████     | 1260/2500 [01:08<03:08,  6.59it/s]                                                   {'loss': 2.057, 'grad_norm': 0.1720416241097708, 'learning_rate': 2.4685849002916183e-05, 'rewards/chosen': -0.7956631183624268, 'rewards/rejected': -2.454719066619873, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6590557098388672, 'logps/rejected': -6.136796951293945, 'logps/chosen': -1.9891576766967773, 'logits/rejected': -2.334864377975464, 'logits/chosen': -2.958428144454956, 'nll_loss': 1.9725710153579712, 'log_odds_ratio': -0.08582495898008347, 'log_odds_chosen': 4.287029266357422, 'logps/chosen_prompt': -0.8272172808647156, 'logps/rejected_prompt': -1.031011939048767, 'logits/chosen_prompt': -2.775263547897339, 'logits/rejected_prompt': -2.7559731006622314, 'logps/chosen_both': -1.9733705520629883, 'logps/rejected_both': -6.0656609535217285, 'epoch': 1.01}
 50%|█████     | 1260/2500 [01:08<03:08,  6.59it/s] 50%|█████     | 1261/2500 [01:14<03:56,  5.25it/s] 50%|█████     | 1262/2500 [01:26<03:55,  5.25it/s] 51%|█████     | 1263/2500 [01:27<06:11,  3.33it/s] 51%|█████     | 1264/2500 [01:33<07:42,  2.67it/s] 51%|█████     | 1266/2500 [01:45<12:11,  1.69it/s] 51%|█████     | 1267/2500 [01:52<15:12,  1.35it/s] 51%|█████     | 1268/2500 [01:59<19:30,  1.05it/s] 51%|█████     | 1269/2500 [02:05<24:18,  1.18s/it] 51%|█████     | 1270/2500 [02:11<30:48,  1.50s/it]                                                   {'loss': 2.0526, 'grad_norm': 13.694782600642085, 'learning_rate': 2.4371747613916566e-05, 'rewards/chosen': -0.807985782623291, 'rewards/rejected': -2.2430672645568848, 'rewards/accuracies': 1.0, 'rewards/margins': 1.4350816011428833, 'logps/rejected': -5.607668876647949, 'logps/chosen': -2.0199644565582275, 'logits/rejected': -2.3685555458068848, 'logits/chosen': -2.897031307220459, 'nll_loss': 2.004603385925293, 'log_odds_ratio': -0.15850409865379333, 'log_odds_chosen': 3.702482223510742, 'logps/chosen_prompt': -0.8945725560188293, 'logps/rejected_prompt': -1.0042171478271484, 'logits/chosen_prompt': -2.792998790740967, 'logits/rejected_prompt': -2.7757651805877686, 'logps/chosen_both': -2.005324125289917, 'logps/rejected_both': -5.54673957824707, 'epoch': 1.02}
 51%|█████     | 1270/2500 [02:11<30:48,  1.50s/it] 51%|█████     | 1271/2500 [02:18<39:32,  1.93s/it] 51%|█████     | 1272/2500 [02:24<48:46,  2.38s/it] 51%|█████     | 1273/2500 [02:30<59:20,  2.90s/it] 51%|█████     | 1274/2500 [02:37<1:12:14,  3.54s/it] 51%|█████     | 1275/2500 [02:43<1:20:57,  3.96s/it] 51%|█████     | 1276/2500 [02:49<1:28:21,  4.33s/it] 51%|█████     | 1277/2500 [02:55<1:36:07,  4.72s/it] 51%|█████     | 1278/2500 [03:01<1:45:21,  5.17s/it] 51%|█████     | 1279/2500 [03:08<1:52:38,  5.54s/it] 51%|█████     | 1280/2500 [03:14<1:55:13,  5.67s/it]                                                     {'loss': 1.9466, 'grad_norm': 0.1847800976596034, 'learning_rate': 2.4057745433251635e-05, 'rewards/chosen': -0.714826762676239, 'rewards/rejected': -2.685321569442749, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9704946279525757, 'logps/rejected': -6.713304042816162, 'logps/chosen': -1.7870668172836304, 'logits/rejected': -2.16129732131958, 'logits/chosen': -2.913508653640747, 'nll_loss': 1.7730668783187866, 'log_odds_ratio': -0.07373705506324768, 'log_odds_chosen': 5.104033946990967, 'logps/chosen_prompt': -0.8896484375, 'logps/rejected_prompt': -1.093833565711975, 'logits/chosen_prompt': -2.7657768726348877, 'logits/rejected_prompt': -2.7381515502929688, 'logps/chosen_both': -1.773654580116272, 'logps/rejected_both': -6.625698089599609, 'epoch': 1.02}
 51%|█████     | 1280/2500 [03:14<1:55:13,  5.67s/it] 51%|█████     | 1281/2500 [03:21<2:01:15,  5.97s/it] 51%|█████▏    | 1282/2500 [03:27<2:01:13,  5.97s/it] 51%|█████▏    | 1283/2500 [03:33<2:02:57,  6.06s/it] 51%|█████▏    | 1284/2500 [03:39<2:05:22,  6.19s/it] 51%|█████▏    | 1285/2500 [03:45<2:04:07,  6.13s/it] 51%|█████▏    | 1286/2500 [03:52<2:04:39,  6.16s/it] 51%|█████▏    | 1287/2500 [03:58<2:08:52,  6.38s/it] 52%|█████▏    | 1288/2500 [04:04<2:05:39,  6.22s/it] 52%|█████▏    | 1289/2500 [04:11<2:10:25,  6.46s/it] 52%|█████▏    | 1290/2500 [04:17<2:08:00,  6.35s/it]                                                     {'loss': 1.9697, 'grad_norm': 0.18034582150078582, 'learning_rate': 2.3743892045505764e-05, 'rewards/chosen': -0.7612434029579163, 'rewards/rejected': -2.4072835445404053, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6460399627685547, 'logps/rejected': -6.0182085037231445, 'logps/chosen': -1.9031085968017578, 'logits/rejected': -2.2989792823791504, 'logits/chosen': -2.997952938079834, 'nll_loss': 1.8839712142944336, 'log_odds_ratio': -0.14480409026145935, 'log_odds_chosen': 4.2414398193359375, 'logps/chosen_prompt': -0.8114041090011597, 'logps/rejected_prompt': -0.9754440188407898, 'logits/chosen_prompt': -2.735383987426758, 'logits/rejected_prompt': -2.6965184211730957, 'logps/chosen_both': -1.8843858242034912, 'logps/rejected_both': -5.927855491638184, 'epoch': 1.03}
 52%|█████▏    | 1290/2500 [04:17<2:08:00,  6.35s/it] 52%|█████▏    | 1291/2500 [04:24<2:08:52,  6.40s/it] 52%|█████▏    | 1292/2500 [04:30<2:09:31,  6.43s/it] 52%|█████▏    | 1293/2500 [04:37<2:11:34,  6.54s/it] 52%|█████▏    | 1294/2500 [04:43<2:08:53,  6.41s/it] 52%|█████▏    | 1295/2500 [04:50<2:07:08,  6.33s/it] 52%|█████▏    | 1296/2500 [04:56<2:08:36,  6.41s/it] 52%|█████▏    | 1297/2500 [05:02<2:06:12,  6.29s/it] 52%|█████▏    | 1298/2500 [05:08<2:03:50,  6.18s/it] 52%|█████▏    | 1299/2500 [05:15<2:08:11,  6.40s/it] 52%|█████▏    | 1300/2500 [05:21<2:06:06,  6.31s/it]                                                     {'loss': 2.0803, 'grad_norm': 0.16867167051138807, 'learning_rate': 2.3430237011767167e-05, 'rewards/chosen': -0.8372515439987183, 'rewards/rejected': -2.753661632537842, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9164100885391235, 'logps/rejected': -6.884153842926025, 'logps/chosen': -2.0931286811828613, 'logits/rejected': -2.0374085903167725, 'logits/chosen': -2.8917794227600098, 'nll_loss': 2.075140953063965, 'log_odds_ratio': -0.0735301747918129, 'log_odds_chosen': 4.911897659301758, 'logps/chosen_prompt': -0.8204188346862793, 'logps/rejected_prompt': -0.9796915054321289, 'logits/chosen_prompt': -2.752427577972412, 'logits/rejected_prompt': -2.733212947845459, 'logps/chosen_both': -2.075914144515991, 'logps/rejected_both': -6.796868324279785, 'epoch': 1.04}
 52%|█████▏    | 1300/2500 [05:21<2:06:06,  6.31s/it] 52%|█████▏    | 1301/2500 [05:27<2:05:30,  6.28s/it] 52%|█████▏    | 1302/2500 [05:33<2:04:39,  6.24s/it] 52%|█████▏    | 1303/2500 [05:40<2:06:10,  6.32s/it] 52%|█████▏    | 1304/2500 [05:46<2:05:13,  6.28s/it] 52%|█████▏    | 1305/2500 [05:53<2:09:34,  6.51s/it] 52%|█████▏    | 1306/2500 [06:00<2:12:37,  6.66s/it] 52%|█████▏    | 1307/2500 [06:07<2:12:23,  6.66s/it] 52%|█████▏    | 1308/2500 [06:13<2:11:15,  6.61s/it] 52%|█████▏    | 1309/2500 [06:20<2:09:43,  6.54s/it] 52%|█████▏    | 1310/2500 [06:26<2:06:52,  6.40s/it]                                                     {'loss': 1.9859, 'grad_norm': 0.2675257506810404, 'learning_rate': 2.3116829861801686e-05, 'rewards/chosen': -0.8038879632949829, 'rewards/rejected': -2.761246919631958, 'rewards/accuracies': 1.0, 'rewards/margins': 1.957358956336975, 'logps/rejected': -6.9031171798706055, 'logps/chosen': -2.0097198486328125, 'logits/rejected': -1.9886223077774048, 'logits/chosen': -2.8843209743499756, 'nll_loss': 1.9904582500457764, 'log_odds_ratio': -0.07356567680835724, 'log_odds_chosen': 5.027341842651367, 'logps/chosen_prompt': -0.8367593884468079, 'logps/rejected_prompt': -0.9872042536735535, 'logits/chosen_prompt': -2.75431752204895, 'logits/rejected_prompt': -2.7196097373962402, 'logps/chosen_both': -1.990984320640564, 'logps/rejected_both': -6.8120245933532715, 'epoch': 1.05}
 52%|█████▏    | 1310/2500 [06:26<2:06:52,  6.40s/it] 52%|█████▏    | 1311/2500 [06:33<2:09:23,  6.53s/it] 52%|█████▏    | 1312/2500 [06:39<2:07:01,  6.42s/it] 53%|█████▎    | 1313/2500 [06:45<2:05:52,  6.36s/it] 53%|█████▎    | 1314/2500 [06:52<2:07:19,  6.44s/it] 53%|█████▎    | 1315/2500 [06:58<2:06:31,  6.41s/it] 53%|█████▎    | 1316/2500 [07:04<2:03:59,  6.28s/it] 53%|█████▎    | 1317/2500 [07:11<2:05:55,  6.39s/it] 53%|█████▎    | 1318/2500 [07:17<2:03:25,  6.26s/it] 53%|█████▎    | 1319/2500 [07:23<2:02:09,  6.21s/it] 53%|█████▎    | 1320/2500 [07:29<2:02:11,  6.21s/it]                                                     {'loss': 2.1131, 'grad_norm': 0.17430756040481657, 'learning_rate': 2.280372008623142e-05, 'rewards/chosen': -0.7636791467666626, 'rewards/rejected': -2.739264726638794, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.975585699081421, 'logps/rejected': -6.8481621742248535, 'logps/chosen': -1.9091980457305908, 'logits/rejected': -2.031425952911377, 'logits/chosen': -2.952594757080078, 'nll_loss': 1.8915550708770752, 'log_odds_ratio': -0.07625749707221985, 'log_odds_chosen': 5.088331699371338, 'logps/chosen_prompt': -0.8724919557571411, 'logps/rejected_prompt': -1.049777865409851, 'logits/chosen_prompt': -2.7141482830047607, 'logits/rejected_prompt': -2.6890976428985596, 'logps/chosen_both': -1.8927940130233765, 'logps/rejected_both': -6.74472713470459, 'epoch': 1.06}
 53%|█████▎    | 1320/2500 [07:29<2:02:11,  6.21s/it] 53%|█████▎    | 1321/2500 [07:35<2:04:29,  6.34s/it] 53%|█████▎    | 1322/2500 [07:41<2:02:28,  6.24s/it] 53%|█████▎    | 1323/2500 [07:48<2:05:06,  6.38s/it] 53%|█████▎    | 1324/2500 [07:54<2:04:01,  6.33s/it] 53%|█████▎    | 1325/2500 [08:00<2:01:08,  6.19s/it] 53%|█████▎    | 1326/2500 [08:06<2:00:40,  6.17s/it] 53%|█████▎    | 1327/2500 [08:12<1:59:38,  6.12s/it] 53%|█████▎    | 1328/2500 [08:18<1:59:23,  6.11s/it] 53%|█████▎    | 1329/2500 [08:25<1:59:38,  6.13s/it] 53%|█████▎    | 1330/2500 [08:32<2:05:27,  6.43s/it]                                                     {'loss': 2.3103, 'grad_norm': 2.583840774416736, 'learning_rate': 2.2490957128719624e-05, 'rewards/chosen': -1.051758885383606, 'rewards/rejected': -2.645522117614746, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.5937631130218506, 'logps/rejected': -6.613806247711182, 'logps/chosen': -2.629397392272949, 'logits/rejected': -1.9792897701263428, 'logits/chosen': -2.9445791244506836, 'nll_loss': 2.6017398834228516, 'log_odds_ratio': -0.5417389869689941, 'log_odds_chosen': 4.071897983551025, 'logps/chosen_prompt': -0.8532832860946655, 'logps/rejected_prompt': -1.0293222665786743, 'logits/chosen_prompt': -2.701814889907837, 'logits/rejected_prompt': -2.6827151775360107, 'logps/chosen_both': -2.603494644165039, 'logps/rejected_both': -6.519090175628662, 'epoch': 1.06}
 53%|█████▎    | 1330/2500 [08:32<2:05:27,  6.43s/it] 53%|█████▎    | 1331/2500 [08:38<2:06:15,  6.48s/it] 53%|█████▎    | 1332/2500 [08:45<2:04:18,  6.39s/it] 53%|█████▎    | 1333/2500 [08:50<2:00:22,  6.19s/it] 53%|█████▎    | 1334/2500 [08:56<1:57:37,  6.05s/it] 53%|█████▎    | 1335/2500 [09:02<1:56:49,  6.02s/it] 53%|█████▎    | 1336/2500 [09:08<1:57:36,  6.06s/it] 53%|█████▎    | 1337/2500 [09:14<1:58:39,  6.12s/it] 54%|█████▎    | 1338/2500 [09:20<1:58:22,  6.11s/it] 54%|█████▎    | 1339/2500 [09:27<2:00:34,  6.23s/it] 54%|█████▎    | 1340/2500 [09:33<2:02:08,  6.32s/it]                                                     {'loss': 2.0858, 'grad_norm': 0.19311846207382133, 'learning_rate': 2.217859037816296e-05, 'rewards/chosen': -0.7768605947494507, 'rewards/rejected': -2.523833751678467, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7469730377197266, 'logps/rejected': -6.30958366394043, 'logps/chosen': -1.942151427268982, 'logits/rejected': -2.1103525161743164, 'logits/chosen': -2.9947447776794434, 'nll_loss': 1.9238040447235107, 'log_odds_ratio': -0.14130227267742157, 'log_odds_chosen': 4.494226932525635, 'logps/chosen_prompt': -0.7182875871658325, 'logps/rejected_prompt': -0.8996931910514832, 'logits/chosen_prompt': -2.7876639366149902, 'logits/rejected_prompt': -2.7654964923858643, 'logps/chosen_both': -1.9244638681411743, 'logps/rejected_both': -6.22537899017334, 'epoch': 1.07}
 54%|█████▎    | 1340/2500 [09:33<2:02:08,  6.32s/it] 54%|█████▎    | 1341/2500 [09:40<2:01:18,  6.28s/it] 54%|█████▎    | 1342/2500 [09:46<2:01:22,  6.29s/it] 54%|█████▎    | 1343/2500 [09:52<1:58:06,  6.12s/it] 54%|█████▍    | 1344/2500 [09:58<1:59:31,  6.20s/it] 54%|█████▍    | 1345/2500 [10:04<1:57:53,  6.12s/it] 54%|█████▍    | 1346/2500 [10:10<1:57:45,  6.12s/it] 54%|█████▍    | 1347/2500 [10:17<2:01:44,  6.34s/it] 54%|█████▍    | 1348/2500 [10:24<2:04:58,  6.51s/it] 54%|█████▍    | 1349/2500 [10:30<1:59:34,  6.23s/it] 54%|█████▍    | 1350/2500 [10:36<1:59:23,  6.23s/it]                                                     {'loss': 2.0141, 'grad_norm': 12.497364029502023, 'learning_rate': 2.186666916089239e-05, 'rewards/chosen': -0.9422861337661743, 'rewards/rejected': -2.739943742752075, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7976577281951904, 'logps/rejected': -6.84985876083374, 'logps/chosen': -2.355715274810791, 'logits/rejected': -2.2449707984924316, 'logits/chosen': -2.922910451889038, 'nll_loss': 2.332667827606201, 'log_odds_ratio': -0.03583256155252457, 'log_odds_chosen': 4.636378288269043, 'logps/chosen_prompt': -0.8444534540176392, 'logps/rejected_prompt': -1.0258666276931763, 'logits/chosen_prompt': -2.7941555976867676, 'logits/rejected_prompt': -2.767634630203247, 'logps/chosen_both': -2.333418130874634, 'logps/rejected_both': -6.75320291519165, 'epoch': 1.08}
 54%|█████▍    | 1350/2500 [10:36<1:59:23,  6.23s/it] 54%|█████▍    | 1351/2500 [10:42<1:57:35,  6.14s/it] 54%|█████▍    | 1352/2500 [10:47<1:55:18,  6.03s/it] 54%|█████▍    | 1353/2500 [10:54<1:57:25,  6.14s/it] 54%|█████▍    | 1354/2500 [11:00<1:57:13,  6.14s/it] 54%|█████▍    | 1355/2500 [11:06<1:57:10,  6.14s/it] 54%|█████▍    | 1356/2500 [11:12<1:55:27,  6.06s/it] 54%|█████▍    | 1357/2500 [11:18<1:58:03,  6.20s/it] 54%|█████▍    | 1358/2500 [11:28<2:15:46,  7.13s/it] 54%|█████▍    | 1359/2500 [11:34<2:11:26,  6.91s/it] 54%|█████▍    | 1360/2500 [11:41<2:11:21,  6.91s/it]                                                     {'loss': 2.0296, 'grad_norm': 0.2270614213589309, 'learning_rate': 2.155524273288405e-05, 'rewards/chosen': -0.8347503542900085, 'rewards/rejected': -2.916297197341919, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0815467834472656, 'logps/rejected': -7.290743350982666, 'logps/chosen': -2.0868756771087646, 'logits/rejected': -2.165241241455078, 'logits/chosen': -2.8982808589935303, 'nll_loss': 2.06916880607605, 'log_odds_ratio': -0.0055731432512402534, 'log_odds_chosen': 5.339554786682129, 'logps/chosen_prompt': -0.8766686320304871, 'logps/rejected_prompt': -0.9699287414550781, 'logits/chosen_prompt': -2.822666883468628, 'logits/rejected_prompt': -2.798936367034912, 'logps/chosen_both': -2.0702621936798096, 'logps/rejected_both': -7.200596809387207, 'epoch': 1.09}
 54%|█████▍    | 1360/2500 [11:41<2:11:21,  6.91s/it] 54%|█████▍    | 1361/2500 [11:47<2:06:52,  6.68s/it] 54%|█████▍    | 1362/2500 [11:53<2:03:19,  6.50s/it] 55%|█████▍    | 1363/2500 [12:00<2:03:15,  6.50s/it] 55%|█████▍    | 1364/2500 [12:06<1:59:07,  6.29s/it] 55%|█████▍    | 1365/2500 [12:11<1:56:24,  6.15s/it] 55%|█████▍    | 1366/2500 [12:17<1:55:06,  6.09s/it] 55%|█████▍    | 1367/2500 [12:23<1:54:17,  6.05s/it] 55%|█████▍    | 1368/2500 [12:30<1:55:56,  6.15s/it] 55%|█████▍    | 1369/2500 [12:36<1:58:17,  6.28s/it] 55%|█████▍    | 1370/2500 [12:43<1:58:15,  6.28s/it]                                                     {'loss': 2.0366, 'grad_norm': 0.18673822638465642, 'learning_rate': 2.1244360271981073e-05, 'rewards/chosen': -0.7598467469215393, 'rewards/rejected': -2.463371753692627, 'rewards/accuracies': 1.0, 'rewards/margins': 1.703525185585022, 'logps/rejected': -6.158430099487305, 'logps/chosen': -1.8996168375015259, 'logits/rejected': -2.342402696609497, 'logits/chosen': -2.9973549842834473, 'nll_loss': 1.883172631263733, 'log_odds_ratio': -0.14087161421775818, 'log_odds_chosen': 4.400548934936523, 'logps/chosen_prompt': -0.8336794972419739, 'logps/rejected_prompt': -0.9460757970809937, 'logits/chosen_prompt': -2.8455936908721924, 'logits/rejected_prompt': -2.8205618858337402, 'logps/chosen_both': -1.8836266994476318, 'logps/rejected_both': -6.074185371398926, 'epoch': 1.1}
 55%|█████▍    | 1370/2500 [12:43<1:58:15,  6.28s/it] 55%|█████▍    | 1371/2500 [12:49<1:58:50,  6.32s/it] 55%|█████▍    | 1372/2500 [12:55<1:55:27,  6.14s/it] 55%|█████▍    | 1373/2500 [13:01<1:54:05,  6.07s/it] 55%|█████▍    | 1374/2500 [13:07<1:54:14,  6.09s/it] 55%|█████▌    | 1375/2500 [13:13<1:55:13,  6.15s/it] 55%|█████▌    | 1376/2500 [13:19<1:56:19,  6.21s/it] 55%|█████▌    | 1377/2500 [13:25<1:55:19,  6.16s/it] 55%|█████▌    | 1378/2500 [13:32<1:55:24,  6.17s/it] 55%|█████▌    | 1379/2500 [13:38<1:53:53,  6.10s/it] 55%|█████▌    | 1380/2500 [13:44<1:52:46,  6.04s/it]                                                     {'loss': 1.9977, 'grad_norm': 0.2172045576599196, 'learning_rate': 2.0934070870127912e-05, 'rewards/chosen': -0.7425598502159119, 'rewards/rejected': -2.7519497871398926, 'rewards/accuracies': 1.0, 'rewards/margins': 2.009390115737915, 'logps/rejected': -6.879874229431152, 'logps/chosen': -1.8563995361328125, 'logits/rejected': -2.209272623062134, 'logits/chosen': -2.9949612617492676, 'nll_loss': 1.8390493392944336, 'log_odds_ratio': -0.009297337383031845, 'log_odds_chosen': 5.196164131164551, 'logps/chosen_prompt': -0.8623350858688354, 'logps/rejected_prompt': -1.001868486404419, 'logits/chosen_prompt': -2.825692653656006, 'logits/rejected_prompt': -2.7977724075317383, 'logps/chosen_both': -1.83943772315979, 'logps/rejected_both': -6.780916690826416, 'epoch': 1.1}
 55%|█████▌    | 1380/2500 [13:44<1:52:46,  6.04s/it] 55%|█████▌    | 1381/2500 [13:50<1:57:49,  6.32s/it] 55%|█████▌    | 1382/2500 [13:57<1:56:44,  6.27s/it] 55%|█████▌    | 1383/2500 [14:04<2:02:56,  6.60s/it] 55%|█████▌    | 1384/2500 [14:10<2:01:10,  6.51s/it] 55%|█████▌    | 1385/2500 [14:16<1:58:28,  6.38s/it] 55%|█████▌    | 1386/2500 [14:22<1:56:17,  6.26s/it] 55%|█████▌    | 1387/2500 [14:28<1:53:25,  6.11s/it] 56%|█████▌    | 1388/2500 [14:34<1:52:27,  6.07s/it] 56%|█████▌    | 1389/2500 [14:40<1:54:11,  6.17s/it] 56%|█████▌    | 1390/2500 [14:47<1:56:32,  6.30s/it]                                                     {'loss': 1.9681, 'grad_norm': 0.1929084709665783, 'learning_rate': 2.0624423525618098e-05, 'rewards/chosen': -0.7725422382354736, 'rewards/rejected': -2.959909677505493, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1873672008514404, 'logps/rejected': -7.39977502822876, 'logps/chosen': -1.9313554763793945, 'logits/rejected': -2.0224051475524902, 'logits/chosen': -2.9610986709594727, 'nll_loss': 1.9153549671173096, 'log_odds_ratio': -0.0038383095525205135, 'log_odds_chosen': 5.628210544586182, 'logps/chosen_prompt': -0.9007645845413208, 'logps/rejected_prompt': -0.9978343844413757, 'logits/chosen_prompt': -2.7801530361175537, 'logits/rejected_prompt': -2.7500534057617188, 'logps/chosen_both': -1.9156417846679688, 'logps/rejected_both': -7.303445339202881, 'epoch': 1.11}
 56%|█████▌    | 1390/2500 [14:47<1:56:32,  6.30s/it] 56%|█████▌    | 1391/2500 [14:53<1:56:43,  6.32s/it] 56%|█████▌    | 1392/2500 [14:59<1:52:37,  6.10s/it] 56%|█████▌    | 1393/2500 [15:05<1:54:16,  6.19s/it] 56%|█████▌    | 1394/2500 [15:14<2:05:41,  6.82s/it] 56%|█████▌    | 1395/2500 [15:20<2:01:29,  6.60s/it] 56%|█████▌    | 1396/2500 [15:26<1:57:50,  6.40s/it] 56%|█████▌    | 1397/2500 [15:32<1:54:06,  6.21s/it] 56%|█████▌    | 1398/2500 [15:38<1:54:04,  6.21s/it] 56%|█████▌    | 1399/2500 [15:44<1:56:40,  6.36s/it] 56%|█████▌    | 1400/2500 [15:51<1:55:46,  6.31s/it]                                                     {'loss': 2.0691, 'grad_norm': 9.042155801309253, 'learning_rate': 2.031546713535688e-05, 'rewards/chosen': -0.8020264506340027, 'rewards/rejected': -2.84417462348938, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0421485900878906, 'logps/rejected': -7.110436916351318, 'logps/chosen': -2.005066156387329, 'logits/rejected': -2.015038013458252, 'logits/chosen': -2.9094903469085693, 'nll_loss': 1.9849870204925537, 'log_odds_ratio': -0.006375719793140888, 'log_odds_chosen': 5.250771522521973, 'logps/chosen_prompt': -0.7499234080314636, 'logps/rejected_prompt': -0.9696563482284546, 'logits/chosen_prompt': -2.7867002487182617, 'logits/rejected_prompt': -2.75203275680542, 'logps/chosen_both': -1.9861829280853271, 'logps/rejected_both': -7.012091636657715, 'epoch': 1.12}
 56%|█████▌    | 1400/2500 [15:51<1:55:46,  6.31s/it] 56%|█████▌    | 1401/2500 [15:57<1:53:57,  6.22s/it] 56%|█████▌    | 1402/2500 [16:04<1:57:54,  6.44s/it] 56%|█████▌    | 1403/2500 [16:10<1:57:00,  6.40s/it] 56%|█████▌    | 1404/2500 [16:16<1:54:46,  6.28s/it] 56%|█████▌    | 1405/2500 [16:22<1:55:04,  6.31s/it] 56%|█████▌    | 1406/2500 [16:28<1:54:24,  6.27s/it] 56%|█████▋    | 1407/2500 [16:35<1:53:29,  6.23s/it] 56%|█████▋    | 1408/2500 [16:41<1:52:18,  6.17s/it] 56%|█████▋    | 1409/2500 [16:47<1:54:02,  6.27s/it] 56%|█████▋    | 1410/2500 [16:54<1:54:27,  6.30s/it]                                                     {'loss': 2.0743, 'grad_norm': 0.4602953451114973, 'learning_rate': 2.000725048713983e-05, 'rewards/chosen': -0.826917290687561, 'rewards/rejected': -2.5972986221313477, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7703813314437866, 'logps/rejected': -6.493246555328369, 'logps/chosen': -2.067293405532837, 'logits/rejected': -2.188276767730713, 'logits/chosen': -2.903918981552124, 'nll_loss': 2.0476672649383545, 'log_odds_ratio': -0.04044898971915245, 'log_odds_chosen': 4.5587053298950195, 'logps/chosen_prompt': -0.7630623579025269, 'logps/rejected_prompt': -0.9369118809700012, 'logits/chosen_prompt': -2.783762216567993, 'logits/rejected_prompt': -2.7554469108581543, 'logps/chosen_both': -2.0483763217926025, 'logps/rejected_both': -6.412131309509277, 'epoch': 1.13}
 56%|█████▋    | 1410/2500 [16:54<1:54:27,  6.30s/it] 56%|█████▋    | 1411/2500 [17:00<1:56:54,  6.44s/it] 56%|█████▋    | 1412/2500 [17:07<1:55:47,  6.39s/it] 57%|█████▋    | 1413/2500 [17:13<1:54:52,  6.34s/it] 57%|█████▋    | 1414/2500 [17:20<1:57:40,  6.50s/it] 57%|█████▋    | 1415/2500 [17:29<2:14:03,  7.41s/it] 57%|█████▋    | 1416/2500 [17:36<2:10:35,  7.23s/it] 57%|█████▋    | 1417/2500 [17:42<2:03:10,  6.82s/it] 57%|█████▋    | 1418/2500 [17:47<1:55:49,  6.42s/it] 57%|█████▋    | 1419/2500 [17:53<1:52:08,  6.22s/it] 57%|█████▋    | 1420/2500 [18:01<1:58:53,  6.60s/it]                                                     {'loss': 2.0218, 'grad_norm': 1.6324065087355166, 'learning_rate': 1.969982225194864e-05, 'rewards/chosen': -0.8317164182662964, 'rewards/rejected': -2.675629138946533, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8439127206802368, 'logps/rejected': -6.689073085784912, 'logps/chosen': -2.0792911052703857, 'logits/rejected': -2.0795235633850098, 'logits/chosen': -2.915642261505127, 'nll_loss': 2.062190055847168, 'log_odds_ratio': -0.07670964300632477, 'log_odds_chosen': 4.7324395179748535, 'logps/chosen_prompt': -0.8459361791610718, 'logps/rejected_prompt': -1.0485248565673828, 'logits/chosen_prompt': -2.7813823223114014, 'logits/rejected_prompt': -2.7434256076812744, 'logps/chosen_both': -2.0637896060943604, 'logps/rejected_both': -6.608209133148193, 'epoch': 1.14}
 57%|█████▋    | 1420/2500 [18:01<1:58:53,  6.60s/it] 57%|█████▋    | 1421/2500 [18:07<1:56:33,  6.48s/it] 57%|█████▋    | 1422/2500 [18:12<1:50:43,  6.16s/it] 57%|█████▋    | 1423/2500 [18:18<1:50:00,  6.13s/it] 57%|█████▋    | 1424/2500 [18:24<1:49:29,  6.11s/it] 57%|█████▋    | 1425/2500 [18:31<1:51:51,  6.24s/it] 57%|█████▋    | 1426/2500 [18:37<1:52:32,  6.29s/it] 57%|█████▋    | 1427/2500 [18:44<1:52:06,  6.27s/it] 57%|█████▋    | 1428/2500 [18:50<1:50:42,  6.20s/it] 57%|█████▋    | 1429/2500 [18:56<1:50:02,  6.16s/it] 57%|█████▋    | 1430/2500 [19:02<1:48:37,  6.09s/it]                                                     {'loss': 2.1237, 'grad_norm': 0.20738972997356556, 'learning_rate': 1.9393230976265473e-05, 'rewards/chosen': -0.7408865094184875, 'rewards/rejected': -3.0098750591278076, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2689883708953857, 'logps/rejected': -7.524687767028809, 'logps/chosen': -1.852216362953186, 'logits/rejected': -1.9229800701141357, 'logits/chosen': -2.9260740280151367, 'nll_loss': 1.838269829750061, 'log_odds_ratio': -0.006005392409861088, 'log_odds_chosen': 5.855748176574707, 'logps/chosen_prompt': -0.843426525592804, 'logps/rejected_prompt': -1.0058763027191162, 'logits/chosen_prompt': -2.7461719512939453, 'logits/rejected_prompt': -2.729494333267212, 'logps/chosen_both': -1.8391883373260498, 'logps/rejected_both': -7.436516761779785, 'epoch': 1.14}
 57%|█████▋    | 1430/2500 [19:02<1:48:37,  6.09s/it] 57%|█████▋    | 1431/2500 [19:07<1:47:40,  6.04s/it] 57%|█████▋    | 1432/2500 [19:13<1:45:56,  5.95s/it] 57%|█████▋    | 1433/2500 [19:19<1:43:57,  5.85s/it] 57%|█████▋    | 1434/2500 [19:26<1:48:31,  6.11s/it] 57%|█████▋    | 1435/2500 [19:32<1:47:44,  6.07s/it] 57%|█████▋    | 1436/2500 [19:37<1:45:56,  5.97s/it] 57%|█████▋    | 1437/2500 [19:44<1:47:33,  6.07s/it] 58%|█████▊    | 1438/2500 [19:49<1:44:33,  5.91s/it] 58%|█████▊    | 1439/2500 [19:55<1:44:55,  5.93s/it] 58%|█████▊    | 1440/2500 [20:02<1:47:40,  6.09s/it]                                                     {'loss': 2.1693, 'grad_norm': 4.151128412015006, 'learning_rate': 1.908752507440689e-05, 'rewards/chosen': -0.7797169089317322, 'rewards/rejected': -2.5334482192993164, 'rewards/accuracies': 1.0, 'rewards/margins': 1.75373113155365, 'logps/rejected': -6.333620071411133, 'logps/chosen': -1.9492921829223633, 'logits/rejected': -2.076245069503784, 'logits/chosen': -2.9301161766052246, 'nll_loss': 1.931354284286499, 'log_odds_ratio': -0.1414000540971756, 'log_odds_chosen': 4.500386714935303, 'logps/chosen_prompt': -0.925390899181366, 'logps/rejected_prompt': -1.0695972442626953, 'logits/chosen_prompt': -2.765993118286133, 'logits/rejected_prompt': -2.744814395904541, 'logps/chosen_both': -1.9315818548202515, 'logps/rejected_both': -6.240424633026123, 'epoch': 1.15}
 58%|█████▊    | 1440/2500 [20:02<1:47:40,  6.09s/it] 58%|█████▊    | 1441/2500 [20:08<1:48:30,  6.15s/it] 58%|█████▊    | 1442/2500 [20:13<1:45:48,  6.00s/it] 58%|█████▊    | 1443/2500 [20:20<1:49:26,  6.21s/it] 58%|█████▊    | 1444/2500 [20:26<1:46:22,  6.04s/it] 58%|█████▊    | 1445/2500 [20:32<1:49:25,  6.22s/it] 58%|█████▊    | 1446/2500 [20:39<1:48:15,  6.16s/it] 58%|█████▊    | 1447/2500 [20:44<1:45:36,  6.02s/it] 58%|█████▊    | 1448/2500 [20:50<1:46:58,  6.10s/it] 58%|█████▊    | 1449/2500 [20:59<2:00:14,  6.86s/it] 58%|█████▊    | 1450/2500 [21:05<1:54:47,  6.56s/it]                                                     {'loss': 2.0581, 'grad_norm': 0.442041792594392, 'learning_rate': 1.8782752820878634e-05, 'rewards/chosen': -0.7614157199859619, 'rewards/rejected': -2.8114778995513916, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0500617027282715, 'logps/rejected': -7.028694152832031, 'logps/chosen': -1.9035392999649048, 'logits/rejected': -2.0423340797424316, 'logits/chosen': -2.9879214763641357, 'nll_loss': 1.8826156854629517, 'log_odds_ratio': -0.07156368345022202, 'log_odds_chosen': 5.279881000518799, 'logps/chosen_prompt': -0.8057926297187805, 'logps/rejected_prompt': -0.9666202664375305, 'logits/chosen_prompt': -2.758568286895752, 'logits/rejected_prompt': -2.7383270263671875, 'logps/chosen_both': -1.8826156854629517, 'logps/rejected_both': -6.9193220138549805, 'epoch': 1.16}
 58%|█████▊    | 1450/2500 [21:05<1:54:47,  6.56s/it] 58%|█████▊    | 1451/2500 [21:11<1:50:55,  6.34s/it] 58%|█████▊    | 1452/2500 [21:17<1:48:52,  6.23s/it] 58%|█████▊    | 1453/2500 [21:23<1:48:10,  6.20s/it] 58%|█████▊    | 1454/2500 [21:29<1:49:35,  6.29s/it] 58%|█████▊    | 1455/2500 [21:36<1:51:16,  6.39s/it] 58%|█████▊    | 1456/2500 [21:42<1:49:47,  6.31s/it] 58%|█████▊    | 1457/2500 [21:50<1:58:57,  6.84s/it] 58%|█████▊    | 1458/2500 [21:56<1:54:44,  6.61s/it] 58%|█████▊    | 1459/2500 [22:03<1:55:27,  6.65s/it] 58%|█████▊    | 1460/2500 [22:10<1:54:32,  6.61s/it]                                                     {'loss': 2.0741, 'grad_norm': 0.18417095330907962, 'learning_rate': 1.8478962342752583e-05, 'rewards/chosen': -0.8098316192626953, 'rewards/rejected': -2.576881170272827, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7670495510101318, 'logps/rejected': -6.442202568054199, 'logps/chosen': -2.0245792865753174, 'logits/rejected': -2.149646282196045, 'logits/chosen': -2.94092059135437, 'nll_loss': 2.0040090084075928, 'log_odds_ratio': -0.14014403522014618, 'log_odds_chosen': 4.545602798461914, 'logps/chosen_prompt': -0.7753245234489441, 'logps/rejected_prompt': -0.9454455375671387, 'logits/chosen_prompt': -2.770637035369873, 'logits/rejected_prompt': -2.7359559535980225, 'logps/chosen_both': -2.0046844482421875, 'logps/rejected_both': -6.352278709411621, 'epoch': 1.17}
 58%|█████▊    | 1460/2500 [22:10<1:54:32,  6.61s/it] 58%|█████▊    | 1461/2500 [22:16<1:53:20,  6.54s/it] 58%|█████▊    | 1462/2500 [22:22<1:50:54,  6.41s/it] 59%|█████▊    | 1463/2500 [22:28<1:50:27,  6.39s/it] 59%|█████▊    | 1464/2500 [22:34<1:47:07,  6.20s/it] 59%|█████▊    | 1465/2500 [22:40<1:46:32,  6.18s/it] 59%|█████▊    | 1466/2500 [22:46<1:46:28,  6.18s/it] 59%|█████▊    | 1467/2500 [22:53<1:49:14,  6.34s/it] 59%|█████▊    | 1468/2500 [22:59<1:46:10,  6.17s/it] 59%|█████▉    | 1469/2500 [23:05<1:44:46,  6.10s/it] 59%|█████▉    | 1470/2500 [23:11<1:44:48,  6.11s/it]                                                     {'loss': 2.0336, 'grad_norm': 1.7624366585607982, 'learning_rate': 1.817620161206687e-05, 'rewards/chosen': -0.7846772074699402, 'rewards/rejected': -2.408952236175537, 'rewards/accuracies': 1.0, 'rewards/margins': 1.6242752075195312, 'logps/rejected': -6.02238130569458, 'logps/chosen': -1.9616930484771729, 'logits/rejected': -2.1951212882995605, 'logits/chosen': -2.987746238708496, 'nll_loss': 1.9472782611846924, 'log_odds_ratio': -0.14303788542747498, 'log_odds_chosen': 4.18099308013916, 'logps/chosen_prompt': -0.8637250065803528, 'logps/rejected_prompt': -0.917345404624939, 'logits/chosen_prompt': -2.788262128829956, 'logits/rejected_prompt': -2.749626874923706, 'logps/chosen_both': -1.948093056678772, 'logps/rejected_both': -5.9546799659729, 'epoch': 1.18}
 59%|█████▉    | 1470/2500 [23:11<1:44:48,  6.11s/it] 59%|█████▉    | 1471/2500 [23:17<1:45:06,  6.13s/it] 59%|█████▉    | 1472/2500 [23:25<1:52:01,  6.54s/it] 59%|█████▉    | 1473/2500 [23:31<1:49:42,  6.41s/it] 59%|█████▉    | 1474/2500 [23:39<1:59:17,  6.98s/it] 59%|█████▉    | 1475/2500 [23:46<1:57:14,  6.86s/it] 59%|█████▉    | 1476/2500 [23:51<1:48:46,  6.37s/it] 59%|█████▉    | 1477/2500 [23:57<1:46:16,  6.23s/it] 59%|█████▉    | 1478/2500 [24:03<1:47:20,  6.30s/it] 59%|█████▉    | 1479/2500 [24:09<1:45:18,  6.19s/it] 59%|█████▉    | 1480/2500 [24:15<1:42:57,  6.06s/it]                                                     {'loss': 2.0067, 'grad_norm': 1.8805483926237532, 'learning_rate': 1.7874518438250597e-05, 'rewards/chosen': -0.7804209589958191, 'rewards/rejected': -2.711121082305908, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9306999444961548, 'logps/rejected': -6.777802467346191, 'logps/chosen': -1.9510523080825806, 'logits/rejected': -2.0654962062835693, 'logits/chosen': -2.9823737144470215, 'nll_loss': 1.9351886510849, 'log_odds_ratio': -0.07782623916864395, 'log_odds_chosen': 4.966540336608887, 'logps/chosen_prompt': -0.9023610353469849, 'logps/rejected_prompt': -0.9445146322250366, 'logits/chosen_prompt': -2.743725299835205, 'logits/rejected_prompt': -2.7214999198913574, 'logps/chosen_both': -1.9356558322906494, 'logps/rejected_both': -6.689598083496094, 'epoch': 1.18}
 59%|█████▉    | 1480/2500 [24:15<1:42:57,  6.06s/it] 59%|█████▉    | 1481/2500 [24:22<1:46:12,  6.25s/it] 59%|█████▉    | 1482/2500 [24:29<1:48:56,  6.42s/it] 59%|█████▉    | 1483/2500 [24:34<1:45:14,  6.21s/it] 59%|█████▉    | 1484/2500 [24:40<1:41:33,  6.00s/it] 59%|█████▉    | 1485/2500 [24:47<1:50:17,  6.52s/it] 59%|█████▉    | 1486/2500 [24:53<1:45:24,  6.24s/it] 59%|█████▉    | 1487/2500 [24:59<1:43:15,  6.12s/it] 60%|█████▉    | 1488/2500 [25:05<1:43:51,  6.16s/it] 60%|█████▉    | 1489/2500 [25:11<1:43:09,  6.12s/it] 60%|█████▉    | 1490/2500 [25:17<1:39:52,  5.93s/it]                                                     {'loss': 2.0123, 'grad_norm': 14.523314675478927, 'learning_rate': 1.7573960460574133e-05, 'rewards/chosen': -0.9132965803146362, 'rewards/rejected': -2.963430643081665, 'rewards/accuracies': 1.0, 'rewards/margins': 2.0501339435577393, 'logps/rejected': -7.408576011657715, 'logps/chosen': -2.2832417488098145, 'logits/rejected': -1.9658348560333252, 'logits/chosen': -2.924696683883667, 'nll_loss': 2.2554874420166016, 'log_odds_ratio': -0.012707007117569447, 'log_odds_chosen': 5.248503684997559, 'logps/chosen_prompt': -0.8842342495918274, 'logps/rejected_prompt': -1.0210704803466797, 'logits/chosen_prompt': -2.7780261039733887, 'logits/rejected_prompt': -2.744107723236084, 'logps/chosen_both': -2.2554874420166016, 'logps/rejected_both': -7.289267539978027, 'epoch': 1.19}
 60%|█████▉    | 1490/2500 [25:17<1:39:52,  5.93s/it] 60%|█████▉    | 1491/2500 [25:23<1:39:39,  5.93s/it] 60%|█████▉    | 1492/2500 [25:29<1:39:52,  5.95s/it] 60%|█████▉    | 1493/2500 [25:34<1:38:50,  5.89s/it] 60%|█████▉    | 1494/2500 [25:40<1:37:24,  5.81s/it] 60%|█████▉    | 1495/2500 [25:46<1:37:11,  5.80s/it] 60%|█████▉    | 1496/2500 [25:51<1:34:55,  5.67s/it] 60%|█████▉    | 1497/2500 [25:57<1:37:05,  5.81s/it] 60%|█████▉    | 1498/2500 [26:02<1:32:49,  5.56s/it] 60%|█████▉    | 1499/2500 [26:08<1:33:00,  5.58s/it] 60%|██████    | 1500/2500 [26:18<1:57:23,  7.04s/it]                                                     {'loss': 2.1732, 'grad_norm': 0.277062993898632, 'learning_rate': 1.7274575140626318e-05, 'rewards/chosen': -0.8848344683647156, 'rewards/rejected': -2.9834837913513184, 'rewards/accuracies': 1.0, 'rewards/margins': 2.098649501800537, 'logps/rejected': -7.458708763122559, 'logps/chosen': -2.2120862007141113, 'logits/rejected': -1.94744873046875, 'logits/chosen': -2.955223560333252, 'nll_loss': 2.187230348587036, 'log_odds_ratio': -0.01817898079752922, 'log_odds_chosen': 5.376677513122559, 'logps/chosen_prompt': -0.8035541772842407, 'logps/rejected_prompt': -1.0069081783294678, 'logits/chosen_prompt': -2.768512010574341, 'logits/rejected_prompt': -2.740633487701416, 'logps/chosen_both': -2.1878058910369873, 'logps/rejected_both': -7.351090908050537, 'epoch': 1.2}
 60%|██████    | 1500/2500 [26:18<1:57:23,  7.04s/it] 60%|██████    | 1501/2500 [26:24<1:49:56,  6.60s/it] 60%|██████    | 1502/2500 [26:30<1:48:02,  6.50s/it] 60%|██████    | 1503/2500 [26:37<1:48:21,  6.52s/it] 60%|██████    | 1504/2500 [26:42<1:44:29,  6.29s/it] 60%|██████    | 1505/2500 [26:49<1:43:55,  6.27s/it] 60%|██████    | 1506/2500 [26:55<1:44:51,  6.33s/it] 60%|██████    | 1507/2500 [27:01<1:43:11,  6.24s/it] 60%|██████    | 1508/2500 [27:08<1:47:16,  6.49s/it] 60%|██████    | 1509/2500 [27:14<1:45:09,  6.37s/it] 60%|██████    | 1510/2500 [27:20<1:43:53,  6.30s/it]                                                     {'loss': 2.0261, 'grad_norm': 0.20754612400548994, 'learning_rate': 1.6976409754819767e-05, 'rewards/chosen': -0.8276768922805786, 'rewards/rejected': -2.279963970184326, 'rewards/accuracies': 1.0, 'rewards/margins': 1.452286958694458, 'logps/rejected': -5.699909210205078, 'logps/chosen': -2.0691921710968018, 'logits/rejected': -2.266988515853882, 'logits/chosen': -2.9268240928649902, 'nll_loss': 2.04994797706604, 'log_odds_ratio': -0.23905882239341736, 'log_odds_chosen': 3.7244980335235596, 'logps/chosen_prompt': -0.8410364985466003, 'logps/rejected_prompt': -1.0303503274917603, 'logits/chosen_prompt': -2.7582294940948486, 'logits/rejected_prompt': -2.7572779655456543, 'logps/chosen_both': -2.0506865978240967, 'logps/rejected_both': -5.632321834564209, 'epoch': 1.21}
 60%|██████    | 1510/2500 [27:20<1:43:53,  6.30s/it] 60%|██████    | 1511/2500 [27:26<1:42:12,  6.20s/it] 60%|██████    | 1512/2500 [27:33<1:42:53,  6.25s/it] 61%|██████    | 1513/2500 [27:39<1:42:44,  6.25s/it] 61%|██████    | 1514/2500 [27:45<1:41:43,  6.19s/it] 61%|██████    | 1515/2500 [27:52<1:44:45,  6.38s/it] 61%|██████    | 1516/2500 [27:58<1:41:37,  6.20s/it] 61%|██████    | 1517/2500 [28:09<2:08:51,  7.87s/it] 61%|██████    | 1518/2500 [28:16<1:59:57,  7.33s/it] 61%|██████    | 1519/2500 [28:21<1:51:37,  6.83s/it] 61%|██████    | 1520/2500 [28:27<1:45:21,  6.45s/it]                                                     {'loss': 2.0148, 'grad_norm': 0.17969512036733956, 'learning_rate': 1.6679511386925337e-05, 'rewards/chosen': -0.785891056060791, 'rewards/rejected': -2.6121106147766113, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8262193202972412, 'logps/rejected': -6.530276298522949, 'logps/chosen': -1.9647274017333984, 'logits/rejected': -2.0694189071655273, 'logits/chosen': -2.9122989177703857, 'nll_loss': 1.9477348327636719, 'log_odds_ratio': -0.14112287759780884, 'log_odds_chosen': 4.6866865158081055, 'logps/chosen_prompt': -0.864264190196991, 'logps/rejected_prompt': -1.0295734405517578, 'logits/chosen_prompt': -2.6968207359313965, 'logits/rejected_prompt': -2.6890578269958496, 'logps/chosen_both': -1.9483833312988281, 'logps/rejected_both': -6.451663017272949, 'epoch': 1.22}
 61%|██████    | 1520/2500 [28:27<1:45:21,  6.45s/it] 61%|██████    | 1521/2500 [28:33<1:42:21,  6.27s/it] 61%|██████    | 1522/2500 [28:40<1:45:34,  6.48s/it] 61%|██████    | 1523/2500 [28:46<1:44:10,  6.40s/it] 61%|██████    | 1524/2500 [28:52<1:43:11,  6.34s/it] 61%|██████    | 1525/2500 [28:58<1:39:11,  6.10s/it] 61%|██████    | 1526/2500 [29:03<1:37:30,  6.01s/it] 61%|██████    | 1527/2500 [29:10<1:38:43,  6.09s/it] 61%|██████    | 1528/2500 [29:16<1:39:32,  6.14s/it] 61%|██████    | 1529/2500 [29:22<1:38:05,  6.06s/it] 61%|██████    | 1530/2500 [29:27<1:36:04,  5.94s/it]                                                     {'loss': 2.0805, 'grad_norm': 0.7407899905799475, 'learning_rate': 1.6383926920637077e-05, 'rewards/chosen': -0.8014545440673828, 'rewards/rejected': -3.0925307273864746, 'rewards/accuracies': 1.0, 'rewards/margins': 2.291076183319092, 'logps/rejected': -7.731326103210449, 'logps/chosen': -2.003636360168457, 'logits/rejected': -1.8194621801376343, 'logits/chosen': -2.938737392425537, 'nll_loss': 1.9854434728622437, 'log_odds_ratio': -0.007840188220143318, 'log_odds_chosen': 5.874896049499512, 'logps/chosen_prompt': -0.8189128637313843, 'logps/rejected_prompt': -0.9349613189697266, 'logits/chosen_prompt': -2.694021701812744, 'logits/rejected_prompt': -2.678117513656616, 'logps/chosen_both': -1.9862537384033203, 'logps/rejected_both': -7.625927925109863, 'epoch': 1.22}
 61%|██████    | 1530/2500 [29:27<1:36:04,  5.94s/it] 61%|██████    | 1531/2500 [29:33<1:35:17,  5.90s/it] 61%|██████▏   | 1532/2500 [29:40<1:39:06,  6.14s/it] 61%|██████▏   | 1533/2500 [29:46<1:38:33,  6.12s/it] 61%|██████▏   | 1534/2500 [29:52<1:38:22,  6.11s/it] 61%|██████▏   | 1535/2500 [29:58<1:39:46,  6.20s/it] 61%|██████▏   | 1536/2500 [30:06<1:48:12,  6.73s/it] 61%|██████▏   | 1537/2500 [30:12<1:43:46,  6.47s/it] 62%|██████▏   | 1538/2500 [30:18<1:39:26,  6.20s/it] 62%|██████▏   | 1539/2500 [30:24<1:38:01,  6.12s/it] 62%|██████▏   | 1540/2500 [30:29<1:35:35,  5.97s/it]                                                     {'loss': 2.087, 'grad_norm': 0.19578506605860266, 'learning_rate': 1.6089703032168733e-05, 'rewards/chosen': -0.848910927772522, 'rewards/rejected': -2.561509370803833, 'rewards/accuracies': 1.0, 'rewards/margins': 1.712598204612732, 'logps/rejected': -6.403773307800293, 'logps/chosen': -2.12227725982666, 'logits/rejected': -2.049774646759033, 'logits/chosen': -2.948899030685425, 'nll_loss': 2.098493814468384, 'log_odds_ratio': -0.1184636577963829, 'log_odds_chosen': 4.391539096832275, 'logps/chosen_prompt': -0.9418958425521851, 'logps/rejected_prompt': -1.1320421695709229, 'logits/chosen_prompt': -2.7112746238708496, 'logits/rejected_prompt': -2.7076594829559326, 'logps/chosen_both': -2.0991575717926025, 'logps/rejected_both': -6.301241397857666, 'epoch': 1.23}
 62%|██████▏   | 1540/2500 [30:29<1:35:35,  5.97s/it] 62%|██████▏   | 1541/2500 [30:35<1:35:33,  5.98s/it] 62%|██████▏   | 1542/2500 [30:41<1:35:17,  5.97s/it] 62%|██████▏   | 1543/2500 [30:47<1:34:20,  5.91s/it] 62%|██████▏   | 1544/2500 [30:53<1:34:03,  5.90s/it] 62%|██████▏   | 1545/2500 [30:59<1:33:23,  5.87s/it] 62%|██████▏   | 1546/2500 [31:05<1:37:05,  6.11s/it] 62%|██████▏   | 1547/2500 [31:11<1:36:24,  6.07s/it] 62%|██████▏   | 1548/2500 [31:18<1:36:33,  6.09s/it] 62%|██████▏   | 1549/2500 [31:23<1:33:33,  5.90s/it] 62%|██████▏   | 1550/2500 [31:29<1:33:41,  5.92s/it]                                                     {'loss': 2.1279, 'grad_norm': 0.20740065510227848, 'learning_rate': 1.5796886182883053e-05, 'rewards/chosen': -0.7741274237632751, 'rewards/rejected': -2.7525453567504883, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9784181118011475, 'logps/rejected': -6.8813629150390625, 'logps/chosen': -1.9353185892105103, 'logits/rejected': -1.9331802129745483, 'logits/chosen': -2.871703624725342, 'nll_loss': 1.9155601263046265, 'log_odds_ratio': -0.07555343955755234, 'log_odds_chosen': 5.1061577796936035, 'logps/chosen_prompt': -0.7967368364334106, 'logps/rejected_prompt': -0.9483763575553894, 'logits/chosen_prompt': -2.7193095684051514, 'logits/rejected_prompt': -2.710068941116333, 'logps/chosen_both': -1.9160022735595703, 'logps/rejected_both': -6.787671089172363, 'epoch': 1.24}
 62%|██████▏   | 1550/2500 [31:29<1:33:41,  5.92s/it] 62%|██████▏   | 1551/2500 [31:35<1:32:09,  5.83s/it] 62%|██████▏   | 1552/2500 [31:41<1:33:37,  5.93s/it] 62%|██████▏   | 1553/2500 [31:47<1:33:30,  5.92s/it] 62%|██████▏   | 1554/2500 [31:53<1:35:44,  6.07s/it] 62%|██████▏   | 1555/2500 [31:59<1:33:42,  5.95s/it] 62%|██████▏   | 1556/2500 [32:05<1:33:52,  5.97s/it] 62%|██████▏   | 1557/2500 [32:10<1:32:23,  5.88s/it] 62%|██████▏   | 1558/2500 [32:17<1:33:04,  5.93s/it] 62%|██████▏   | 1559/2500 [32:22<1:31:31,  5.84s/it] 62%|██████▏   | 1560/2500 [32:29<1:34:19,  6.02s/it]                                                     {'loss': 2.0058, 'grad_norm': 13.110037682250107, 'learning_rate': 1.5505522611954975e-05, 'rewards/chosen': -0.7661730647087097, 'rewards/rejected': -2.674041986465454, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9078689813613892, 'logps/rejected': -6.6851043701171875, 'logps/chosen': -1.9154326915740967, 'logits/rejected': -1.9702670574188232, 'logits/chosen': -3.018805980682373, 'nll_loss': 1.8969436883926392, 'log_odds_ratio': -0.09565360844135284, 'log_odds_chosen': 4.9078474044799805, 'logps/chosen_prompt': -0.8419493436813354, 'logps/rejected_prompt': -1.0201938152313232, 'logits/chosen_prompt': -2.7189230918884277, 'logits/rejected_prompt': -2.7037787437438965, 'logps/chosen_both': -1.8979841470718384, 'logps/rejected_both': -6.601175785064697, 'epoch': 1.25}
 62%|██████▏   | 1560/2500 [32:29<1:34:19,  6.02s/it] 62%|██████▏   | 1561/2500 [32:35<1:33:46,  5.99s/it] 62%|██████▏   | 1562/2500 [32:40<1:33:11,  5.96s/it] 63%|██████▎   | 1563/2500 [32:47<1:34:14,  6.04s/it] 63%|██████▎   | 1564/2500 [32:52<1:32:01,  5.90s/it] 63%|██████▎   | 1565/2500 [32:58<1:31:51,  5.89s/it] 63%|██████▎   | 1566/2500 [33:04<1:31:13,  5.86s/it] 63%|██████▎   | 1567/2500 [33:10<1:31:38,  5.89s/it] 63%|██████▎   | 1568/2500 [33:18<1:43:56,  6.69s/it] 63%|██████▎   | 1569/2500 [33:24<1:38:25,  6.34s/it] 63%|██████▎   | 1570/2500 [33:32<1:44:31,  6.74s/it]                                                     {'loss': 1.9511, 'grad_norm': 0.19039225420008823, 'learning_rate': 1.521565832906994e-05, 'rewards/chosen': -0.7113676071166992, 'rewards/rejected': -2.813021421432495, 'rewards/accuracies': 1.0, 'rewards/margins': 2.101653575897217, 'logps/rejected': -7.032553672790527, 'logps/chosen': -1.7784191370010376, 'logits/rejected': -1.875065565109253, 'logits/chosen': -2.970283269882202, 'nll_loss': 1.7632510662078857, 'log_odds_ratio': -0.07205988466739655, 'log_odds_chosen': 5.449731349945068, 'logps/chosen_prompt': -0.7146488428115845, 'logps/rejected_prompt': -0.9977965354919434, 'logits/chosen_prompt': -2.719583034515381, 'logits/rejected_prompt': -2.699563503265381, 'logps/chosen_both': -1.7646013498306274, 'logps/rejected_both': -6.949163913726807, 'epoch': 1.26}
 63%|██████▎   | 1570/2500 [33:32<1:44:31,  6.74s/it] 63%|██████▎   | 1571/2500 [33:37<1:39:39,  6.44s/it] 63%|██████▎   | 1572/2500 [33:43<1:36:53,  6.27s/it] 63%|██████▎   | 1573/2500 [33:51<1:41:52,  6.59s/it] 63%|██████▎   | 1574/2500 [33:57<1:40:25,  6.51s/it] 63%|██████▎   | 1575/2500 [34:04<1:43:53,  6.74s/it] 63%|██████▎   | 1576/2500 [34:11<1:43:32,  6.72s/it] 63%|██████▎   | 1577/2500 [34:17<1:39:44,  6.48s/it] 63%|██████▎   | 1578/2500 [34:23<1:37:56,  6.37s/it] 63%|██████▎   | 1579/2500 [34:29<1:37:35,  6.36s/it] 63%|██████▎   | 1580/2500 [34:35<1:35:32,  6.23s/it]                                                     {'loss': 2.0674, 'grad_norm': 0.22308753091177122, 'learning_rate': 1.4927339107158437e-05, 'rewards/chosen': -0.7960368990898132, 'rewards/rejected': -2.5165648460388184, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7205278873443604, 'logps/rejected': -6.291411399841309, 'logps/chosen': -1.9900922775268555, 'logits/rejected': -2.033951997756958, 'logits/chosen': -2.9278159141540527, 'nll_loss': 1.9725139141082764, 'log_odds_ratio': -0.18397700786590576, 'log_odds_chosen': 4.40993595123291, 'logps/chosen_prompt': -0.7823570966720581, 'logps/rejected_prompt': -1.0574694871902466, 'logits/chosen_prompt': -2.71443247795105, 'logits/rejected_prompt': -2.6978702545166016, 'logps/chosen_both': -1.973472237586975, 'logps/rejected_both': -6.212893486022949, 'epoch': 1.26}
 63%|██████▎   | 1580/2500 [34:35<1:35:32,  6.23s/it] 63%|██████▎   | 1581/2500 [34:41<1:32:55,  6.07s/it] 63%|██████▎   | 1582/2500 [34:46<1:31:13,  5.96s/it] 63%|██████▎   | 1583/2500 [34:52<1:29:54,  5.88s/it] 63%|██████▎   | 1584/2500 [34:59<1:33:30,  6.13s/it] 63%|██████▎   | 1585/2500 [35:04<1:29:27,  5.87s/it] 63%|██████▎   | 1586/2500 [35:10<1:29:55,  5.90s/it] 63%|██████▎   | 1587/2500 [35:16<1:30:08,  5.92s/it] 64%|██████▎   | 1588/2500 [35:22<1:28:28,  5.82s/it] 64%|██████▎   | 1589/2500 [35:28<1:29:06,  5.87s/it] 64%|██████▎   | 1590/2500 [35:34<1:31:54,  6.06s/it]                                                     {'loss': 2.041, 'grad_norm': 0.19054534277036075, 'learning_rate': 1.4640610475167898e-05, 'rewards/chosen': -0.743659257888794, 'rewards/rejected': -2.6919004917144775, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9482409954071045, 'logps/rejected': -6.729750633239746, 'logps/chosen': -1.8591480255126953, 'logits/rejected': -1.9672138690948486, 'logits/chosen': -2.964674472808838, 'nll_loss': 1.8412290811538696, 'log_odds_ratio': -0.08381481468677521, 'log_odds_chosen': 5.06654167175293, 'logps/chosen_prompt': -0.7734343409538269, 'logps/rejected_prompt': -0.9831528663635254, 'logits/chosen_prompt': -2.7386646270751953, 'logits/rejected_prompt': -2.696291923522949, 'logps/chosen_both': -1.8420082330703735, 'logps/rejected_both': -6.6285834312438965, 'epoch': 1.27}
 64%|██████▎   | 1590/2500 [35:34<1:31:54,  6.06s/it] 64%|██████▎   | 1591/2500 [35:40<1:31:07,  6.02s/it] 64%|██████▎   | 1592/2500 [35:46<1:30:56,  6.01s/it] 64%|██████▎   | 1593/2500 [35:52<1:30:57,  6.02s/it] 64%|██████▍   | 1594/2500 [35:58<1:32:10,  6.10s/it] 64%|██████▍   | 1595/2500 [36:05<1:34:27,  6.26s/it] 64%|██████▍   | 1596/2500 [36:11<1:33:10,  6.18s/it] 64%|██████▍   | 1597/2500 [36:17<1:31:21,  6.07s/it] 64%|██████▍   | 1598/2500 [36:23<1:32:01,  6.12s/it] 64%|██████▍   | 1599/2500 [36:29<1:30:23,  6.02s/it] 64%|██████▍   | 1600/2500 [36:35<1:30:40,  6.05s/it]                                                     {'loss': 1.9933, 'grad_norm': 0.2650702526307155, 'learning_rate': 1.4355517710873184e-05, 'rewards/chosen': -0.7385538220405579, 'rewards/rejected': -2.885633945465088, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1470799446105957, 'logps/rejected': -7.214084625244141, 'logps/chosen': -1.8463846445083618, 'logits/rejected': -1.8671737909317017, 'logits/chosen': -2.9555344581604004, 'nll_loss': 1.8324296474456787, 'log_odds_ratio': -0.006100042723119259, 'log_odds_chosen': 5.553177356719971, 'logps/chosen_prompt': -0.7500739693641663, 'logps/rejected_prompt': -0.9253940582275391, 'logits/chosen_prompt': -2.7369465827941895, 'logits/rejected_prompt': -2.719994068145752, 'logps/chosen_both': -1.8328708410263062, 'logps/rejected_both': -7.131778717041016, 'epoch': 1.28}
 64%|██████▍   | 1600/2500 [36:35<1:30:40,  6.05s/it] 64%|██████▍   | 1601/2500 [36:40<1:26:47,  5.79s/it] 64%|██████▍   | 1602/2500 [36:46<1:28:46,  5.93s/it] 64%|██████▍   | 1603/2500 [36:53<1:29:21,  5.98s/it] 64%|██████▍   | 1604/2500 [36:58<1:26:30,  5.79s/it] 64%|██████▍   | 1605/2500 [37:04<1:26:16,  5.78s/it] 64%|██████▍   | 1606/2500 [37:10<1:27:29,  5.87s/it] 64%|██████▍   | 1607/2500 [37:16<1:28:34,  5.95s/it] 64%|██████▍   | 1608/2500 [37:22<1:27:51,  5.91s/it] 64%|██████▍   | 1609/2500 [37:29<1:32:22,  6.22s/it] 64%|██████▍   | 1610/2500 [37:34<1:30:20,  6.09s/it]                                                     {'loss': 2.0366, 'grad_norm': 0.2142278396859269, 'learning_rate': 1.4072105833726684e-05, 'rewards/chosen': -0.7462930679321289, 'rewards/rejected': -3.114245891571045, 'rewards/accuracies': 1.0, 'rewards/margins': 2.367952585220337, 'logps/rejected': -7.785614967346191, 'logps/chosen': -1.8657327890396118, 'logits/rejected': -1.7227647304534912, 'logits/chosen': -3.008474826812744, 'nll_loss': 1.8474807739257812, 'log_odds_ratio': -0.007168472744524479, 'log_odds_chosen': 6.093027591705322, 'logps/chosen_prompt': -0.8973295092582703, 'logps/rejected_prompt': -0.9875823259353638, 'logits/chosen_prompt': -2.6898322105407715, 'logits/rejected_prompt': -2.6638293266296387, 'logps/chosen_both': -1.847730278968811, 'logps/rejected_both': -7.6571807861328125, 'epoch': 1.29}
 64%|██████▍   | 1610/2500 [37:34<1:30:20,  6.09s/it] 64%|██████▍   | 1611/2500 [37:40<1:26:59,  5.87s/it] 64%|██████▍   | 1612/2500 [37:46<1:29:52,  6.07s/it] 65%|██████▍   | 1613/2500 [37:52<1:28:00,  5.95s/it] 65%|██████▍   | 1614/2500 [37:58<1:30:07,  6.10s/it] 65%|██████▍   | 1615/2500 [38:04<1:27:42,  5.95s/it] 65%|██████▍   | 1616/2500 [38:14<1:43:12,  7.01s/it] 65%|██████▍   | 1617/2500 [38:19<1:36:52,  6.58s/it] 65%|██████▍   | 1618/2500 [38:25<1:34:34,  6.43s/it] 65%|██████▍   | 1619/2500 [38:33<1:42:07,  6.96s/it] 65%|██████▍   | 1620/2500 [38:39<1:37:23,  6.64s/it]                                                     {'loss': 2.0706, 'grad_norm': 0.27315985615525146, 'learning_rate': 1.3790419597749199e-05, 'rewards/chosen': -0.8151528239250183, 'rewards/rejected': -3.3108534812927246, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4957010746002197, 'logps/rejected': -8.277134895324707, 'logps/chosen': -2.037881851196289, 'logits/rejected': -1.5245832204818726, 'logits/chosen': -2.925840377807617, 'nll_loss': 2.021907329559326, 'log_odds_ratio': -0.0018111132085323334, 'log_odds_chosen': 6.385594844818115, 'logps/chosen_prompt': -0.848060131072998, 'logps/rejected_prompt': -1.081843614578247, 'logits/chosen_prompt': -2.691370964050293, 'logits/rejected_prompt': -2.667586088180542, 'logps/chosen_both': -2.023228406906128, 'logps/rejected_both': -8.180235862731934, 'epoch': 1.3}
 65%|██████▍   | 1620/2500 [38:39<1:37:23,  6.64s/it] 65%|██████▍   | 1621/2500 [38:46<1:35:30,  6.52s/it] 65%|██████▍   | 1622/2500 [38:51<1:31:00,  6.22s/it] 65%|██████▍   | 1623/2500 [38:58<1:32:25,  6.32s/it] 65%|██████▍   | 1624/2500 [39:03<1:30:18,  6.19s/it] 65%|██████▌   | 1625/2500 [39:09<1:29:11,  6.12s/it] 65%|██████▌   | 1626/2500 [39:15<1:28:12,  6.06s/it] 65%|██████▌   | 1627/2500 [39:21<1:27:36,  6.02s/it] 65%|██████▌   | 1628/2500 [39:27<1:27:42,  6.04s/it] 65%|██████▌   | 1629/2500 [39:33<1:27:19,  6.02s/it] 65%|██████▌   | 1630/2500 [39:39<1:25:43,  5.91s/it]                                                     {'loss': 2.0195, 'grad_norm': 0.20024913489382712, 'learning_rate': 1.3510503484462805e-05, 'rewards/chosen': -0.8161776661872864, 'rewards/rejected': -2.964817523956299, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1486401557922363, 'logps/rejected': -7.412043571472168, 'logps/chosen': -2.0404438972473145, 'logits/rejected': -1.7067989110946655, 'logits/chosen': -2.9339845180511475, 'nll_loss': 2.0214381217956543, 'log_odds_ratio': -0.07163720577955246, 'log_odds_chosen': 5.494431495666504, 'logps/chosen_prompt': -0.8444884419441223, 'logps/rejected_prompt': -1.111812949180603, 'logits/chosen_prompt': -2.692061185836792, 'logits/rejected_prompt': -2.670522928237915, 'logps/chosen_both': -2.02243709564209, 'logps/rejected_both': -7.3062591552734375, 'epoch': 1.3}
 65%|██████▌   | 1630/2500 [39:39<1:25:43,  5.91s/it] 65%|██████▌   | 1631/2500 [39:45<1:25:07,  5.88s/it] 65%|██████▌   | 1632/2500 [39:50<1:24:14,  5.82s/it] 65%|██████▌   | 1633/2500 [39:56<1:24:45,  5.87s/it] 65%|██████▌   | 1634/2500 [40:02<1:22:46,  5.74s/it] 65%|██████▌   | 1635/2500 [40:07<1:20:45,  5.60s/it] 65%|██████▌   | 1636/2500 [40:13<1:23:00,  5.76s/it] 65%|██████▌   | 1637/2500 [40:19<1:22:06,  5.71s/it] 66%|██████▌   | 1638/2500 [40:25<1:21:49,  5.70s/it] 66%|██████▌   | 1639/2500 [40:30<1:22:21,  5.74s/it] 66%|██████▌   | 1640/2500 [40:37<1:26:01,  6.00s/it]                                                     {'loss': 2.0372, 'grad_norm': 0.18603812476824122, 'learning_rate': 1.3232401695866687e-05, 'rewards/chosen': -0.7777801752090454, 'rewards/rejected': -2.97725510597229, 'rewards/accuracies': 1.0, 'rewards/margins': 2.199474811553955, 'logps/rejected': -7.443137168884277, 'logps/chosen': -1.9444503784179688, 'logits/rejected': -1.721756935119629, 'logits/chosen': -2.982698440551758, 'nll_loss': 1.9237861633300781, 'log_odds_ratio': -0.019205983728170395, 'log_odds_chosen': 5.658219814300537, 'logps/chosen_prompt': -0.8289767503738403, 'logps/rejected_prompt': -0.9888274073600769, 'logits/chosen_prompt': -2.6906144618988037, 'logits/rejected_prompt': -2.6728127002716064, 'logps/chosen_both': -1.9243927001953125, 'logps/rejected_both': -7.325814247131348, 'epoch': 1.31}
 66%|██████▌   | 1640/2500 [40:37<1:26:01,  6.00s/it] 66%|██████▌   | 1641/2500 [40:43<1:25:29,  5.97s/it] 66%|██████▌   | 1642/2500 [40:49<1:27:43,  6.13s/it] 66%|██████▌   | 1643/2500 [40:56<1:30:47,  6.36s/it] 66%|██████▌   | 1644/2500 [41:02<1:29:06,  6.25s/it] 66%|██████▌   | 1645/2500 [41:09<1:30:22,  6.34s/it] 66%|██████▌   | 1646/2500 [41:14<1:26:44,  6.09s/it] 66%|██████▌   | 1647/2500 [41:20<1:24:45,  5.96s/it] 66%|██████▌   | 1648/2500 [41:26<1:23:16,  5.86s/it] 66%|██████▌   | 1649/2500 [41:32<1:25:00,  5.99s/it] 66%|██████▌   | 1650/2500 [41:38<1:24:59,  6.00s/it]                                                     {'loss': 2.0099, 'grad_norm': 0.45109258122051765, 'learning_rate': 1.2956158147457115e-05, 'rewards/chosen': -0.7946547269821167, 'rewards/rejected': -3.0018954277038574, 'rewards/accuracies': 1.0, 'rewards/margins': 2.207240581512451, 'logps/rejected': -7.504737854003906, 'logps/chosen': -1.9866368770599365, 'logits/rejected': -1.6645431518554688, 'logits/chosen': -2.969813346862793, 'nll_loss': 1.9644935131072998, 'log_odds_ratio': -0.07421554625034332, 'log_odds_chosen': 5.656313419342041, 'logps/chosen_prompt': -0.7482956647872925, 'logps/rejected_prompt': -1.0507978200912476, 'logits/chosen_prompt': -2.706571340560913, 'logits/rejected_prompt': -2.6797471046447754, 'logps/chosen_both': -1.9651542901992798, 'logps/rejected_both': -7.392207145690918, 'epoch': 1.32}
 66%|██████▌   | 1650/2500 [41:38<1:24:59,  6.00s/it] 66%|██████▌   | 1651/2500 [41:44<1:26:20,  6.10s/it] 66%|██████▌   | 1652/2500 [41:50<1:25:41,  6.06s/it] 66%|██████▌   | 1653/2500 [41:56<1:24:11,  5.96s/it] 66%|██████▌   | 1654/2500 [42:01<1:21:50,  5.80s/it] 66%|██████▌   | 1655/2500 [42:07<1:20:52,  5.74s/it] 66%|██████▌   | 1656/2500 [42:13<1:20:04,  5.69s/it] 66%|██████▋   | 1657/2500 [42:18<1:20:38,  5.74s/it] 66%|██████▋   | 1658/2500 [42:25<1:21:49,  5.83s/it] 66%|██████▋   | 1659/2500 [42:31<1:23:01,  5.92s/it] 66%|██████▋   | 1660/2500 [42:38<1:27:06,  6.22s/it]                                                     {'loss': 2.0032, 'grad_norm': 0.25118993768318776, 'learning_rate': 1.2681816461292715e-05, 'rewards/chosen': -0.7900967597961426, 'rewards/rejected': -3.075894832611084, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2857978343963623, 'logps/rejected': -7.689736843109131, 'logps/chosen': -1.9752418994903564, 'logits/rejected': -1.6160228252410889, 'logits/chosen': -2.9932761192321777, 'nll_loss': 1.9573304653167725, 'log_odds_ratio': -0.07050176709890366, 'log_odds_chosen': 5.856919765472412, 'logps/chosen_prompt': -0.7520488500595093, 'logps/rejected_prompt': -0.9965227246284485, 'logits/chosen_prompt': -2.7052884101867676, 'logits/rejected_prompt': -2.6759018898010254, 'logps/chosen_both': -1.9577947854995728, 'logps/rejected_both': -7.599605560302734, 'epoch': 1.33}
 66%|██████▋   | 1660/2500 [42:38<1:27:06,  6.22s/it] 66%|██████▋   | 1661/2500 [42:43<1:24:46,  6.06s/it] 66%|██████▋   | 1662/2500 [42:49<1:24:26,  6.05s/it] 67%|██████▋   | 1663/2500 [42:55<1:22:58,  5.95s/it] 67%|██████▋   | 1664/2500 [43:00<1:18:09,  5.61s/it] 67%|██████▋   | 1665/2500 [43:06<1:21:38,  5.87s/it] 67%|██████▋   | 1666/2500 [43:12<1:21:59,  5.90s/it] 67%|██████▋   | 1667/2500 [43:18<1:21:40,  5.88s/it] 67%|██████▋   | 1668/2500 [43:24<1:21:00,  5.84s/it] 67%|██████▋   | 1669/2500 [43:29<1:18:45,  5.69s/it] 67%|██████▋   | 1670/2500 [43:35<1:19:27,  5.74s/it]                                                     {'loss': 2.1354, 'grad_norm': 0.3441403276596822, 'learning_rate': 1.2409419959105981e-05, 'rewards/chosen': -0.7803536653518677, 'rewards/rejected': -3.081026554107666, 'rewards/accuracies': 1.0, 'rewards/margins': 2.300672769546509, 'logps/rejected': -7.702565670013428, 'logps/chosen': -1.9508838653564453, 'logits/rejected': -1.6293513774871826, 'logits/chosen': -2.9116601943969727, 'nll_loss': 1.9342187643051147, 'log_odds_ratio': -0.07288520038127899, 'log_odds_chosen': 5.890207767486572, 'logps/chosen_prompt': -0.7790221571922302, 'logps/rejected_prompt': -1.0076009035110474, 'logits/chosen_prompt': -2.7063584327697754, 'logits/rejected_prompt': -2.6672801971435547, 'logps/chosen_both': -1.934664011001587, 'logps/rejected_both': -7.608944892883301, 'epoch': 1.34}
 67%|██████▋   | 1670/2500 [43:35<1:19:27,  5.74s/it] 67%|██████▋   | 1671/2500 [43:41<1:20:27,  5.82s/it] 67%|██████▋   | 1672/2500 [43:47<1:20:10,  5.81s/it] 67%|██████▋   | 1673/2500 [43:53<1:21:10,  5.89s/it] 67%|██████▋   | 1674/2500 [43:58<1:19:44,  5.79s/it] 67%|██████▋   | 1675/2500 [44:04<1:19:46,  5.80s/it] 67%|██████▋   | 1676/2500 [44:11<1:22:22,  6.00s/it] 67%|██████▋   | 1677/2500 [44:17<1:24:30,  6.16s/it] 67%|██████▋   | 1678/2500 [44:23<1:21:51,  5.97s/it] 67%|██████▋   | 1679/2500 [44:29<1:21:57,  5.99s/it] 67%|██████▋   | 1680/2500 [44:34<1:20:01,  5.86s/it]                                                     {'loss': 2.1211, 'grad_norm': 0.21680791358163498, 'learning_rate': 1.2139011655462337e-05, 'rewards/chosen': -0.8185635805130005, 'rewards/rejected': -3.0841593742370605, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2655956745147705, 'logps/rejected': -7.710398197174072, 'logps/chosen': -2.0464091300964355, 'logits/rejected': -1.5952856540679932, 'logits/chosen': -2.9453179836273193, 'nll_loss': 2.0271670818328857, 'log_odds_ratio': -0.07125348597764969, 'log_odds_chosen': 5.7955827713012695, 'logps/chosen_prompt': -0.8559902310371399, 'logps/rejected_prompt': -1.0296353101730347, 'logits/chosen_prompt': -2.7091875076293945, 'logits/rejected_prompt': -2.680628538131714, 'logps/chosen_both': -2.0279593467712402, 'logps/rejected_both': -7.605578422546387, 'epoch': 1.34}
 67%|██████▋   | 1680/2500 [44:34<1:20:01,  5.86s/it] 67%|██████▋   | 1681/2500 [44:40<1:20:11,  5.88s/it] 67%|██████▋   | 1682/2500 [44:46<1:17:39,  5.70s/it] 67%|██████▋   | 1683/2500 [44:52<1:18:56,  5.80s/it] 67%|██████▋   | 1684/2500 [44:57<1:17:32,  5.70s/it] 67%|██████▋   | 1685/2500 [45:03<1:19:30,  5.85s/it] 67%|██████▋   | 1686/2500 [45:10<1:21:40,  6.02s/it] 67%|██████▋   | 1687/2500 [45:16<1:22:31,  6.09s/it] 68%|██████▊   | 1688/2500 [45:22<1:22:37,  6.11s/it] 68%|██████▊   | 1689/2500 [45:28<1:20:46,  5.98s/it] 68%|██████▊   | 1690/2500 [45:34<1:20:03,  5.93s/it]                                                     {'loss': 2.0164, 'grad_norm': 7.193114561831289, 'learning_rate': 1.1870634250967605e-05, 'rewards/chosen': -0.7206429243087769, 'rewards/rejected': -3.1175765991210938, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3969335556030273, 'logps/rejected': -7.793940544128418, 'logps/chosen': -1.8016074895858765, 'logits/rejected': -1.5862877368927002, 'logits/chosen': -3.005887269973755, 'nll_loss': 1.784912347793579, 'log_odds_ratio': -0.07004228234291077, 'log_odds_chosen': 6.152562141418457, 'logps/chosen_prompt': -0.7767849564552307, 'logps/rejected_prompt': -1.0307962894439697, 'logits/chosen_prompt': -2.708181619644165, 'logits/rejected_prompt': -2.7091293334960938, 'logps/chosen_both': -1.7869327068328857, 'logps/rejected_both': -7.685845851898193, 'epoch': 1.35}
 68%|██████▊   | 1690/2500 [45:34<1:20:03,  5.93s/it] 68%|██████▊   | 1691/2500 [45:40<1:20:34,  5.98s/it] 68%|██████▊   | 1692/2500 [45:46<1:20:59,  6.01s/it] 68%|██████▊   | 1693/2500 [45:51<1:19:02,  5.88s/it] 68%|██████▊   | 1694/2500 [45:57<1:19:19,  5.90s/it] 68%|██████▊   | 1695/2500 [46:03<1:19:02,  5.89s/it] 68%|██████▊   | 1696/2500 [46:09<1:19:57,  5.97s/it] 68%|██████▊   | 1697/2500 [46:16<1:21:18,  6.08s/it] 68%|██████▊   | 1698/2500 [46:22<1:21:49,  6.12s/it] 68%|██████▊   | 1699/2500 [46:28<1:20:34,  6.04s/it] 68%|██████▊   | 1700/2500 [46:34<1:21:45,  6.13s/it]                                                     {'loss': 2.0095, 'grad_norm': 0.1883777619055695, 'learning_rate': 1.1604330125525079e-05, 'rewards/chosen': -0.7886604070663452, 'rewards/rejected': -2.531670331954956, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7430098056793213, 'logps/rejected': -6.3291754722595215, 'logps/chosen': -1.9716510772705078, 'logits/rejected': -1.9508018493652344, 'logits/chosen': -2.9786839485168457, 'nll_loss': 1.9534410238265991, 'log_odds_ratio': -0.2087760865688324, 'log_odds_chosen': 4.46850061416626, 'logps/chosen_prompt': -0.8371461033821106, 'logps/rejected_prompt': -1.00449538230896, 'logits/chosen_prompt': -2.7516732215881348, 'logits/rejected_prompt': -2.702972412109375, 'logps/chosen_both': -1.9539352655410767, 'logps/rejected_both': -6.248607158660889, 'epoch': 1.36}
 68%|██████▊   | 1700/2500 [46:34<1:21:45,  6.13s/it] 68%|██████▊   | 1701/2500 [46:40<1:20:39,  6.06s/it] 68%|██████▊   | 1702/2500 [46:47<1:22:35,  6.21s/it] 68%|██████▊   | 1703/2500 [46:53<1:23:34,  6.29s/it] 68%|██████▊   | 1704/2500 [47:00<1:24:17,  6.35s/it] 68%|██████▊   | 1705/2500 [47:05<1:20:26,  6.07s/it] 68%|██████▊   | 1706/2500 [47:10<1:17:48,  5.88s/it] 68%|██████▊   | 1707/2500 [47:16<1:17:50,  5.89s/it] 68%|██████▊   | 1708/2500 [47:22<1:17:07,  5.84s/it] 68%|██████▊   | 1709/2500 [47:29<1:21:32,  6.19s/it] 68%|██████▊   | 1710/2500 [47:35<1:20:30,  6.11s/it]                                                     {'loss': 2.0566, 'grad_norm': 0.4545215580275642, 'learning_rate': 1.1340141331643276e-05, 'rewards/chosen': -0.7989187240600586, 'rewards/rejected': -3.0937724113464355, 'rewards/accuracies': 1.0, 'rewards/margins': 2.294853925704956, 'logps/rejected': -7.73443078994751, 'logps/chosen': -1.997296690940857, 'logits/rejected': -1.6199884414672852, 'logits/chosen': -2.9371676445007324, 'nll_loss': 1.97933828830719, 'log_odds_ratio': -0.017771778628230095, 'log_odds_chosen': 5.883325576782227, 'logps/chosen_prompt': -0.802758514881134, 'logps/rejected_prompt': -1.0660558938980103, 'logits/chosen_prompt': -2.7415239810943604, 'logits/rejected_prompt': -2.722252368927002, 'logps/chosen_both': -1.9803251028060913, 'logps/rejected_both': -7.637998104095459, 'epoch': 1.37}
 68%|██████▊   | 1710/2500 [47:35<1:20:30,  6.11s/it] 68%|██████▊   | 1711/2500 [47:40<1:17:56,  5.93s/it] 68%|██████▊   | 1712/2500 [47:46<1:17:07,  5.87s/it] 69%|██████▊   | 1713/2500 [47:52<1:15:13,  5.74s/it] 69%|██████▊   | 1714/2500 [47:58<1:16:40,  5.85s/it] 69%|██████▊   | 1715/2500 [48:03<1:16:02,  5.81s/it] 69%|██████▊   | 1716/2500 [48:09<1:14:00,  5.66s/it] 69%|██████▊   | 1717/2500 [48:15<1:14:42,  5.72s/it] 69%|██████▊   | 1718/2500 [48:21<1:18:11,  6.00s/it] 69%|██████▉   | 1719/2500 [48:28<1:19:44,  6.13s/it] 69%|██████▉   | 1720/2500 [48:34<1:19:13,  6.09s/it]                                                     {'loss': 2.0061, 'grad_norm': 1.1997452621235265, 'learning_rate': 1.107810958779531e-05, 'rewards/chosen': -0.7996522188186646, 'rewards/rejected': -2.980699300765991, 'rewards/accuracies': 1.0, 'rewards/margins': 2.181047201156616, 'logps/rejected': -7.451747894287109, 'logps/chosen': -1.9991306066513062, 'logits/rejected': -1.6561696529388428, 'logits/chosen': -2.9388651847839355, 'nll_loss': 1.9815709590911865, 'log_odds_ratio': -0.07156334817409515, 'log_odds_chosen': 5.593207359313965, 'logps/chosen_prompt': -0.8030672073364258, 'logps/rejected_prompt': -0.9857326745986938, 'logits/chosen_prompt': -2.731867551803589, 'logits/rejected_prompt': -2.6983978748321533, 'logps/chosen_both': -1.9822534322738647, 'logps/rejected_both': -7.3482794761657715, 'epoch': 1.38}
 69%|██████▉   | 1720/2500 [48:34<1:19:13,  6.09s/it] 69%|██████▉   | 1721/2500 [48:39<1:17:22,  5.96s/it] 69%|██████▉   | 1722/2500 [48:45<1:17:12,  5.95s/it] 69%|██████▉   | 1723/2500 [48:51<1:17:15,  5.97s/it] 69%|██████▉   | 1724/2500 [48:57<1:14:48,  5.78s/it] 69%|██████▉   | 1725/2500 [49:02<1:13:10,  5.67s/it] 69%|██████▉   | 1726/2500 [49:08<1:14:52,  5.80s/it] 69%|██████▉   | 1727/2500 [49:14<1:13:27,  5.70s/it] 69%|██████▉   | 1728/2500 [49:19<1:12:26,  5.63s/it] 69%|██████▉   | 1729/2500 [49:25<1:13:39,  5.73s/it] 69%|██████▉   | 1730/2500 [49:31<1:12:47,  5.67s/it]                                                     {'loss': 2.049, 'grad_norm': 0.19716435957466513, 'learning_rate': 1.0818276271831093e-05, 'rewards/chosen': -0.827889084815979, 'rewards/rejected': -3.142641067504883, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3147521018981934, 'logps/rejected': -7.856602668762207, 'logps/chosen': -2.0697224140167236, 'logits/rejected': -1.5650447607040405, 'logits/chosen': -2.9178428649902344, 'nll_loss': 2.0516767501831055, 'log_odds_ratio': -0.07050631940364838, 'log_odds_chosen': 5.9064459800720215, 'logps/chosen_prompt': -0.8549707531929016, 'logps/rejected_prompt': -1.0415699481964111, 'logits/chosen_prompt': -2.688906192779541, 'logits/rejected_prompt': -2.667656660079956, 'logps/chosen_both': -2.051950693130493, 'logps/rejected_both': -7.754634857177734, 'epoch': 1.38}
 69%|██████▉   | 1730/2500 [49:31<1:12:47,  5.67s/it] 69%|██████▉   | 1731/2500 [49:37<1:14:18,  5.80s/it] 69%|██████▉   | 1732/2500 [49:43<1:17:09,  6.03s/it] 69%|██████▉   | 1733/2500 [49:49<1:16:56,  6.02s/it] 69%|██████▉   | 1734/2500 [49:55<1:14:33,  5.84s/it] 69%|██████▉   | 1735/2500 [50:00<1:13:23,  5.76s/it] 69%|██████▉   | 1736/2500 [50:06<1:12:20,  5.68s/it] 69%|██████▉   | 1737/2500 [50:11<1:11:52,  5.65s/it] 70%|██████▉   | 1738/2500 [50:17<1:11:49,  5.66s/it] 70%|██████▉   | 1739/2500 [50:23<1:11:31,  5.64s/it] 70%|██████▉   | 1740/2500 [50:29<1:13:46,  5.82s/it]                                                     {'loss': 1.9509, 'grad_norm': 18.15796544396043, 'learning_rate': 1.0560682414443315e-05, 'rewards/chosen': -0.7788323163986206, 'rewards/rejected': -3.3951754570007324, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6163430213928223, 'logps/rejected': -8.48793888092041, 'logps/chosen': -1.9470806121826172, 'logits/rejected': -1.39240300655365, 'logits/chosen': -2.9712464809417725, 'nll_loss': 1.9252256155014038, 'log_odds_ratio': -0.001423981157131493, 'log_odds_chosen': 6.700833797454834, 'logps/chosen_prompt': -0.7826536297798157, 'logps/rejected_prompt': -0.9802854657173157, 'logits/chosen_prompt': -2.7174434661865234, 'logits/rejected_prompt': -2.7043309211730957, 'logps/chosen_both': -1.9272314310073853, 'logps/rejected_both': -8.350778579711914, 'epoch': 1.39}
 70%|██████▉   | 1740/2500 [50:29<1:13:46,  5.82s/it] 70%|██████▉   | 1741/2500 [50:35<1:15:01,  5.93s/it] 70%|██████▉   | 1742/2500 [50:41<1:14:04,  5.86s/it] 70%|██████▉   | 1743/2500 [50:47<1:14:10,  5.88s/it] 70%|██████▉   | 1744/2500 [50:52<1:13:18,  5.82s/it] 70%|██████▉   | 1745/2500 [50:58<1:11:23,  5.67s/it] 70%|██████▉   | 1746/2500 [51:04<1:12:19,  5.76s/it] 70%|██████▉   | 1747/2500 [51:10<1:13:30,  5.86s/it] 70%|██████▉   | 1748/2500 [51:16<1:16:19,  6.09s/it] 70%|██████▉   | 1749/2500 [51:23<1:18:46,  6.29s/it] 70%|███████   | 1750/2500 [51:29<1:16:05,  6.09s/it]                                                     {'loss': 2.0578, 'grad_norm': 0.306884626090602, 'learning_rate': 1.0305368692688174e-05, 'rewards/chosen': -0.7544252276420593, 'rewards/rejected': -3.145629405975342, 'rewards/accuracies': 1.0, 'rewards/margins': 2.391204357147217, 'logps/rejected': -7.864073753356934, 'logps/chosen': -1.8860629796981812, 'logits/rejected': -1.5384562015533447, 'logits/chosen': -2.946425199508667, 'nll_loss': 1.8705356121063232, 'log_odds_ratio': -0.07031579315662384, 'log_odds_chosen': 6.136950492858887, 'logps/chosen_prompt': -0.7232022285461426, 'logps/rejected_prompt': -0.916634738445282, 'logits/chosen_prompt': -2.7230069637298584, 'logits/rejected_prompt': -2.6866297721862793, 'logps/chosen_both': -1.8708884716033936, 'logps/rejected_both': -7.770904541015625, 'epoch': 1.4}
 70%|███████   | 1750/2500 [51:29<1:16:05,  6.09s/it] 70%|███████   | 1751/2500 [51:36<1:18:56,  6.32s/it] 70%|███████   | 1752/2500 [51:41<1:16:07,  6.11s/it] 70%|███████   | 1753/2500 [51:47<1:14:01,  5.95s/it] 70%|███████   | 1754/2500 [51:53<1:16:47,  6.18s/it] 70%|███████   | 1755/2500 [51:59<1:14:41,  6.01s/it] 70%|███████   | 1756/2500 [52:05<1:15:03,  6.05s/it] 70%|███████   | 1757/2500 [52:11<1:14:19,  6.00s/it] 70%|███████   | 1758/2500 [52:17<1:13:33,  5.95s/it] 70%|███████   | 1759/2500 [52:23<1:13:06,  5.92s/it] 70%|███████   | 1760/2500 [52:28<1:10:25,  5.71s/it]                                                     {'loss': 2.1614, 'grad_norm': 0.18881847372683813, 'learning_rate': 1.0052375423562038e-05, 'rewards/chosen': -0.8756723403930664, 'rewards/rejected': -3.277121067047119, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4014487266540527, 'logps/rejected': -8.192803382873535, 'logps/chosen': -2.189180850982666, 'logits/rejected': -1.4644935131072998, 'logits/chosen': -2.9632670879364014, 'nll_loss': 2.168154239654541, 'log_odds_ratio': -0.008913763798773289, 'log_odds_chosen': 6.1585893630981445, 'logps/chosen_prompt': -0.8722349405288696, 'logps/rejected_prompt': -1.1272975206375122, 'logits/chosen_prompt': -2.71419620513916, 'logits/rejected_prompt': -2.6670680046081543, 'logps/chosen_both': -2.16886568069458, 'logps/rejected_both': -8.07650375366211, 'epoch': 1.41}
 70%|███████   | 1760/2500 [52:28<1:10:25,  5.71s/it] 70%|███████   | 1761/2500 [52:34<1:10:29,  5.72s/it] 70%|███████   | 1762/2500 [52:40<1:11:46,  5.84s/it] 71%|███████   | 1763/2500 [52:45<1:10:42,  5.76s/it] 71%|███████   | 1764/2500 [52:52<1:12:31,  5.91s/it] 71%|███████   | 1765/2500 [52:57<1:10:44,  5.78s/it] 71%|███████   | 1766/2500 [53:02<1:08:41,  5.61s/it] 71%|███████   | 1767/2500 [53:09<1:11:55,  5.89s/it] 71%|███████   | 1768/2500 [53:15<1:11:31,  5.86s/it] 71%|███████   | 1769/2500 [53:20<1:11:02,  5.83s/it] 71%|███████   | 1770/2500 [53:26<1:10:21,  5.78s/it]                                                     {'loss': 1.9946, 'grad_norm': 0.17281530980372947, 'learning_rate': 9.801742557634872e-06, 'rewards/chosen': -0.8311726450920105, 'rewards/rejected': -2.9474053382873535, 'rewards/accuracies': 1.0, 'rewards/margins': 2.116232395172119, 'logps/rejected': -7.3685126304626465, 'logps/chosen': -2.0779316425323486, 'logits/rejected': -1.6701503992080688, 'logits/chosen': -2.944209337234497, 'nll_loss': 2.0592682361602783, 'log_odds_ratio': -0.07887142151594162, 'log_odds_chosen': 5.409924507141113, 'logps/chosen_prompt': -0.8584500551223755, 'logps/rejected_prompt': -1.0396044254302979, 'logits/chosen_prompt': -2.7262632846832275, 'logits/rejected_prompt': -2.699427604675293, 'logps/chosen_both': -2.0600078105926514, 'logps/rejected_both': -7.270436763763428, 'epoch': 1.42}
 71%|███████   | 1770/2500 [53:26<1:10:21,  5.78s/it] 71%|███████   | 1771/2500 [53:33<1:12:26,  5.96s/it] 71%|███████   | 1772/2500 [53:38<1:12:10,  5.95s/it] 71%|███████   | 1773/2500 [53:44<1:10:35,  5.83s/it] 71%|███████   | 1774/2500 [53:49<1:08:45,  5.68s/it] 71%|███████   | 1775/2500 [53:55<1:08:48,  5.69s/it] 71%|███████   | 1776/2500 [54:02<1:12:54,  6.04s/it] 71%|███████   | 1777/2500 [54:08<1:13:42,  6.12s/it] 71%|███████   | 1778/2500 [54:14<1:13:13,  6.09s/it] 71%|███████   | 1779/2500 [54:20<1:11:43,  5.97s/it] 71%|███████   | 1780/2500 [54:26<1:13:47,  6.15s/it]                                                     {'loss': 2.039, 'grad_norm': 0.17548964182907714, 'learning_rate': 9.553509672741645e-06, 'rewards/chosen': -0.8001230359077454, 'rewards/rejected': -2.698500871658325, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8983774185180664, 'logps/rejected': -6.746251106262207, 'logps/chosen': -2.000307559967041, 'logits/rejected': -1.8278512954711914, 'logits/chosen': -2.9678618907928467, 'nll_loss': 1.9816503524780273, 'log_odds_ratio': -0.14615245163440704, 'log_odds_chosen': 4.869265556335449, 'logps/chosen_prompt': -0.7849266529083252, 'logps/rejected_prompt': -0.9317256212234497, 'logits/chosen_prompt': -2.7222800254821777, 'logits/rejected_prompt': -2.707014560699463, 'logps/chosen_both': -1.9819421768188477, 'logps/rejected_both': -6.653542518615723, 'epoch': 1.42}
 71%|███████   | 1780/2500 [54:26<1:13:47,  6.15s/it] 71%|███████   | 1781/2500 [54:33<1:13:48,  6.16s/it] 71%|███████▏  | 1782/2500 [54:39<1:13:14,  6.12s/it] 71%|███████▏  | 1783/2500 [54:45<1:12:29,  6.07s/it] 71%|███████▏  | 1784/2500 [54:51<1:14:10,  6.22s/it] 71%|███████▏  | 1785/2500 [54:57<1:12:56,  6.12s/it] 71%|███████▏  | 1786/2500 [55:03<1:11:29,  6.01s/it] 71%|███████▏  | 1787/2500 [55:09<1:10:47,  5.96s/it] 72%|███████▏  | 1788/2500 [55:17<1:18:38,  6.63s/it] 72%|███████▏  | 1789/2500 [55:23<1:15:02,  6.33s/it] 72%|███████▏  | 1790/2500 [55:28<1:13:25,  6.20s/it]                                                     {'loss': 2.0166, 'grad_norm': 16.59823036408421, 'learning_rate': 9.307715967732491e-06, 'rewards/chosen': -0.7902355790138245, 'rewards/rejected': -3.4376683235168457, 'rewards/accuracies': 1.0, 'rewards/margins': 2.647432804107666, 'logps/rejected': -8.594171524047852, 'logps/chosen': -1.9755887985229492, 'logits/rejected': -1.333492636680603, 'logits/chosen': -2.9545249938964844, 'nll_loss': 1.9590076208114624, 'log_odds_ratio': -0.0012302311370149255, 'log_odds_chosen': 6.773609161376953, 'logps/chosen_prompt': -0.9338394999504089, 'logps/rejected_prompt': -1.072101354598999, 'logits/chosen_prompt': -2.695913791656494, 'logits/rejected_prompt': -2.667999029159546, 'logps/chosen_both': -1.960455298423767, 'logps/rejected_both': -8.47549057006836, 'epoch': 1.43}
 72%|███████▏  | 1790/2500 [55:28<1:13:25,  6.20s/it] 72%|███████▏  | 1791/2500 [55:34<1:11:49,  6.08s/it] 72%|███████▏  | 1792/2500 [55:39<1:08:55,  5.84s/it] 72%|███████▏  | 1793/2500 [55:46<1:11:13,  6.04s/it] 72%|███████▏  | 1794/2500 [55:52<1:09:10,  5.88s/it] 72%|███████▏  | 1795/2500 [55:57<1:08:27,  5.83s/it] 72%|███████▏  | 1796/2500 [56:03<1:07:36,  5.76s/it] 72%|███████▏  | 1797/2500 [56:09<1:08:02,  5.81s/it] 72%|███████▏  | 1798/2500 [56:15<1:08:41,  5.87s/it] 72%|███████▏  | 1799/2500 [56:20<1:07:17,  5.76s/it] 72%|███████▏  | 1800/2500 [56:27<1:09:22,  5.95s/it]                                                     {'loss': 2.037, 'grad_norm': 1.0268230857677676, 'learning_rate': 9.064400256282757e-06, 'rewards/chosen': -0.8224391937255859, 'rewards/rejected': -2.196458339691162, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.3740193843841553, 'logps/rejected': -5.491146564483643, 'logps/chosen': -2.0560977458953857, 'logits/rejected': -2.1232717037200928, 'logits/chosen': -2.881737470626831, 'nll_loss': 2.0378191471099854, 'log_odds_ratio': -0.2833627760410309, 'log_odds_chosen': 3.5168049335479736, 'logps/chosen_prompt': -0.6793454885482788, 'logps/rejected_prompt': -0.8112664222717285, 'logits/chosen_prompt': -2.712773561477661, 'logits/rejected_prompt': -2.691920280456543, 'logps/chosen_both': -2.0388028621673584, 'logps/rejected_both': -5.427721977233887, 'epoch': 1.44}
 72%|███████▏  | 1800/2500 [56:27<1:09:22,  5.95s/it] 72%|███████▏  | 1801/2500 [56:32<1:07:13,  5.77s/it] 72%|███████▏  | 1802/2500 [56:38<1:07:21,  5.79s/it] 72%|███████▏  | 1803/2500 [56:43<1:05:36,  5.65s/it] 72%|███████▏  | 1804/2500 [56:48<1:03:56,  5.51s/it] 72%|███████▏  | 1805/2500 [56:54<1:04:01,  5.53s/it] 72%|███████▏  | 1806/2500 [57:02<1:14:05,  6.41s/it] 72%|███████▏  | 1807/2500 [57:08<1:09:47,  6.04s/it] 72%|███████▏  | 1808/2500 [57:13<1:08:07,  5.91s/it] 72%|███████▏  | 1809/2500 [57:19<1:08:29,  5.95s/it] 72%|███████▏  | 1810/2500 [57:27<1:13:43,  6.41s/it]                                                     {'loss': 2.0148, 'grad_norm': 0.25944875450503607, 'learning_rate': 8.8236009607639e-06, 'rewards/chosen': -0.7545753717422485, 'rewards/rejected': -2.3622918128967285, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.6077163219451904, 'logps/rejected': -5.905728816986084, 'logps/chosen': -1.8864381313323975, 'logits/rejected': -2.1008501052856445, 'logits/chosen': -3.038058042526245, 'nll_loss': 1.8674299716949463, 'log_odds_ratio': -0.21856260299682617, 'log_odds_chosen': 4.140050888061523, 'logps/chosen_prompt': -0.9085067510604858, 'logps/rejected_prompt': -1.0472512245178223, 'logits/chosen_prompt': -2.7061855792999268, 'logits/rejected_prompt': -2.698530673980713, 'logps/chosen_both': -1.8686155080795288, 'logps/rejected_both': -5.821648597717285, 'epoch': 1.45}
 72%|███████▏  | 1810/2500 [57:27<1:13:43,  6.41s/it] 72%|███████▏  | 1811/2500 [57:32<1:10:00,  6.10s/it] 72%|███████▏  | 1812/2500 [57:38<1:09:37,  6.07s/it] 73%|███████▎  | 1813/2500 [57:44<1:08:36,  5.99s/it] 73%|███████▎  | 1814/2500 [57:50<1:08:28,  5.99s/it] 73%|███████▎  | 1815/2500 [57:57<1:12:24,  6.34s/it] 73%|███████▎  | 1816/2500 [58:03<1:09:43,  6.12s/it] 73%|███████▎  | 1817/2500 [58:09<1:10:26,  6.19s/it] 73%|███████▎  | 1818/2500 [58:15<1:10:43,  6.22s/it] 73%|███████▎  | 1819/2500 [58:21<1:08:19,  6.02s/it] 73%|███████▎  | 1820/2500 [58:27<1:07:06,  5.92s/it]                                                     {'loss': 1.9636, 'grad_norm': 2.80496551722963, 'learning_rate': 8.585356106176094e-06, 'rewards/chosen': -0.7535495758056641, 'rewards/rejected': -3.392299175262451, 'rewards/accuracies': 1.0, 'rewards/margins': 2.638749599456787, 'logps/rejected': -8.480748176574707, 'logps/chosen': -1.8838739395141602, 'logits/rejected': -1.3794535398483276, 'logits/chosen': -2.9982614517211914, 'nll_loss': 1.8650197982788086, 'log_odds_ratio': -0.0017175996908918023, 'log_odds_chosen': 6.7718963623046875, 'logps/chosen_prompt': -0.7680783867835999, 'logps/rejected_prompt': -1.0070313215255737, 'logits/chosen_prompt': -2.7320094108581543, 'logits/rejected_prompt': -2.6957271099090576, 'logps/chosen_both': -1.8668479919433594, 'logps/rejected_both': -8.358384132385254, 'epoch': 1.46}
 73%|███████▎  | 1820/2500 [58:27<1:07:06,  5.92s/it] 73%|███████▎  | 1821/2500 [58:33<1:07:29,  5.96s/it] 73%|███████▎  | 1822/2500 [58:38<1:04:47,  5.73s/it] 73%|███████▎  | 1823/2500 [58:43<1:04:27,  5.71s/it] 73%|███████▎  | 1824/2500 [58:49<1:03:58,  5.68s/it] 73%|███████▎  | 1825/2500 [58:55<1:05:22,  5.81s/it] 73%|███████▎  | 1826/2500 [59:01<1:04:03,  5.70s/it] 73%|███████▎  | 1827/2500 [59:07<1:06:10,  5.90s/it] 73%|███████▎  | 1828/2500 [59:12<1:03:50,  5.70s/it] 73%|███████▎  | 1829/2500 [59:18<1:04:26,  5.76s/it] 73%|███████▎  | 1830/2500 [59:23<1:02:52,  5.63s/it]                                                     {'loss': 1.9914, 'grad_norm': 1.3515931629426523, 'learning_rate': 8.34970331414371e-06, 'rewards/chosen': -0.7711480855941772, 'rewards/rejected': -2.828004837036133, 'rewards/accuracies': 1.0, 'rewards/margins': 2.056856632232666, 'logps/rejected': -7.070012092590332, 'logps/chosen': -1.9278701543807983, 'logits/rejected': -1.7584384679794312, 'logits/chosen': -2.9704651832580566, 'nll_loss': 1.9113006591796875, 'log_odds_ratio': -0.0821521133184433, 'log_odds_chosen': 5.278162002563477, 'logps/chosen_prompt': -0.7792649269104004, 'logps/rejected_prompt': -0.903057873249054, 'logits/chosen_prompt': -2.7231509685516357, 'logits/rejected_prompt': -2.7038371562957764, 'logps/chosen_both': -1.9125480651855469, 'logps/rejected_both': -6.975979804992676, 'epoch': 1.46}
 73%|███████▎  | 1830/2500 [59:23<1:02:52,  5.63s/it] 73%|███████▎  | 1831/2500 [59:33<1:17:07,  6.92s/it] 73%|███████▎  | 1832/2500 [59:39<1:13:01,  6.56s/it] 73%|███████▎  | 1833/2500 [59:45<1:10:26,  6.34s/it] 73%|███████▎  | 1834/2500 [59:51<1:10:09,  6.32s/it] 73%|███████▎  | 1835/2500 [59:57<1:07:17,  6.07s/it] 73%|███████▎  | 1836/2500 [1:00:02<1:06:10,  5.98s/it] 73%|███████▎  | 1837/2500 [1:00:08<1:06:18,  6.00s/it] 74%|███████▎  | 1838/2500 [1:00:14<1:04:50,  5.88s/it] 74%|███████▎  | 1839/2500 [1:00:20<1:03:45,  5.79s/it] 74%|███████▎  | 1840/2500 [1:00:25<1:03:45,  5.80s/it]                                                       {'loss': 2.0078, 'grad_norm': 7.354931265737482, 'learning_rate': 8.116679796974388e-06, 'rewards/chosen': -0.742232620716095, 'rewards/rejected': -3.081692934036255, 'rewards/accuracies': 1.0, 'rewards/margins': 2.339460611343384, 'logps/rejected': -7.704232692718506, 'logps/chosen': -1.855581283569336, 'logits/rejected': -1.5669771432876587, 'logits/chosen': -2.956164598464966, 'nll_loss': 1.842017412185669, 'log_odds_ratio': -0.07183117419481277, 'log_odds_chosen': 5.9964070320129395, 'logps/chosen_prompt': -0.8657811880111694, 'logps/rejected_prompt': -1.0101978778839111, 'logits/chosen_prompt': -2.7317473888397217, 'logits/rejected_prompt': -2.707166910171509, 'logps/chosen_both': -1.8426975011825562, 'logps/rejected_both': -7.615309238433838, 'epoch': 1.47}
 74%|███████▎  | 1840/2500 [1:00:25<1:03:45,  5.80s/it] 74%|███████▎  | 1841/2500 [1:00:32<1:06:02,  6.01s/it] 74%|███████▎  | 1842/2500 [1:00:37<1:03:50,  5.82s/it] 74%|███████▎  | 1843/2500 [1:00:44<1:06:06,  6.04s/it] 74%|███████▍  | 1844/2500 [1:00:51<1:09:05,  6.32s/it] 74%|███████▍  | 1845/2500 [1:00:57<1:07:43,  6.20s/it] 74%|███████▍  | 1846/2500 [1:01:02<1:05:42,  6.03s/it] 74%|███████▍  | 1847/2500 [1:01:08<1:04:06,  5.89s/it] 74%|███████▍  | 1848/2500 [1:01:14<1:04:14,  5.91s/it] 74%|███████▍  | 1849/2500 [1:01:19<1:02:37,  5.77s/it] 74%|███████▍  | 1850/2500 [1:01:25<1:01:57,  5.72s/it]                                                       {'loss': 2.0488, 'grad_norm': 0.6405636115653229, 'learning_rate': 7.886322351782783e-06, 'rewards/chosen': -0.842377781867981, 'rewards/rejected': -3.2571327686309814, 'rewards/accuracies': 1.0, 'rewards/margins': 2.414754867553711, 'logps/rejected': -8.142831802368164, 'logps/chosen': -2.1059443950653076, 'logits/rejected': -1.4464902877807617, 'logits/chosen': -2.9476819038391113, 'nll_loss': 2.085146903991699, 'log_odds_ratio': -0.01580904796719551, 'log_odds_chosen': 6.1805877685546875, 'logps/chosen_prompt': -0.7968143820762634, 'logps/rejected_prompt': -0.9554328918457031, 'logits/chosen_prompt': -2.7067055702209473, 'logits/rejected_prompt': -2.680663585662842, 'logps/chosen_both': -2.0857958793640137, 'logps/rejected_both': -8.028375625610352, 'epoch': 1.48}
 74%|███████▍  | 1850/2500 [1:01:25<1:01:57,  5.72s/it] 74%|███████▍  | 1851/2500 [1:01:31<1:03:01,  5.83s/it] 74%|███████▍  | 1852/2500 [1:01:36<1:01:19,  5.68s/it] 74%|███████▍  | 1853/2500 [1:01:42<1:00:10,  5.58s/it] 74%|███████▍  | 1854/2500 [1:01:47<1:00:05,  5.58s/it] 74%|███████▍  | 1855/2500 [1:01:53<1:01:53,  5.76s/it] 74%|███████▍  | 1856/2500 [1:02:00<1:05:18,  6.08s/it] 74%|███████▍  | 1857/2500 [1:02:06<1:03:24,  5.92s/it] 74%|███████▍  | 1858/2500 [1:02:12<1:03:54,  5.97s/it] 74%|███████▍  | 1859/2500 [1:02:17<1:01:52,  5.79s/it] 74%|███████▍  | 1860/2500 [1:02:23<1:01:21,  5.75s/it]                                                       {'loss': 2.2127, 'grad_norm': 0.19987265167230164, 'learning_rate': 7.65866735467988e-06, 'rewards/chosen': -0.810462474822998, 'rewards/rejected': -2.9936399459838867, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1831774711608887, 'logps/rejected': -7.484099388122559, 'logps/chosen': -2.026156187057495, 'logits/rejected': -1.5546457767486572, 'logits/chosen': -2.8908579349517822, 'nll_loss': 2.010030746459961, 'log_odds_ratio': -0.13918620347976685, 'log_odds_chosen': 5.563407897949219, 'logps/chosen_prompt': -0.8833006024360657, 'logps/rejected_prompt': -1.0516681671142578, 'logits/chosen_prompt': -2.6897943019866943, 'logits/rejected_prompt': -2.6759300231933594, 'logps/chosen_both': -2.0106046199798584, 'logps/rejected_both': -7.399407863616943, 'epoch': 1.49}
 74%|███████▍  | 1860/2500 [1:02:23<1:01:21,  5.75s/it] 74%|███████▍  | 1861/2500 [1:02:29<1:01:07,  5.74s/it] 74%|███████▍  | 1862/2500 [1:02:34<1:00:44,  5.71s/it] 75%|███████▍  | 1863/2500 [1:02:41<1:02:08,  5.85s/it] 75%|███████▍  | 1864/2500 [1:02:47<1:03:19,  5.97s/it] 75%|███████▍  | 1865/2500 [1:02:52<1:00:41,  5.73s/it] 75%|███████▍  | 1866/2500 [1:02:58<1:00:48,  5.75s/it] 75%|███████▍  | 1867/2500 [1:03:04<1:01:26,  5.82s/it] 75%|███████▍  | 1868/2500 [1:03:14<1:14:29,  7.07s/it] 75%|███████▍  | 1869/2500 [1:03:19<1:10:11,  6.67s/it] 75%|███████▍  | 1870/2500 [1:03:25<1:07:39,  6.44s/it]                                                       {'loss': 2.0374, 'grad_norm': 0.20545499118482996, 'learning_rate': 7.433750755028773e-06, 'rewards/chosen': -0.7189947366714478, 'rewards/rejected': -2.861034631729126, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1420397758483887, 'logps/rejected': -7.152586460113525, 'logps/chosen': -1.7974869012832642, 'logits/rejected': -1.6960422992706299, 'logits/chosen': -2.968942165374756, 'nll_loss': 1.7828178405761719, 'log_odds_ratio': -0.14290952682495117, 'log_odds_chosen': 5.551226615905762, 'logps/chosen_prompt': -0.7890797257423401, 'logps/rejected_prompt': -0.9145042300224304, 'logits/chosen_prompt': -2.7480621337890625, 'logits/rejected_prompt': -2.7131667137145996, 'logps/chosen_both': -1.7836053371429443, 'logps/rejected_both': -7.053192138671875, 'epoch': 1.5}
 75%|███████▍  | 1870/2500 [1:03:25<1:07:39,  6.44s/it] 75%|███████▍  | 1871/2500 [1:03:31<1:06:24,  6.34s/it] 75%|███████▍  | 1872/2500 [1:03:37<1:04:39,  6.18s/it] 75%|███████▍  | 1873/2500 [1:03:43<1:02:14,  5.96s/it] 75%|███████▍  | 1874/2500 [1:03:49<1:01:33,  5.90s/it] 75%|███████▌  | 1875/2500 [1:03:54<1:00:00,  5.76s/it] 75%|███████▌  | 1876/2500 [1:04:00<1:00:06,  5.78s/it] 75%|███████▌  | 1877/2500 [1:04:05<59:24,  5.72s/it]   75%|███████▌  | 1878/2500 [1:04:12<1:01:35,  5.94s/it] 75%|███████▌  | 1879/2500 [1:04:18<1:01:29,  5.94s/it] 75%|███████▌  | 1880/2500 [1:04:23<59:12,  5.73s/it]                                                       {'loss': 2.0301, 'grad_norm': 0.2177647913636776, 'learning_rate': 7.211608069767867e-06, 'rewards/chosen': -0.8220794796943665, 'rewards/rejected': -3.206092119216919, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3840126991271973, 'logps/rejected': -8.015230178833008, 'logps/chosen': -2.0551986694335938, 'logits/rejected': -1.4146044254302979, 'logits/chosen': -2.944500684738159, 'nll_loss': 2.033806324005127, 'log_odds_ratio': -0.0701688900589943, 'log_odds_chosen': 6.082915782928467, 'logps/chosen_prompt': -0.8937435150146484, 'logps/rejected_prompt': -1.032755970954895, 'logits/chosen_prompt': -2.739798069000244, 'logits/rejected_prompt': -2.7159626483917236, 'logps/chosen_both': -2.034550905227661, 'logps/rejected_both': -7.8913702964782715, 'epoch': 1.5}
 75%|███████▌  | 1880/2500 [1:04:23<59:12,  5.73s/it] 75%|███████▌  | 1881/2500 [1:04:29<1:01:29,  5.96s/it] 75%|███████▌  | 1882/2500 [1:04:35<1:00:21,  5.86s/it] 75%|███████▌  | 1883/2500 [1:04:41<59:15,  5.76s/it]   75%|███████▌  | 1884/2500 [1:04:46<59:23,  5.78s/it] 75%|███████▌  | 1885/2500 [1:04:53<1:02:06,  6.06s/it] 75%|███████▌  | 1886/2500 [1:04:59<1:01:03,  5.97s/it] 75%|███████▌  | 1887/2500 [1:05:04<58:53,  5.76s/it]   76%|███████▌  | 1888/2500 [1:05:10<57:53,  5.68s/it] 76%|███████▌  | 1889/2500 [1:05:15<57:12,  5.62s/it] 76%|███████▌  | 1890/2500 [1:05:22<59:41,  5.87s/it]                                                     {'loss': 1.9602, 'grad_norm': 0.24649217712577137, 'learning_rate': 6.992274377802327e-06, 'rewards/chosen': -0.793796956539154, 'rewards/rejected': -3.3064608573913574, 'rewards/accuracies': 1.0, 'rewards/margins': 2.512664318084717, 'logps/rejected': -8.266152381896973, 'logps/chosen': -1.984492301940918, 'logits/rejected': -1.4115771055221558, 'logits/chosen': -2.9186906814575195, 'nll_loss': 1.9659830331802368, 'log_odds_ratio': -0.004943188279867172, 'log_odds_chosen': 6.431056022644043, 'logps/chosen_prompt': -0.6751627922058105, 'logps/rejected_prompt': -0.9480065107345581, 'logits/chosen_prompt': -2.736438035964966, 'logits/rejected_prompt': -2.6946330070495605, 'logps/chosen_both': -1.9667268991470337, 'logps/rejected_both': -8.162810325622559, 'epoch': 1.51}
 76%|███████▌  | 1890/2500 [1:05:22<59:41,  5.87s/it] 76%|███████▌  | 1891/2500 [1:05:28<1:00:01,  5.91s/it] 76%|███████▌  | 1892/2500 [1:05:33<59:27,  5.87s/it]   76%|███████▌  | 1893/2500 [1:05:39<57:55,  5.73s/it] 76%|███████▌  | 1894/2500 [1:05:44<57:18,  5.67s/it] 76%|███████▌  | 1895/2500 [1:05:50<56:59,  5.65s/it] 76%|███████▌  | 1896/2500 [1:05:56<57:50,  5.75s/it] 76%|███████▌  | 1897/2500 [1:06:02<59:13,  5.89s/it] 76%|███████▌  | 1898/2500 [1:06:08<58:49,  5.86s/it] 76%|███████▌  | 1899/2500 [1:06:14<59:34,  5.95s/it] 76%|███████▌  | 1900/2500 [1:06:19<57:42,  5.77s/it]                                                     {'loss': 1.9627, 'grad_norm': 1.8199269743751476, 'learning_rate': 6.775784314464717e-06, 'rewards/chosen': -0.7585269212722778, 'rewards/rejected': -3.3460471630096436, 'rewards/accuracies': 1.0, 'rewards/margins': 2.587520122528076, 'logps/rejected': -8.365118026733398, 'logps/chosen': -1.8963172435760498, 'logits/rejected': -1.3618006706237793, 'logits/chosen': -2.9983952045440674, 'nll_loss': 1.879476547241211, 'log_odds_ratio': -0.0034759175032377243, 'log_odds_chosen': 6.635956764221191, 'logps/chosen_prompt': -0.7936553955078125, 'logps/rejected_prompt': -0.9678634405136108, 'logits/chosen_prompt': -2.7283902168273926, 'logits/rejected_prompt': -2.6869683265686035, 'logps/chosen_both': -1.8804759979248047, 'logps/rejected_both': -8.250776290893555, 'epoch': 1.52}
 76%|███████▌  | 1900/2500 [1:06:19<57:42,  5.77s/it] 76%|███████▌  | 1901/2500 [1:06:25<57:20,  5.74s/it] 76%|███████▌  | 1902/2500 [1:06:31<58:55,  5.91s/it] 76%|███████▌  | 1903/2500 [1:06:37<58:35,  5.89s/it] 76%|███████▌  | 1904/2500 [1:06:43<57:35,  5.80s/it] 76%|███████▌  | 1905/2500 [1:06:49<57:16,  5.78s/it] 76%|███████▌  | 1906/2500 [1:06:54<57:11,  5.78s/it] 76%|███████▋  | 1907/2500 [1:07:00<56:10,  5.68s/it] 76%|███████▋  | 1908/2500 [1:07:05<54:52,  5.56s/it] 76%|███████▋  | 1909/2500 [1:07:11<55:52,  5.67s/it] 76%|███████▋  | 1910/2500 [1:07:16<54:31,  5.55s/it]                                                     {'loss': 1.9852, 'grad_norm': 0.17335956066867328, 'learning_rate': 6.562172066045655e-06, 'rewards/chosen': -0.8270961046218872, 'rewards/rejected': -3.2415504455566406, 'rewards/accuracies': 1.0, 'rewards/margins': 2.414454221725464, 'logps/rejected': -8.103876113891602, 'logps/chosen': -2.067739963531494, 'logits/rejected': -1.402918815612793, 'logits/chosen': -2.8932619094848633, 'nll_loss': 2.050727605819702, 'log_odds_ratio': -0.07030755281448364, 'log_odds_chosen': 6.16471004486084, 'logps/chosen_prompt': -0.7614051103591919, 'logps/rejected_prompt': -0.930437445640564, 'logits/chosen_prompt': -2.707535982131958, 'logits/rejected_prompt': -2.6866507530212402, 'logps/chosen_both': -2.0511081218719482, 'logps/rejected_both': -8.012598991394043, 'epoch': 1.53}
 76%|███████▋  | 1910/2500 [1:07:16<54:31,  5.55s/it] 76%|███████▋  | 1911/2500 [1:07:22<54:07,  5.51s/it] 76%|███████▋  | 1912/2500 [1:07:27<53:29,  5.46s/it] 77%|███████▋  | 1913/2500 [1:07:33<53:27,  5.46s/it] 77%|███████▋  | 1914/2500 [1:07:38<53:24,  5.47s/it] 77%|███████▋  | 1915/2500 [1:07:44<54:07,  5.55s/it] 77%|███████▋  | 1916/2500 [1:07:50<55:22,  5.69s/it] 77%|███████▋  | 1917/2500 [1:07:55<55:10,  5.68s/it] 77%|███████▋  | 1918/2500 [1:08:01<54:37,  5.63s/it] 77%|███████▋  | 1919/2500 [1:08:07<54:39,  5.64s/it] 77%|███████▋  | 1920/2500 [1:08:13<57:29,  5.95s/it]                                                     {'loss': 2.0427, 'grad_norm': 0.1813938627540028, 'learning_rate': 6.3514713643954475e-06, 'rewards/chosen': -0.7654072642326355, 'rewards/rejected': -3.5542874336242676, 'rewards/accuracies': 1.0, 'rewards/margins': 2.788879871368408, 'logps/rejected': -8.885717391967773, 'logps/chosen': -1.9135183095932007, 'logits/rejected': -1.2027853727340698, 'logits/chosen': -2.9509732723236084, 'nll_loss': 1.8980090618133545, 'log_odds_ratio': -0.0009057835559360683, 'log_odds_chosen': 7.136712551116943, 'logps/chosen_prompt': -0.7617759108543396, 'logps/rejected_prompt': -1.0301071405410767, 'logits/chosen_prompt': -2.710644245147705, 'logits/rejected_prompt': -2.6867594718933105, 'logps/chosen_both': -1.8985214233398438, 'logps/rejected_both': -8.781938552856445, 'epoch': 1.54}
 77%|███████▋  | 1920/2500 [1:08:13<57:29,  5.95s/it] 77%|███████▋  | 1921/2500 [1:08:19<55:51,  5.79s/it] 77%|███████▋  | 1922/2500 [1:08:24<55:39,  5.78s/it] 77%|███████▋  | 1923/2500 [1:08:30<55:04,  5.73s/it] 77%|███████▋  | 1924/2500 [1:08:36<56:21,  5.87s/it] 77%|███████▋  | 1925/2500 [1:08:42<55:09,  5.76s/it] 77%|███████▋  | 1926/2500 [1:08:47<54:21,  5.68s/it] 77%|███████▋  | 1927/2500 [1:08:53<54:19,  5.69s/it] 77%|███████▋  | 1928/2500 [1:08:58<52:06,  5.47s/it] 77%|███████▋  | 1929/2500 [1:09:04<54:51,  5.76s/it] 77%|███████▋  | 1930/2500 [1:09:09<52:06,  5.49s/it]                                                     {'loss': 2.1982, 'grad_norm': 5.283335302692811, 'learning_rate': 6.143715481597404e-06, 'rewards/chosen': -0.8557437062263489, 'rewards/rejected': -3.5044140815734863, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6486704349517822, 'logps/rejected': -8.761034965515137, 'logps/chosen': -2.13935923576355, 'logits/rejected': -1.2635687589645386, 'logits/chosen': -2.95304274559021, 'nll_loss': 2.119908571243286, 'log_odds_ratio': -0.0018854513764381409, 'log_odds_chosen': 6.770785331726074, 'logps/chosen_prompt': -0.789169192314148, 'logps/rejected_prompt': -1.0815883874893188, 'logits/chosen_prompt': -2.697026252746582, 'logits/rejected_prompt': -2.6728100776672363, 'logps/chosen_both': -2.120624303817749, 'logps/rejected_both': -8.646589279174805, 'epoch': 1.54}
 77%|███████▋  | 1930/2500 [1:09:09<52:06,  5.49s/it] 77%|███████▋  | 1931/2500 [1:09:15<52:30,  5.54s/it] 77%|███████▋  | 1932/2500 [1:09:21<54:46,  5.79s/it] 77%|███████▋  | 1933/2500 [1:09:27<55:40,  5.89s/it] 77%|███████▋  | 1934/2500 [1:09:33<54:20,  5.76s/it] 77%|███████▋  | 1935/2500 [1:09:38<53:22,  5.67s/it] 77%|███████▋  | 1936/2500 [1:09:44<52:16,  5.56s/it] 77%|███████▋  | 1937/2500 [1:09:50<53:55,  5.75s/it] 78%|███████▊  | 1938/2500 [1:09:55<53:16,  5.69s/it] 78%|███████▊  | 1939/2500 [1:10:01<52:59,  5.67s/it] 78%|███████▊  | 1940/2500 [1:10:07<52:46,  5.65s/it]                                                     {'loss': 1.9667, 'grad_norm': 16.477998070888354, 'learning_rate': 5.9389372247138e-06, 'rewards/chosen': -0.7763077020645142, 'rewards/rejected': -3.3268611431121826, 'rewards/accuracies': 1.0, 'rewards/margins': 2.550553560256958, 'logps/rejected': -8.317153930664062, 'logps/chosen': -1.9407694339752197, 'logits/rejected': -1.3681821823120117, 'logits/chosen': -2.92641019821167, 'nll_loss': 1.9262564182281494, 'log_odds_ratio': -0.00986974872648716, 'log_odds_chosen': 6.53433895111084, 'logps/chosen_prompt': -0.8568117022514343, 'logps/rejected_prompt': -0.9839801788330078, 'logits/chosen_prompt': -2.6943159103393555, 'logits/rejected_prompt': -2.6651058197021484, 'logps/chosen_both': -1.927452802658081, 'logps/rejected_both': -8.21821117401123, 'epoch': 1.55}
 78%|███████▊  | 1940/2500 [1:10:07<52:46,  5.65s/it] 78%|███████▊  | 1941/2500 [1:10:13<53:31,  5.75s/it] 78%|███████▊  | 1942/2500 [1:10:19<55:21,  5.95s/it] 78%|███████▊  | 1943/2500 [1:10:25<55:59,  6.03s/it] 78%|███████▊  | 1944/2500 [1:10:31<54:58,  5.93s/it] 78%|███████▊  | 1945/2500 [1:10:40<1:03:07,  6.82s/it] 78%|███████▊  | 1946/2500 [1:10:45<59:18,  6.42s/it]   78%|███████▊  | 1947/2500 [1:10:51<56:36,  6.14s/it] 78%|███████▊  | 1948/2500 [1:10:57<55:53,  6.07s/it] 78%|███████▊  | 1949/2500 [1:11:03<55:17,  6.02s/it] 78%|███████▊  | 1950/2500 [1:11:08<53:39,  5.85s/it]                                                     {'loss': 2.0165, 'grad_norm': 0.22512497067132542, 'learning_rate': 5.737168930605272e-06, 'rewards/chosen': -0.775126576423645, 'rewards/rejected': -3.3887763023376465, 'rewards/accuracies': 1.0, 'rewards/margins': 2.613649368286133, 'logps/rejected': -8.471940994262695, 'logps/chosen': -1.9378163814544678, 'logits/rejected': -1.3873342275619507, 'logits/chosen': -2.9435606002807617, 'nll_loss': 1.9220653772354126, 'log_odds_ratio': -0.006222098600119352, 'log_odds_chosen': 6.691765785217285, 'logps/chosen_prompt': -0.8648831248283386, 'logps/rejected_prompt': -1.0566165447235107, 'logits/chosen_prompt': -2.717947006225586, 'logits/rejected_prompt': -2.664790391921997, 'logps/chosen_both': -1.9225056171417236, 'logps/rejected_both': -8.353784561157227, 'epoch': 1.56}
 78%|███████▊  | 1950/2500 [1:11:08<53:39,  5.85s/it] 78%|███████▊  | 1951/2500 [1:11:14<53:44,  5.87s/it] 78%|███████▊  | 1952/2500 [1:11:19<52:31,  5.75s/it] 78%|███████▊  | 1953/2500 [1:11:25<51:59,  5.70s/it] 78%|███████▊  | 1954/2500 [1:11:31<52:19,  5.75s/it] 78%|███████▊  | 1955/2500 [1:11:37<52:06,  5.74s/it] 78%|███████▊  | 1956/2500 [1:11:43<52:37,  5.80s/it] 78%|███████▊  | 1957/2500 [1:11:49<53:03,  5.86s/it] 78%|███████▊  | 1958/2500 [1:11:55<53:47,  5.96s/it] 78%|███████▊  | 1959/2500 [1:12:01<53:43,  5.96s/it] 78%|███████▊  | 1960/2500 [1:12:06<53:12,  5.91s/it]                                                     {'loss': 2.0288, 'grad_norm': 1.3420731515178246, 'learning_rate': 5.538442460824417e-06, 'rewards/chosen': -0.7684556245803833, 'rewards/rejected': -3.210599184036255, 'rewards/accuracies': 1.0, 'rewards/margins': 2.442143678665161, 'logps/rejected': -8.026498794555664, 'logps/chosen': -1.921139121055603, 'logits/rejected': -1.4868175983428955, 'logits/chosen': -2.962092876434326, 'nll_loss': 1.9021461009979248, 'log_odds_ratio': -0.07003439962863922, 'log_odds_chosen': 6.277246952056885, 'logps/chosen_prompt': -0.890544056892395, 'logps/rejected_prompt': -1.118395209312439, 'logits/chosen_prompt': -2.6851491928100586, 'logits/rejected_prompt': -2.6795144081115723, 'logps/chosen_both': -1.9029964208602905, 'logps/rejected_both': -7.92144250869751, 'epoch': 1.57}
 78%|███████▊  | 1960/2500 [1:12:06<53:12,  5.91s/it] 78%|███████▊  | 1961/2500 [1:12:12<53:13,  5.92s/it] 78%|███████▊  | 1962/2500 [1:12:18<53:14,  5.94s/it] 79%|███████▊  | 1963/2500 [1:12:24<52:33,  5.87s/it] 79%|███████▊  | 1964/2500 [1:12:31<54:09,  6.06s/it] 79%|███████▊  | 1965/2500 [1:12:36<51:53,  5.82s/it] 79%|███████▊  | 1966/2500 [1:12:41<51:02,  5.74s/it] 79%|███████▊  | 1967/2500 [1:12:47<49:51,  5.61s/it] 79%|███████▊  | 1968/2500 [1:12:54<53:02,  5.98s/it] 79%|███████▉  | 1969/2500 [1:13:00<54:03,  6.11s/it] 79%|███████▉  | 1970/2500 [1:13:05<51:30,  5.83s/it]                                                     {'loss': 2.1082, 'grad_norm': 12.960501631224533, 'learning_rate': 5.342789196584527e-06, 'rewards/chosen': -0.96513831615448, 'rewards/rejected': -2.564405918121338, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.599267601966858, 'logps/rejected': -6.411014556884766, 'logps/chosen': -2.4128458499908447, 'logits/rejected': -1.897993803024292, 'logits/chosen': -2.83239483833313, 'nll_loss': 2.3904495239257812, 'log_odds_ratio': -0.20256087183952332, 'log_odds_chosen': 4.102078437805176, 'logps/chosen_prompt': -0.7408974170684814, 'logps/rejected_prompt': -0.9321101307868958, 'logits/chosen_prompt': -2.7054226398468018, 'logits/rejected_prompt': -2.6901042461395264, 'logps/chosen_both': -2.3911867141723633, 'logps/rejected_both': -6.338159084320068, 'epoch': 1.58}
 79%|███████▉  | 1970/2500 [1:13:05<51:30,  5.83s/it] 79%|███████▉  | 1971/2500 [1:13:10<50:00,  5.67s/it] 79%|███████▉  | 1972/2500 [1:13:16<49:21,  5.61s/it] 79%|███████▉  | 1973/2500 [1:13:21<48:34,  5.53s/it] 79%|███████▉  | 1974/2500 [1:13:27<48:51,  5.57s/it] 79%|███████▉  | 1975/2500 [1:13:32<48:15,  5.52s/it] 79%|███████▉  | 1976/2500 [1:13:38<48:12,  5.52s/it] 79%|███████▉  | 1977/2500 [1:13:44<48:34,  5.57s/it] 79%|███████▉  | 1978/2500 [1:13:49<48:50,  5.61s/it] 79%|███████▉  | 1979/2500 [1:13:55<47:50,  5.51s/it] 79%|███████▉  | 1980/2500 [1:14:00<48:01,  5.54s/it]                                                     {'loss': 2.0155, 'grad_norm': 11.481137492856341, 'learning_rate': 5.150240033804116e-06, 'rewards/chosen': -0.7543237805366516, 'rewards/rejected': -2.3291945457458496, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.5748708248138428, 'logps/rejected': -5.822986602783203, 'logps/chosen': -1.8858095407485962, 'logits/rejected': -2.0364396572113037, 'logits/chosen': -2.98791766166687, 'nll_loss': 1.8684860467910767, 'log_odds_ratio': -0.2303629219532013, 'log_odds_chosen': 4.065099716186523, 'logps/chosen_prompt': -0.8046451807022095, 'logps/rejected_prompt': -1.0397605895996094, 'logits/chosen_prompt': -2.70316743850708, 'logits/rejected_prompt': -2.6766979694366455, 'logps/chosen_both': -1.869710922241211, 'logps/rejected_both': -5.747632026672363, 'epoch': 1.58}
 79%|███████▉  | 1980/2500 [1:14:00<48:01,  5.54s/it] 79%|███████▉  | 1981/2500 [1:14:05<47:05,  5.44s/it] 79%|███████▉  | 1982/2500 [1:14:11<46:49,  5.42s/it] 79%|███████▉  | 1983/2500 [1:14:17<47:54,  5.56s/it] 79%|███████▉  | 1984/2500 [1:14:22<47:48,  5.56s/it] 79%|███████▉  | 1985/2500 [1:14:30<53:23,  6.22s/it] 79%|███████▉  | 1986/2500 [1:14:35<51:33,  6.02s/it] 79%|███████▉  | 1987/2500 [1:14:42<52:19,  6.12s/it] 80%|███████▉  | 1988/2500 [1:14:48<51:51,  6.08s/it] 80%|███████▉  | 1989/2500 [1:14:54<50:51,  5.97s/it] 80%|███████▉  | 1990/2500 [1:14:59<49:54,  5.87s/it]                                                     {'loss': 2.0436, 'grad_norm': 0.19546749157088109, 'learning_rate': 4.960825378228082e-06, 'rewards/chosen': -0.7729231119155884, 'rewards/rejected': -3.5039641857147217, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7310409545898438, 'logps/rejected': -8.759910583496094, 'logps/chosen': -1.9323078393936157, 'logits/rejected': -1.2503888607025146, 'logits/chosen': -2.972013473510742, 'nll_loss': 1.9159834384918213, 'log_odds_ratio': -0.0011325248051434755, 'log_odds_chosen': 6.999327182769775, 'logps/chosen_prompt': -0.8072878122329712, 'logps/rejected_prompt': -1.0308054685592651, 'logits/chosen_prompt': -2.688580274581909, 'logits/rejected_prompt': -2.6795592308044434, 'logps/chosen_both': -1.9167814254760742, 'logps/rejected_both': -8.641786575317383, 'epoch': 1.59}
 80%|███████▉  | 1990/2500 [1:14:59<49:54,  5.87s/it] 80%|███████▉  | 1991/2500 [1:15:05<48:35,  5.73s/it] 80%|███████▉  | 1992/2500 [1:15:10<48:20,  5.71s/it] 80%|███████▉  | 1993/2500 [1:15:16<47:23,  5.61s/it] 80%|███████▉  | 1994/2500 [1:15:21<46:49,  5.55s/it] 80%|███████▉  | 1995/2500 [1:15:30<55:21,  6.58s/it] 80%|███████▉  | 1996/2500 [1:15:36<53:11,  6.33s/it] 80%|███████▉  | 1997/2500 [1:15:42<52:09,  6.22s/it] 80%|███████▉  | 1998/2500 [1:15:47<49:21,  5.90s/it] 80%|███████▉  | 1999/2500 [1:15:52<48:30,  5.81s/it] 80%|████████  | 2000/2500 [1:15:58<47:13,  5.67s/it]                                                     {'loss': 1.9481, 'grad_norm': 0.19729998370783036, 'learning_rate': 4.7745751406263165e-06, 'rewards/chosen': -0.7511903047561646, 'rewards/rejected': -3.3883118629455566, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6371216773986816, 'logps/rejected': -8.470778465270996, 'logps/chosen': -1.8779758214950562, 'logits/rejected': -1.347316861152649, 'logits/chosen': -2.9636759757995605, 'nll_loss': 1.8597233295440674, 'log_odds_ratio': -0.002975467126816511, 'log_odds_chosen': 6.769123077392578, 'logps/chosen_prompt': -0.7904615998268127, 'logps/rejected_prompt': -1.070899248123169, 'logits/chosen_prompt': -2.6940860748291016, 'logits/rejected_prompt': -2.673450469970703, 'logps/chosen_both': -1.8605492115020752, 'logps/rejected_both': -8.343839645385742, 'epoch': 1.6}
 80%|████████  | 2000/2500 [1:15:58<47:13,  5.67s/it] 80%|████████  | 2001/2500 [1:16:04<47:37,  5.73s/it] 80%|████████  | 2002/2500 [1:16:10<48:12,  5.81s/it] 80%|████████  | 2003/2500 [1:16:15<47:41,  5.76s/it] 80%|████████  | 2004/2500 [1:16:21<47:09,  5.70s/it] 80%|████████  | 2005/2500 [1:16:28<50:37,  6.14s/it] 80%|████████  | 2006/2500 [1:16:34<49:01,  5.95s/it] 80%|████████  | 2007/2500 [1:16:40<48:59,  5.96s/it] 80%|████████  | 2008/2500 [1:16:46<48:53,  5.96s/it] 80%|████████  | 2009/2500 [1:16:51<46:57,  5.74s/it] 80%|████████  | 2010/2500 [1:16:56<46:14,  5.66s/it]                                                     {'loss': 1.9701, 'grad_norm': 4.863188798039148, 'learning_rate': 4.591518732070402e-06, 'rewards/chosen': -0.8000348806381226, 'rewards/rejected': -2.6906776428222656, 'rewards/accuracies': 1.0, 'rewards/margins': 1.890642762184143, 'logps/rejected': -6.726694583892822, 'logps/chosen': -2.000087261199951, 'logits/rejected': -1.7899357080459595, 'logits/chosen': -2.997523784637451, 'nll_loss': 1.9786475896835327, 'log_odds_ratio': -0.14266851544380188, 'log_odds_chosen': 4.84625768661499, 'logps/chosen_prompt': -0.7608593106269836, 'logps/rejected_prompt': -0.9442145228385925, 'logits/chosen_prompt': -2.7061197757720947, 'logits/rejected_prompt': -2.6873691082000732, 'logps/chosen_both': -1.9791902303695679, 'logps/rejected_both': -6.622114658355713, 'epoch': 1.61}
 80%|████████  | 2010/2500 [1:16:56<46:14,  5.66s/it] 80%|████████  | 2011/2500 [1:17:03<47:53,  5.88s/it] 80%|████████  | 2012/2500 [1:17:09<48:39,  5.98s/it] 81%|████████  | 2013/2500 [1:17:14<47:02,  5.80s/it] 81%|████████  | 2014/2500 [1:17:20<46:25,  5.73s/it] 81%|████████  | 2015/2500 [1:17:26<46:41,  5.78s/it] 81%|████████  | 2016/2500 [1:17:32<47:41,  5.91s/it] 81%|████████  | 2017/2500 [1:17:38<47:08,  5.86s/it] 81%|████████  | 2018/2500 [1:17:43<46:10,  5.75s/it] 81%|████████  | 2019/2500 [1:17:49<45:20,  5.66s/it] 81%|████████  | 2020/2500 [1:17:55<46:23,  5.80s/it]                                                     {'loss': 2.0192, 'grad_norm': 0.564641891632149, 'learning_rate': 4.411685059289314e-06, 'rewards/chosen': -0.7611441612243652, 'rewards/rejected': -3.177661895751953, 'rewards/accuracies': 1.0, 'rewards/margins': 2.416517972946167, 'logps/rejected': -7.944155216217041, 'logps/chosen': -1.902860403060913, 'logits/rejected': -1.4330286979675293, 'logits/chosen': -2.9463534355163574, 'nll_loss': 1.8885453939437866, 'log_odds_ratio': -0.0703711062669754, 'log_odds_chosen': 6.200541973114014, 'logps/chosen_prompt': -1.0047961473464966, 'logps/rejected_prompt': -1.1412936449050903, 'logits/chosen_prompt': -2.689056873321533, 'logits/rejected_prompt': -2.672241687774658, 'logps/chosen_both': -1.889167070388794, 'logps/rejected_both': -7.828339576721191, 'epoch': 1.62}
 81%|████████  | 2020/2500 [1:17:55<46:23,  5.80s/it] 81%|████████  | 2021/2500 [1:18:04<54:45,  6.86s/it] 81%|████████  | 2022/2500 [1:18:09<51:09,  6.42s/it] 81%|████████  | 2023/2500 [1:18:16<50:50,  6.39s/it] 81%|████████  | 2024/2500 [1:18:21<48:42,  6.14s/it] 81%|████████  | 2025/2500 [1:18:29<51:21,  6.49s/it] 81%|████████  | 2026/2500 [1:18:34<48:04,  6.09s/it] 81%|████████  | 2027/2500 [1:18:40<47:49,  6.07s/it] 81%|████████  | 2028/2500 [1:18:46<47:30,  6.04s/it] 81%|████████  | 2029/2500 [1:18:51<44:57,  5.73s/it] 81%|████████  | 2030/2500 [1:18:56<44:40,  5.70s/it]                                                     {'loss': 1.964, 'grad_norm': 0.33737248376862683, 'learning_rate': 4.235102520104681e-06, 'rewards/chosen': -0.7627428770065308, 'rewards/rejected': -3.2448678016662598, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4821245670318604, 'logps/rejected': -8.11216926574707, 'logps/chosen': -1.9068572521209717, 'logits/rejected': -1.432997465133667, 'logits/chosen': -3.027432918548584, 'nll_loss': 1.8875757455825806, 'log_odds_ratio': -0.009977634064853191, 'log_odds_chosen': 6.389623165130615, 'logps/chosen_prompt': -0.7403895258903503, 'logps/rejected_prompt': -0.9739906191825867, 'logits/chosen_prompt': -2.6685585975646973, 'logits/rejected_prompt': -2.6544837951660156, 'logps/chosen_both': -1.8887401819229126, 'logps/rejected_both': -8.00120735168457, 'epoch': 1.62}
 81%|████████  | 2030/2500 [1:18:56<44:40,  5.70s/it] 81%|████████  | 2031/2500 [1:19:02<44:41,  5.72s/it] 81%|████████▏ | 2032/2500 [1:19:08<44:05,  5.65s/it] 81%|████████▏ | 2033/2500 [1:19:16<49:16,  6.33s/it] 81%|████████▏ | 2034/2500 [1:19:21<47:41,  6.14s/it] 81%|████████▏ | 2035/2500 [1:19:27<47:00,  6.06s/it] 81%|████████▏ | 2036/2500 [1:19:32<44:55,  5.81s/it] 81%|████████▏ | 2037/2500 [1:19:38<44:04,  5.71s/it] 82%|████████▏ | 2038/2500 [1:19:44<44:13,  5.74s/it] 82%|████████▏ | 2039/2500 [1:19:49<42:27,  5.53s/it] 82%|████████▏ | 2040/2500 [1:19:55<43:14,  5.64s/it]                                                     {'loss': 1.9373, 'grad_norm': 0.2988030145836119, 'learning_rate': 4.061798998946459e-06, 'rewards/chosen': -0.7986812591552734, 'rewards/rejected': -2.5035524368286133, 'rewards/accuracies': 1.0, 'rewards/margins': 1.7048711776733398, 'logps/rejected': -6.258880615234375, 'logps/chosen': -1.9967029094696045, 'logits/rejected': -1.9146404266357422, 'logits/chosen': -2.959590435028076, 'nll_loss': 1.973345160484314, 'log_odds_ratio': -0.2160888910293579, 'log_odds_chosen': 4.362215995788574, 'logps/chosen_prompt': -0.7355998754501343, 'logps/rejected_prompt': -0.9319154024124146, 'logits/chosen_prompt': -2.6875030994415283, 'logits/rejected_prompt': -2.657719135284424, 'logps/chosen_both': -1.9751638174057007, 'logps/rejected_both': -6.172951698303223, 'epoch': 1.63}
 82%|████████▏ | 2040/2500 [1:19:55<43:14,  5.64s/it] 82%|████████▏ | 2041/2500 [1:20:00<42:37,  5.57s/it] 82%|████████▏ | 2042/2500 [1:20:05<42:06,  5.52s/it] 82%|████████▏ | 2043/2500 [1:20:12<44:32,  5.85s/it] 82%|████████▏ | 2044/2500 [1:20:18<44:52,  5.90s/it] 82%|████████▏ | 2045/2500 [1:20:24<44:31,  5.87s/it] 82%|████████▏ | 2046/2500 [1:20:29<42:48,  5.66s/it] 82%|████████▏ | 2047/2500 [1:20:38<50:20,  6.67s/it] 82%|████████▏ | 2048/2500 [1:20:44<48:21,  6.42s/it] 82%|████████▏ | 2049/2500 [1:20:50<47:07,  6.27s/it] 82%|████████▏ | 2050/2500 [1:20:56<46:22,  6.18s/it]                                                     {'loss': 2.0454, 'grad_norm': 0.3439254364456004, 'learning_rate': 3.891801862449629e-06, 'rewards/chosen': -0.805147647857666, 'rewards/rejected': -3.320870876312256, 'rewards/accuracies': 1.0, 'rewards/margins': 2.51572322845459, 'logps/rejected': -8.302176475524902, 'logps/chosen': -2.012869119644165, 'logits/rejected': -1.3685810565948486, 'logits/chosen': -2.9270541667938232, 'nll_loss': 1.9898681640625, 'log_odds_ratio': -0.003478050697594881, 'log_odds_chosen': 6.436378479003906, 'logps/chosen_prompt': -0.8390440940856934, 'logps/rejected_prompt': -1.0366463661193848, 'logits/chosen_prompt': -2.6802194118499756, 'logits/rejected_prompt': -2.6525990962982178, 'logps/chosen_both': -1.9908316135406494, 'logps/rejected_both': -8.158720016479492, 'epoch': 1.64}
 82%|████████▏ | 2050/2500 [1:20:56<46:22,  6.18s/it] 82%|████████▏ | 2051/2500 [1:21:01<45:04,  6.02s/it] 82%|████████▏ | 2052/2500 [1:21:08<47:07,  6.31s/it] 82%|████████▏ | 2053/2500 [1:21:15<46:47,  6.28s/it] 82%|████████▏ | 2054/2500 [1:21:20<45:09,  6.08s/it] 82%|████████▏ | 2055/2500 [1:21:26<45:20,  6.11s/it] 82%|████████▏ | 2056/2500 [1:21:32<44:21,  5.99s/it] 82%|████████▏ | 2057/2500 [1:21:38<44:53,  6.08s/it] 82%|████████▏ | 2058/2500 [1:21:46<48:40,  6.61s/it] 82%|████████▏ | 2059/2500 [1:21:53<47:53,  6.52s/it] 82%|████████▏ | 2060/2500 [1:21:58<45:33,  6.21s/it]                                                     {'loss': 2.0279, 'grad_norm': 0.1735841219555294, 'learning_rate': 3.725137955132707e-06, 'rewards/chosen': -0.8695524334907532, 'rewards/rejected': -3.2213504314422607, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3517978191375732, 'logps/rejected': -8.053375244140625, 'logps/chosen': -2.1738810539245605, 'logits/rejected': -1.447820782661438, 'logits/chosen': -2.926696538925171, 'nll_loss': 2.154222011566162, 'log_odds_ratio': -0.011558645404875278, 'log_odds_chosen': 6.027080535888672, 'logps/chosen_prompt': -0.8342956304550171, 'logps/rejected_prompt': -1.0617144107818604, 'logits/chosen_prompt': -2.7070040702819824, 'logits/rejected_prompt': -2.6682450771331787, 'logps/chosen_both': -2.1552398204803467, 'logps/rejected_both': -7.939155578613281, 'epoch': 1.65}
 82%|████████▏ | 2060/2500 [1:21:58<45:33,  6.21s/it] 82%|████████▏ | 2061/2500 [1:22:03<42:54,  5.87s/it] 82%|████████▏ | 2062/2500 [1:22:10<46:10,  6.33s/it] 83%|████████▎ | 2063/2500 [1:22:16<44:02,  6.05s/it] 83%|████████▎ | 2064/2500 [1:22:21<42:31,  5.85s/it] 83%|████████▎ | 2065/2500 [1:22:27<42:01,  5.80s/it] 83%|████████▎ | 2066/2500 [1:22:33<41:38,  5.76s/it] 83%|████████▎ | 2067/2500 [1:22:40<44:56,  6.23s/it] 83%|████████▎ | 2068/2500 [1:22:45<42:58,  5.97s/it] 83%|████████▎ | 2069/2500 [1:22:51<42:32,  5.92s/it] 83%|████████▎ | 2070/2500 [1:22:57<42:54,  5.99s/it]                                                     {'loss': 2.0253, 'grad_norm': 0.24058929721941633, 'learning_rate': 3.561833595158698e-06, 'rewards/chosen': -0.8021367788314819, 'rewards/rejected': -2.9739089012145996, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1717724800109863, 'logps/rejected': -7.434772491455078, 'logps/chosen': -2.0053420066833496, 'logits/rejected': -1.5194802284240723, 'logits/chosen': -2.9375696182250977, 'nll_loss': 1.9858620166778564, 'log_odds_ratio': -0.1392855942249298, 'log_odds_chosen': 5.560084819793701, 'logps/chosen_prompt': -0.7362433075904846, 'logps/rejected_prompt': -0.9465538263320923, 'logits/chosen_prompt': -2.691044330596924, 'logits/rejected_prompt': -2.679962396621704, 'logps/chosen_both': -1.986762285232544, 'logps/rejected_both': -7.328239440917969, 'epoch': 1.66}
 83%|████████▎ | 2070/2500 [1:22:57<42:54,  5.99s/it] 83%|████████▎ | 2071/2500 [1:23:03<43:23,  6.07s/it] 83%|████████▎ | 2072/2500 [1:23:09<42:34,  5.97s/it] 83%|████████▎ | 2073/2500 [1:23:14<40:42,  5.72s/it] 83%|████████▎ | 2074/2500 [1:23:21<41:42,  5.87s/it] 83%|████████▎ | 2075/2500 [1:23:28<44:29,  6.28s/it] 83%|████████▎ | 2076/2500 [1:23:33<42:39,  6.04s/it] 83%|████████▎ | 2077/2500 [1:23:39<42:27,  6.02s/it] 83%|████████▎ | 2078/2500 [1:23:45<40:58,  5.83s/it] 83%|████████▎ | 2079/2500 [1:23:50<40:41,  5.80s/it] 83%|████████▎ | 2080/2500 [1:23:56<39:29,  5.64s/it]                                                     {'loss': 1.9956, 'grad_norm': 0.2098739954588768, 'learning_rate': 3.4019145701791184e-06, 'rewards/chosen': -0.8145160675048828, 'rewards/rejected': -3.431370973587036, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6168549060821533, 'logps/rejected': -8.5784273147583, 'logps/chosen': -2.036290407180786, 'logits/rejected': -1.2613775730133057, 'logits/chosen': -2.936375379562378, 'nll_loss': 2.015052318572998, 'log_odds_ratio': -0.0027137277647852898, 'log_odds_chosen': 6.693533897399902, 'logps/chosen_prompt': -0.8616547584533691, 'logps/rejected_prompt': -1.0273234844207764, 'logits/chosen_prompt': -2.694241523742676, 'logits/rejected_prompt': -2.6604161262512207, 'logps/chosen_both': -2.0157952308654785, 'logps/rejected_both': -8.452858924865723, 'epoch': 1.66}
 83%|████████▎ | 2080/2500 [1:23:56<39:29,  5.64s/it] 83%|████████▎ | 2081/2500 [1:24:01<38:45,  5.55s/it] 83%|████████▎ | 2082/2500 [1:24:07<38:37,  5.54s/it] 83%|████████▎ | 2083/2500 [1:24:14<41:37,  5.99s/it] 83%|████████▎ | 2084/2500 [1:24:19<40:31,  5.84s/it] 83%|████████▎ | 2085/2500 [1:24:25<40:32,  5.86s/it] 83%|████████▎ | 2086/2500 [1:24:31<40:48,  5.91s/it] 83%|████████▎ | 2087/2500 [1:24:36<39:27,  5.73s/it] 84%|████████▎ | 2088/2500 [1:24:42<38:59,  5.68s/it] 84%|████████▎ | 2089/2500 [1:24:47<38:47,  5.66s/it] 84%|████████▎ | 2090/2500 [1:24:53<37:45,  5.53s/it]                                                     {'loss': 1.9836, 'grad_norm': 0.9010627706713868, 'learning_rate': 3.245406133261858e-06, 'rewards/chosen': -0.7925900816917419, 'rewards/rejected': -2.941091775894165, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1485018730163574, 'logps/rejected': -7.352729797363281, 'logps/chosen': -1.9814752340316772, 'logits/rejected': -1.5538198947906494, 'logits/chosen': -2.9757602214813232, 'nll_loss': 1.9610350131988525, 'log_odds_ratio': -0.11630578339099884, 'log_odds_chosen': 5.498623847961426, 'logps/chosen_prompt': -0.7859075665473938, 'logps/rejected_prompt': -0.9275178909301758, 'logits/chosen_prompt': -2.6881608963012695, 'logits/rejected_prompt': -2.67132306098938, 'logps/chosen_both': -1.961381196975708, 'logps/rejected_both': -7.239079475402832, 'epoch': 1.67}
 84%|████████▎ | 2090/2500 [1:24:53<37:45,  5.53s/it] 84%|████████▎ | 2091/2500 [1:24:58<37:45,  5.54s/it] 84%|████████▎ | 2092/2500 [1:25:04<38:04,  5.60s/it] 84%|████████▎ | 2093/2500 [1:25:10<37:49,  5.58s/it] 84%|████████▍ | 2094/2500 [1:25:18<44:26,  6.57s/it] 84%|████████▍ | 2095/2500 [1:25:24<42:32,  6.30s/it] 84%|████████▍ | 2096/2500 [1:25:29<39:55,  5.93s/it] 84%|████████▍ | 2097/2500 [1:25:35<39:55,  5.94s/it] 84%|████████▍ | 2098/2500 [1:25:41<39:11,  5.85s/it] 84%|████████▍ | 2099/2500 [1:25:47<39:31,  5.91s/it] 84%|████████▍ | 2100/2500 [1:25:52<38:15,  5.74s/it]                                                     {'loss': 2.0463, 'grad_norm': 0.5746641704885379, 'learning_rate': 3.092332998903416e-06, 'rewards/chosen': -0.8402625918388367, 'rewards/rejected': -2.9273805618286133, 'rewards/accuracies': 1.0, 'rewards/margins': 2.087117910385132, 'logps/rejected': -7.318450927734375, 'logps/chosen': -2.100656747817993, 'logits/rejected': -1.6246936321258545, 'logits/chosen': -2.9435055255889893, 'nll_loss': 2.0747833251953125, 'log_odds_ratio': -0.13957300782203674, 'log_odds_chosen': 5.321537971496582, 'logps/chosen_prompt': -0.7967726588249207, 'logps/rejected_prompt': -0.9595252871513367, 'logits/chosen_prompt': -2.7158000469207764, 'logits/rejected_prompt': -2.6734907627105713, 'logps/chosen_both': -2.076551914215088, 'logps/rejected_both': -7.197140693664551, 'epoch': 1.68}
 84%|████████▍ | 2100/2500 [1:25:52<38:15,  5.74s/it] 84%|████████▍ | 2101/2500 [1:25:58<37:23,  5.62s/it] 84%|████████▍ | 2102/2500 [1:26:04<38:03,  5.74s/it] 84%|████████▍ | 2103/2500 [1:26:09<38:11,  5.77s/it] 84%|████████▍ | 2104/2500 [1:26:15<38:12,  5.79s/it] 84%|████████▍ | 2105/2500 [1:26:20<37:05,  5.64s/it] 84%|████████▍ | 2106/2500 [1:26:26<36:14,  5.52s/it] 84%|████████▍ | 2107/2500 [1:26:31<36:30,  5.57s/it] 84%|████████▍ | 2108/2500 [1:26:37<36:21,  5.57s/it] 84%|████████▍ | 2109/2500 [1:26:43<36:53,  5.66s/it] 84%|████████▍ | 2110/2500 [1:26:48<35:52,  5.52s/it]                                                     {'loss': 2.1247, 'grad_norm': 0.266534824893988, 'learning_rate': 2.942719339126171e-06, 'rewards/chosen': -0.8023418188095093, 'rewards/rejected': -2.871957302093506, 'rewards/accuracies': 1.0, 'rewards/margins': 2.069615125656128, 'logps/rejected': -7.179893493652344, 'logps/chosen': -2.005854606628418, 'logits/rejected': -1.6252539157867432, 'logits/chosen': -2.910923957824707, 'nll_loss': 1.9904718399047852, 'log_odds_ratio': -0.14139609038829803, 'log_odds_chosen': 5.295780658721924, 'logps/chosen_prompt': -0.8165298700332642, 'logps/rejected_prompt': -0.9019848704338074, 'logits/chosen_prompt': -2.6802258491516113, 'logits/rejected_prompt': -2.6550300121307373, 'logps/chosen_both': -1.9909772872924805, 'logps/rejected_both': -7.098330020904541, 'epoch': 1.69}
 84%|████████▍ | 2110/2500 [1:26:48<35:52,  5.52s/it] 84%|████████▍ | 2111/2500 [1:26:54<35:50,  5.53s/it] 84%|████████▍ | 2112/2500 [1:26:59<36:22,  5.63s/it] 85%|████████▍ | 2113/2500 [1:27:05<35:55,  5.57s/it] 85%|████████▍ | 2114/2500 [1:27:11<36:54,  5.74s/it] 85%|████████▍ | 2115/2500 [1:27:17<36:23,  5.67s/it] 85%|████████▍ | 2116/2500 [1:27:22<35:05,  5.48s/it] 85%|████████▍ | 2117/2500 [1:27:27<35:08,  5.50s/it] 85%|████████▍ | 2118/2500 [1:27:32<34:36,  5.44s/it] 85%|████████▍ | 2119/2500 [1:27:38<34:51,  5.49s/it] 85%|████████▍ | 2120/2500 [1:27:44<34:59,  5.53s/it]                                                     {'loss': 2.0088, 'grad_norm': 0.1789702981704489, 'learning_rate': 2.7965887796613884e-06, 'rewards/chosen': -0.7682700157165527, 'rewards/rejected': -3.5595951080322266, 'rewards/accuracies': 1.0, 'rewards/margins': 2.791325092315674, 'logps/rejected': -8.898987770080566, 'logps/chosen': -1.9206749200820923, 'logits/rejected': -1.1409399509429932, 'logits/chosen': -3.009477138519287, 'nll_loss': 1.902294397354126, 'log_odds_ratio': -0.0008628932991996408, 'log_odds_chosen': 7.156485080718994, 'logps/chosen_prompt': -0.8406771421432495, 'logps/rejected_prompt': -0.9535967111587524, 'logits/chosen_prompt': -2.693809747695923, 'logits/rejected_prompt': -2.6666159629821777, 'logps/chosen_both': -1.9032020568847656, 'logps/rejected_both': -8.761430740356445, 'epoch': 1.7}
 85%|████████▍ | 2120/2500 [1:27:44<34:59,  5.53s/it] 85%|████████▍ | 2121/2500 [1:27:50<36:04,  5.71s/it] 85%|████████▍ | 2122/2500 [1:27:56<36:24,  5.78s/it] 85%|████████▍ | 2123/2500 [1:28:01<35:31,  5.66s/it] 85%|████████▍ | 2124/2500 [1:28:07<36:47,  5.87s/it] 85%|████████▌ | 2125/2500 [1:28:13<35:58,  5.76s/it] 85%|████████▌ | 2126/2500 [1:28:18<35:28,  5.69s/it] 85%|████████▌ | 2127/2500 [1:28:24<35:11,  5.66s/it] 85%|████████▌ | 2128/2500 [1:28:30<36:14,  5.85s/it] 85%|████████▌ | 2129/2500 [1:28:36<35:13,  5.70s/it] 85%|████████▌ | 2130/2500 [1:28:42<35:35,  5.77s/it]                                                     {'loss': 2.0591, 'grad_norm': 0.3688673907825976, 'learning_rate': 2.6539643962184057e-06, 'rewards/chosen': -0.7883628606796265, 'rewards/rejected': -3.064112424850464, 'rewards/accuracies': 1.0, 'rewards/margins': 2.275749683380127, 'logps/rejected': -7.660280704498291, 'logps/chosen': -1.9709069728851318, 'logits/rejected': -1.4569532871246338, 'logits/chosen': -2.898824691772461, 'nll_loss': 1.9551252126693726, 'log_odds_ratio': -0.13902898132801056, 'log_odds_chosen': 5.813083648681641, 'logps/chosen_prompt': -0.7707621455192566, 'logps/rejected_prompt': -0.890097439289093, 'logits/chosen_prompt': -2.677579641342163, 'logits/rejected_prompt': -2.6577789783477783, 'logps/chosen_both': -1.9560848474502563, 'logps/rejected_both': -7.572904109954834, 'epoch': 1.7}
 85%|████████▌ | 2130/2500 [1:28:42<35:35,  5.77s/it] 85%|████████▌ | 2131/2500 [1:28:48<35:49,  5.82s/it] 85%|████████▌ | 2132/2500 [1:28:53<35:14,  5.75s/it] 85%|████████▌ | 2133/2500 [1:28:59<35:44,  5.84s/it] 85%|████████▌ | 2134/2500 [1:29:05<35:39,  5.84s/it] 85%|████████▌ | 2135/2500 [1:29:11<35:27,  5.83s/it] 85%|████████▌ | 2136/2500 [1:29:17<35:28,  5.85s/it] 85%|████████▌ | 2137/2500 [1:29:22<34:37,  5.72s/it] 86%|████████▌ | 2138/2500 [1:29:28<34:25,  5.71s/it] 86%|████████▌ | 2139/2500 [1:29:33<33:48,  5.62s/it] 86%|████████▌ | 2140/2500 [1:29:39<33:38,  5.61s/it]                                                     {'loss': 1.9656, 'grad_norm': 0.20304528383349504, 'learning_rate': 2.514868710840723e-06, 'rewards/chosen': -0.8026010394096375, 'rewards/rejected': -3.393918991088867, 'rewards/accuracies': 1.0, 'rewards/margins': 2.591317892074585, 'logps/rejected': -8.484796524047852, 'logps/chosen': -2.006502628326416, 'logits/rejected': -1.3016430139541626, 'logits/chosen': -2.875211238861084, 'nll_loss': 1.991927146911621, 'log_odds_ratio': -0.01039933506399393, 'log_odds_chosen': 6.623157501220703, 'logps/chosen_prompt': -0.8087636828422546, 'logps/rejected_prompt': -1.0334651470184326, 'logits/chosen_prompt': -2.6680877208709717, 'logits/rejected_prompt': -2.6645376682281494, 'logps/chosen_both': -1.9923961162567139, 'logps/rejected_both': -8.39560317993164, 'epoch': 1.71}
 86%|████████▌ | 2140/2500 [1:29:39<33:38,  5.61s/it] 86%|████████▌ | 2141/2500 [1:29:44<32:54,  5.50s/it] 86%|████████▌ | 2142/2500 [1:29:50<33:16,  5.58s/it] 86%|████████▌ | 2143/2500 [1:29:55<33:12,  5.58s/it] 86%|████████▌ | 2144/2500 [1:30:01<33:27,  5.64s/it] 86%|████████▌ | 2145/2500 [1:30:07<33:56,  5.74s/it] 86%|████████▌ | 2146/2500 [1:30:13<34:04,  5.78s/it] 86%|████████▌ | 2147/2500 [1:30:19<34:27,  5.86s/it] 86%|████████▌ | 2148/2500 [1:30:25<34:27,  5.87s/it] 86%|████████▌ | 2149/2500 [1:30:31<34:19,  5.87s/it] 86%|████████▌ | 2150/2500 [1:30:36<33:06,  5.68s/it]                                                     {'loss': 1.9636, 'grad_norm': 0.4394142622225324, 'learning_rate': 2.379323688349516e-06, 'rewards/chosen': -0.7923983335494995, 'rewards/rejected': -3.055945873260498, 'rewards/accuracies': 1.0, 'rewards/margins': 2.263547420501709, 'logps/rejected': -7.639864921569824, 'logps/chosen': -1.9809958934783936, 'logits/rejected': -1.492988109588623, 'logits/chosen': -2.8944690227508545, 'nll_loss': 1.9631407260894775, 'log_odds_ratio': -0.09623978286981583, 'log_odds_chosen': 5.78470516204834, 'logps/chosen_prompt': -0.8619140386581421, 'logps/rejected_prompt': -0.9760622978210449, 'logits/chosen_prompt': -2.682424545288086, 'logits/rejected_prompt': -2.6484761238098145, 'logps/chosen_both': -1.963255524635315, 'logps/rejected_both': -7.534977912902832, 'epoch': 1.72}
 86%|████████▌ | 2150/2500 [1:30:36<33:06,  5.68s/it] 86%|████████▌ | 2151/2500 [1:30:41<32:23,  5.57s/it] 86%|████████▌ | 2152/2500 [1:30:47<32:29,  5.60s/it] 86%|████████▌ | 2153/2500 [1:30:53<32:16,  5.58s/it] 86%|████████▌ | 2154/2500 [1:30:59<32:46,  5.68s/it] 86%|████████▌ | 2155/2500 [1:31:04<31:49,  5.53s/it] 86%|████████▌ | 2156/2500 [1:31:09<31:37,  5.52s/it] 86%|████████▋ | 2157/2500 [1:31:15<31:52,  5.58s/it] 86%|████████▋ | 2158/2500 [1:31:20<31:31,  5.53s/it] 86%|████████▋ | 2159/2500 [1:31:26<32:25,  5.71s/it] 86%|████████▋ | 2160/2500 [1:31:31<31:05,  5.49s/it]                                                     {'loss': 2.0872, 'grad_norm': 0.29007029588061106, 'learning_rate': 2.2473507328751086e-06, 'rewards/chosen': -0.8032106161117554, 'rewards/rejected': -2.998034954071045, 'rewards/accuracies': 1.0, 'rewards/margins': 2.19482421875, 'logps/rejected': -7.49508810043335, 'logps/chosen': -2.008026599884033, 'logits/rejected': -1.546983003616333, 'logits/chosen': -2.939020872116089, 'nll_loss': 1.9894702434539795, 'log_odds_ratio': -0.07557649165391922, 'log_odds_chosen': 5.6166605949401855, 'logps/chosen_prompt': -0.7306305170059204, 'logps/rejected_prompt': -0.9255159497261047, 'logits/chosen_prompt': -2.689547061920166, 'logits/rejected_prompt': -2.6722054481506348, 'logps/chosen_both': -1.990046739578247, 'logps/rejected_both': -7.397957801818848, 'epoch': 1.73}
 86%|████████▋ | 2160/2500 [1:31:31<31:05,  5.49s/it] 86%|████████▋ | 2161/2500 [1:31:37<31:48,  5.63s/it] 86%|████████▋ | 2162/2500 [1:31:43<31:45,  5.64s/it] 87%|████████▋ | 2163/2500 [1:31:48<31:15,  5.57s/it] 87%|████████▋ | 2164/2500 [1:31:55<33:01,  5.90s/it] 87%|████████▋ | 2165/2500 [1:32:01<32:42,  5.86s/it] 87%|████████▋ | 2166/2500 [1:32:06<31:41,  5.69s/it] 87%|████████▋ | 2167/2500 [1:32:12<31:22,  5.65s/it] 87%|████████▋ | 2168/2500 [1:32:17<30:56,  5.59s/it] 87%|████████▋ | 2169/2500 [1:32:23<30:57,  5.61s/it] 87%|████████▋ | 2170/2500 [1:32:28<30:30,  5.55s/it]                                                     {'loss': 1.9533, 'grad_norm': 0.18189736715103325, 'learning_rate': 2.118970684477062e-06, 'rewards/chosen': -0.743049144744873, 'rewards/rejected': -3.2470314502716064, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5039825439453125, 'logps/rejected': -8.117578506469727, 'logps/chosen': -1.8576228618621826, 'logits/rejected': -1.4166488647460938, 'logits/chosen': -2.9344184398651123, 'nll_loss': 1.8420631885528564, 'log_odds_ratio': -0.003319238545373082, 'log_odds_chosen': 6.437538146972656, 'logps/chosen_prompt': -0.8366341590881348, 'logps/rejected_prompt': -1.0763131380081177, 'logits/chosen_prompt': -2.6941819190979004, 'logits/rejected_prompt': -2.659660816192627, 'logps/chosen_both': -1.84250807762146, 'logps/rejected_both': -8.010236740112305, 'epoch': 1.74}
 87%|████████▋ | 2170/2500 [1:32:28<30:30,  5.55s/it] 87%|████████▋ | 2171/2500 [1:32:34<30:31,  5.57s/it] 87%|████████▋ | 2172/2500 [1:32:40<31:02,  5.68s/it] 87%|████████▋ | 2173/2500 [1:32:45<30:23,  5.58s/it] 87%|████████▋ | 2174/2500 [1:32:51<31:25,  5.78s/it] 87%|████████▋ | 2175/2500 [1:32:57<31:37,  5.84s/it] 87%|████████▋ | 2176/2500 [1:33:03<30:43,  5.69s/it] 87%|████████▋ | 2177/2500 [1:33:08<29:23,  5.46s/it] 87%|████████▋ | 2178/2500 [1:33:14<30:12,  5.63s/it] 87%|████████▋ | 2179/2500 [1:33:19<29:28,  5.51s/it] 87%|████████▋ | 2180/2500 [1:33:25<30:06,  5.65s/it]                                                     {'loss': 2.0888, 'grad_norm': 8.753161200112954, 'learning_rate': 1.9942038158532407e-06, 'rewards/chosen': -0.8025758862495422, 'rewards/rejected': -3.026583671569824, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.2240076065063477, 'logps/rejected': -7.566459655761719, 'logps/chosen': -2.006439685821533, 'logits/rejected': -1.5025402307510376, 'logits/chosen': -2.9370193481445312, 'nll_loss': 1.988701581954956, 'log_odds_ratio': -0.13946333527565002, 'log_odds_chosen': 5.700346946716309, 'logps/chosen_prompt': -0.7905480265617371, 'logps/rejected_prompt': -0.9439245462417603, 'logits/chosen_prompt': -2.663550853729248, 'logits/rejected_prompt': -2.662057399749756, 'logps/chosen_both': -1.9903736114501953, 'logps/rejected_both': -7.463855743408203, 'epoch': 1.74}
 87%|████████▋ | 2180/2500 [1:33:25<30:06,  5.65s/it] 87%|████████▋ | 2181/2500 [1:33:30<29:41,  5.58s/it] 87%|████████▋ | 2182/2500 [1:33:36<30:05,  5.68s/it] 87%|████████▋ | 2183/2500 [1:33:42<29:27,  5.58s/it] 87%|████████▋ | 2184/2500 [1:33:47<29:51,  5.67s/it] 87%|████████▋ | 2185/2500 [1:33:53<30:08,  5.74s/it] 87%|████████▋ | 2186/2500 [1:34:00<30:56,  5.91s/it] 87%|████████▋ | 2187/2500 [1:34:05<30:04,  5.77s/it] 88%|████████▊ | 2188/2500 [1:34:11<29:46,  5.73s/it] 88%|████████▊ | 2189/2500 [1:34:17<30:00,  5.79s/it] 88%|████████▊ | 2190/2500 [1:34:23<30:30,  5.91s/it]                                                     {'loss': 2.0303, 'grad_norm': 2.5972254929698955, 'learning_rate': 1.8730698291385518e-06, 'rewards/chosen': -0.7623436450958252, 'rewards/rejected': -2.9324679374694824, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1701247692108154, 'logps/rejected': -7.331170558929443, 'logps/chosen': -1.9058592319488525, 'logits/rejected': -1.6263618469238281, 'logits/chosen': -2.9098658561706543, 'nll_loss': 1.891299843788147, 'log_odds_ratio': -0.08086488395929337, 'log_odds_chosen': 5.5640668869018555, 'logps/chosen_prompt': -0.8048498034477234, 'logps/rejected_prompt': -1.019594669342041, 'logits/chosen_prompt': -2.662600040435791, 'logits/rejected_prompt': -2.655545949935913, 'logps/chosen_both': -1.8919883966445923, 'logps/rejected_both': -7.2471604347229, 'epoch': 1.75}
 88%|████████▊ | 2190/2500 [1:34:23<30:30,  5.91s/it] 88%|████████▊ | 2191/2500 [1:34:29<30:12,  5.87s/it] 88%|████████▊ | 2192/2500 [1:34:34<29:43,  5.79s/it] 88%|████████▊ | 2193/2500 [1:34:40<29:34,  5.78s/it] 88%|████████▊ | 2194/2500 [1:34:46<29:48,  5.85s/it] 88%|████████▊ | 2195/2500 [1:34:51<29:00,  5.70s/it] 88%|████████▊ | 2196/2500 [1:34:57<29:16,  5.78s/it] 88%|████████▊ | 2197/2500 [1:35:04<30:33,  6.05s/it] 88%|████████▊ | 2198/2500 [1:35:11<31:16,  6.22s/it] 88%|████████▊ | 2199/2500 [1:35:16<30:03,  5.99s/it] 88%|████████▊ | 2200/2500 [1:35:22<29:55,  5.98s/it]                                                     {'loss': 1.9781, 'grad_norm': 0.23660115635897935, 'learning_rate': 1.7555878527937164e-06, 'rewards/chosen': -0.7438045144081116, 'rewards/rejected': -3.030979633331299, 'rewards/accuracies': 1.0, 'rewards/margins': 2.287174940109253, 'logps/rejected': -7.577448844909668, 'logps/chosen': -1.8595116138458252, 'logits/rejected': -1.4598405361175537, 'logits/chosen': -3.022329568862915, 'nll_loss': 1.8431047201156616, 'log_odds_ratio': -0.13889989256858826, 'log_odds_chosen': 5.846020221710205, 'logps/chosen_prompt': -0.9043897390365601, 'logps/rejected_prompt': -1.0512850284576416, 'logits/chosen_prompt': -2.676358461380005, 'logits/rejected_prompt': -2.6573431491851807, 'logps/chosen_both': -1.8442891836166382, 'logps/rejected_both': -7.46319055557251, 'epoch': 1.76}
 88%|████████▊ | 2200/2500 [1:35:22<29:55,  5.98s/it] 88%|████████▊ | 2201/2500 [1:35:28<30:28,  6.12s/it] 88%|████████▊ | 2202/2500 [1:35:34<29:22,  5.91s/it] 88%|████████▊ | 2203/2500 [1:35:39<28:30,  5.76s/it] 88%|████████▊ | 2204/2500 [1:35:45<28:41,  5.82s/it] 88%|████████▊ | 2205/2500 [1:35:52<29:19,  5.96s/it] 88%|████████▊ | 2206/2500 [1:35:57<28:53,  5.90s/it] 88%|████████▊ | 2207/2500 [1:36:03<28:59,  5.94s/it] 88%|████████▊ | 2208/2500 [1:36:09<28:16,  5.81s/it] 88%|████████▊ | 2209/2500 [1:36:15<28:14,  5.82s/it] 88%|████████▊ | 2210/2500 [1:36:23<31:48,  6.58s/it]                                                     {'loss': 2.0093, 'grad_norm': 0.19241392115674874, 'learning_rate': 1.6417764385846996e-06, 'rewards/chosen': -0.7732215523719788, 'rewards/rejected': -3.3241703510284424, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.5509486198425293, 'logps/rejected': -8.310425758361816, 'logps/chosen': -1.933053731918335, 'logits/rejected': -1.2920866012573242, 'logits/chosen': -2.938408374786377, 'nll_loss': 1.9160425662994385, 'log_odds_ratio': -0.06997065246105194, 'log_odds_chosen': 6.517307281494141, 'logps/chosen_prompt': -0.7351342439651489, 'logps/rejected_prompt': -0.9880400896072388, 'logits/chosen_prompt': -2.676158905029297, 'logits/rejected_prompt': -2.654566764831543, 'logps/chosen_both': -1.9167392253875732, 'logps/rejected_both': -8.204216003417969, 'epoch': 1.77}
 88%|████████▊ | 2210/2500 [1:36:23<31:48,  6.58s/it] 88%|████████▊ | 2211/2500 [1:36:28<29:56,  6.22s/it] 88%|████████▊ | 2212/2500 [1:36:34<28:53,  6.02s/it] 89%|████████▊ | 2213/2500 [1:36:39<28:03,  5.87s/it] 89%|████████▊ | 2214/2500 [1:36:45<27:41,  5.81s/it] 89%|████████▊ | 2215/2500 [1:36:51<27:23,  5.77s/it] 89%|████████▊ | 2216/2500 [1:36:58<29:03,  6.14s/it] 89%|████████▊ | 2217/2500 [1:37:03<27:43,  5.88s/it] 89%|████████▊ | 2218/2500 [1:37:09<27:03,  5.76s/it] 89%|████████▉ | 2219/2500 [1:37:15<27:50,  5.95s/it] 89%|████████▉ | 2220/2500 [1:37:21<27:38,  5.92s/it]                                                     {'loss': 2.1344, 'grad_norm': 12.607113464415646, 'learning_rate': 1.5316535586531483e-06, 'rewards/chosen': -0.8176741600036621, 'rewards/rejected': -3.3418469429016113, 'rewards/accuracies': 1.0, 'rewards/margins': 2.52417254447937, 'logps/rejected': -8.35461711883545, 'logps/chosen': -2.0441854000091553, 'logits/rejected': -1.2792084217071533, 'logits/chosen': -2.9618306159973145, 'nll_loss': 2.021846294403076, 'log_odds_ratio': -0.06994439661502838, 'log_odds_chosen': 6.435976505279541, 'logps/chosen_prompt': -0.7438832521438599, 'logps/rejected_prompt': -0.9309514164924622, 'logits/chosen_prompt': -2.6941170692443848, 'logits/rejected_prompt': -2.6495256423950195, 'logps/chosen_both': -2.022369146347046, 'logps/rejected_both': -8.227459907531738, 'epoch': 1.78}
 89%|████████▉ | 2220/2500 [1:37:21<27:38,  5.92s/it] 89%|████████▉ | 2221/2500 [1:37:27<27:28,  5.91s/it] 89%|████████▉ | 2222/2500 [1:37:33<27:27,  5.92s/it] 89%|████████▉ | 2223/2500 [1:37:38<26:57,  5.84s/it] 89%|████████▉ | 2224/2500 [1:37:44<26:25,  5.75s/it] 89%|████████▉ | 2225/2500 [1:37:49<25:37,  5.59s/it] 89%|████████▉ | 2226/2500 [1:37:56<26:53,  5.89s/it] 89%|████████▉ | 2227/2500 [1:38:02<26:59,  5.93s/it] 89%|████████▉ | 2228/2500 [1:38:07<26:36,  5.87s/it] 89%|████████▉ | 2229/2500 [1:38:14<27:41,  6.13s/it] 89%|████████▉ | 2230/2500 [1:38:19<26:28,  5.88s/it]                                                     {'loss': 2.1171, 'grad_norm': 0.5707806821044193, 'learning_rate': 1.425236602678387e-06, 'rewards/chosen': -0.7484468817710876, 'rewards/rejected': -3.053096294403076, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.3046493530273438, 'logps/rejected': -7.6327409744262695, 'logps/chosen': -1.871117353439331, 'logits/rejected': -1.5305202007293701, 'logits/chosen': -2.963480234146118, 'nll_loss': 1.8556970357894897, 'log_odds_ratio': -0.08363859355449677, 'log_odds_chosen': 5.9131364822387695, 'logps/chosen_prompt': -0.8873545527458191, 'logps/rejected_prompt': -1.0161936283111572, 'logits/chosen_prompt': -2.6727945804595947, 'logits/rejected_prompt': -2.6573126316070557, 'logps/chosen_both': -1.8566415309906006, 'logps/rejected_both': -7.531146049499512, 'epoch': 1.78}
 89%|████████▉ | 2230/2500 [1:38:19<26:28,  5.88s/it] 89%|████████▉ | 2231/2500 [1:38:25<26:35,  5.93s/it] 89%|████████▉ | 2232/2500 [1:38:31<25:40,  5.75s/it] 89%|████████▉ | 2233/2500 [1:38:37<26:15,  5.90s/it] 89%|████████▉ | 2234/2500 [1:38:43<25:39,  5.79s/it] 89%|████████▉ | 2235/2500 [1:38:49<26:15,  5.94s/it] 89%|████████▉ | 2236/2500 [1:38:55<26:12,  5.96s/it] 89%|████████▉ | 2237/2500 [1:39:00<25:38,  5.85s/it] 90%|████████▉ | 2238/2500 [1:39:06<25:37,  5.87s/it] 90%|████████▉ | 2239/2500 [1:39:13<26:12,  6.03s/it] 90%|████████▉ | 2240/2500 [1:39:18<25:39,  5.92s/it]                                                     {'loss': 2.0823, 'grad_norm': 14.899939822219578, 'learning_rate': 1.3225423751313942e-06, 'rewards/chosen': -0.9743664860725403, 'rewards/rejected': -2.8890836238861084, 'rewards/accuracies': 0.800000011920929, 'rewards/margins': 1.9147170782089233, 'logps/rejected': -7.222708225250244, 'logps/chosen': -2.43591570854187, 'logits/rejected': -1.585412621498108, 'logits/chosen': -2.8191707134246826, 'nll_loss': 2.4118120670318604, 'log_odds_ratio': -0.6609615087509155, 'log_odds_chosen': 4.897831916809082, 'logps/chosen_prompt': -0.7758850455284119, 'logps/rejected_prompt': -1.0152117013931274, 'logits/chosen_prompt': -2.6796183586120605, 'logits/rejected_prompt': -2.6572556495666504, 'logps/chosen_both': -2.411881446838379, 'logps/rejected_both': -7.128981590270996, 'epoch': 1.79}
 90%|████████▉ | 2240/2500 [1:39:18<25:39,  5.92s/it] 90%|████████▉ | 2241/2500 [1:39:24<25:28,  5.90s/it] 90%|████████▉ | 2242/2500 [1:39:30<24:44,  5.75s/it] 90%|████████▉ | 2243/2500 [1:39:35<24:23,  5.69s/it] 90%|████████▉ | 2244/2500 [1:39:41<24:29,  5.74s/it] 90%|████████▉ | 2245/2500 [1:39:47<23:56,  5.63s/it] 90%|████████▉ | 2246/2500 [1:39:52<24:10,  5.71s/it] 90%|████████▉ | 2247/2500 [1:39:59<25:41,  6.09s/it] 90%|████████▉ | 2248/2500 [1:40:06<26:03,  6.20s/it] 90%|████████▉ | 2249/2500 [1:40:12<25:35,  6.12s/it] 90%|█████████ | 2250/2500 [1:40:18<25:44,  6.18s/it]                                                     {'loss': 2.0086, 'grad_norm': 0.19975378240583877, 'learning_rate': 1.2235870926211619e-06, 'rewards/chosen': -0.7801361680030823, 'rewards/rejected': -3.5710480213165283, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7909116744995117, 'logps/rejected': -8.927619934082031, 'logps/chosen': -1.9503402709960938, 'logits/rejected': -1.1342413425445557, 'logits/chosen': -2.9651646614074707, 'nll_loss': 1.9316205978393555, 'log_odds_ratio': -0.0009716370259411633, 'log_odds_chosen': 7.137516021728516, 'logps/chosen_prompt': -0.7800375819206238, 'logps/rejected_prompt': -0.9915293455123901, 'logits/chosen_prompt': -2.6956870555877686, 'logits/rejected_prompt': -2.683999538421631, 'logps/chosen_both': -1.9321882724761963, 'logps/rejected_both': -8.804494857788086, 'epoch': 1.8}
 90%|█████████ | 2250/2500 [1:40:18<25:44,  6.18s/it] 90%|█████████ | 2251/2500 [1:40:24<24:56,  6.01s/it] 90%|█████████ | 2252/2500 [1:40:30<24:58,  6.04s/it] 90%|█████████ | 2253/2500 [1:40:36<25:10,  6.11s/it] 90%|█████████ | 2254/2500 [1:40:42<24:37,  6.01s/it] 90%|█████████ | 2255/2500 [1:40:48<24:32,  6.01s/it] 90%|█████████ | 2256/2500 [1:40:54<24:19,  5.98s/it] 90%|█████████ | 2257/2500 [1:40:59<23:30,  5.80s/it] 90%|█████████ | 2258/2500 [1:41:05<22:55,  5.68s/it] 90%|█████████ | 2259/2500 [1:41:10<22:51,  5.69s/it] 90%|█████████ | 2260/2500 [1:41:16<23:20,  5.84s/it]                                                     {'loss': 2.0231, 'grad_norm': 0.3818357226005169, 'learning_rate': 1.1283863813339263e-06, 'rewards/chosen': -0.8052674531936646, 'rewards/rejected': -2.863292932510376, 'rewards/accuracies': 1.0, 'rewards/margins': 2.058025598526001, 'logps/rejected': -7.15823221206665, 'logps/chosen': -2.0131685733795166, 'logits/rejected': -1.6291303634643555, 'logits/chosen': -2.9074344635009766, 'nll_loss': 1.993402123451233, 'log_odds_ratio': -0.1399611532688141, 'log_odds_chosen': 5.262751579284668, 'logps/chosen_prompt': -0.7712079882621765, 'logps/rejected_prompt': -0.9588614702224731, 'logits/chosen_prompt': -2.676665782928467, 'logits/rejected_prompt': -2.6518123149871826, 'logps/chosen_both': -1.9943921566009521, 'logps/rejected_both': -7.054436683654785, 'epoch': 1.81}
 90%|█████████ | 2260/2500 [1:41:16<23:20,  5.84s/it] 90%|█████████ | 2261/2500 [1:41:22<23:13,  5.83s/it] 90%|█████████ | 2262/2500 [1:41:28<23:03,  5.81s/it] 91%|█████████ | 2263/2500 [1:41:34<22:45,  5.76s/it] 91%|█████████ | 2264/2500 [1:41:39<22:08,  5.63s/it] 91%|█████████ | 2265/2500 [1:41:45<22:36,  5.77s/it] 91%|█████████ | 2266/2500 [1:41:51<22:07,  5.67s/it] 91%|█████████ | 2267/2500 [1:41:56<22:02,  5.68s/it] 91%|█████████ | 2268/2500 [1:42:03<22:58,  5.94s/it] 91%|█████████ | 2269/2500 [1:42:09<22:49,  5.93s/it] 91%|█████████ | 2270/2500 [1:42:14<22:27,  5.86s/it]                                                     {'loss': 2.0872, 'grad_norm': 12.068551690734154, 'learning_rate': 1.0369552745656013e-06, 'rewards/chosen': -0.7743667960166931, 'rewards/rejected': -3.644657611846924, 'rewards/accuracies': 1.0, 'rewards/margins': 2.8702902793884277, 'logps/rejected': -9.11164379119873, 'logps/chosen': -1.9359169006347656, 'logits/rejected': -1.1133465766906738, 'logits/chosen': -2.9659335613250732, 'nll_loss': 1.9211848974227905, 'log_odds_ratio': -0.0007184174610301852, 'log_odds_chosen': 7.337935447692871, 'logps/chosen_prompt': -0.9362437129020691, 'logps/rejected_prompt': -1.087132215499878, 'logits/chosen_prompt': -2.669322967529297, 'logits/rejected_prompt': -2.6343612670898438, 'logps/chosen_both': -1.9216928482055664, 'logps/rejected_both': -8.993871688842773, 'epoch': 1.82}
 91%|█████████ | 2270/2500 [1:42:14<22:27,  5.86s/it] 91%|█████████ | 2271/2500 [1:42:20<22:09,  5.81s/it] 91%|█████████ | 2272/2500 [1:42:26<22:11,  5.84s/it] 91%|█████████ | 2273/2500 [1:42:32<21:49,  5.77s/it] 91%|█████████ | 2274/2500 [1:42:37<21:22,  5.68s/it] 91%|█████████ | 2275/2500 [1:42:43<21:38,  5.77s/it] 91%|█████████ | 2276/2500 [1:42:49<21:19,  5.71s/it] 91%|█████████ | 2277/2500 [1:42:54<20:58,  5.64s/it] 91%|█████████ | 2278/2500 [1:43:00<21:02,  5.69s/it] 91%|█████████ | 2279/2500 [1:43:06<21:12,  5.76s/it] 91%|█████████ | 2280/2500 [1:43:12<21:08,  5.77s/it]                                                     {'loss': 1.9806, 'grad_norm': 33.11538324522906, 'learning_rate': 9.493082103478517e-07, 'rewards/chosen': -0.772352397441864, 'rewards/rejected': -3.6086349487304688, 'rewards/accuracies': 1.0, 'rewards/margins': 2.836282730102539, 'logps/rejected': -9.021587371826172, 'logps/chosen': -1.9308809041976929, 'logits/rejected': -1.107086420059204, 'logits/chosen': -2.943401336669922, 'nll_loss': 1.9157644510269165, 'log_odds_ratio': -0.0007827345398254693, 'log_odds_chosen': 7.2577805519104, 'logps/chosen_prompt': -0.7256819605827332, 'logps/rejected_prompt': -0.9447809457778931, 'logits/chosen_prompt': -2.682952404022217, 'logits/rejected_prompt': -2.6607255935668945, 'logps/chosen_both': -1.9166597127914429, 'logps/rejected_both': -8.920001983642578, 'epoch': 1.82}
 91%|█████████ | 2280/2500 [1:43:12<21:08,  5.77s/it] 91%|█████████ | 2281/2500 [1:43:17<20:57,  5.74s/it] 91%|█████████▏| 2282/2500 [1:43:23<20:42,  5.70s/it] 91%|█████████▏| 2283/2500 [1:43:29<20:37,  5.70s/it] 91%|█████████▏| 2284/2500 [1:43:35<20:56,  5.82s/it] 91%|█████████▏| 2285/2500 [1:43:40<20:46,  5.80s/it] 91%|█████████▏| 2286/2500 [1:43:46<20:09,  5.65s/it] 91%|█████████▏| 2287/2500 [1:43:51<20:09,  5.68s/it] 92%|█████████▏| 2288/2500 [1:43:57<19:39,  5.57s/it] 92%|█████████▏| 2289/2500 [1:44:02<19:24,  5.52s/it] 92%|█████████▏| 2290/2500 [1:44:08<19:27,  5.56s/it]                                                     {'loss': 2.0766, 'grad_norm': 0.4411142663055461, 'learning_rate': 8.65459029168153e-07, 'rewards/chosen': -0.8565918803215027, 'rewards/rejected': -2.9652414321899414, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.108649492263794, 'logps/rejected': -7.4131035804748535, 'logps/chosen': -2.141479969024658, 'logits/rejected': -1.528686285018921, 'logits/chosen': -2.8957035541534424, 'nll_loss': 2.1242899894714355, 'log_odds_ratio': -0.13947732746601105, 'log_odds_chosen': 5.375699043273926, 'logps/chosen_prompt': -0.8731950521469116, 'logps/rejected_prompt': -0.9539289474487305, 'logits/chosen_prompt': -2.6855359077453613, 'logits/rejected_prompt': -2.6730213165283203, 'logps/chosen_both': -2.125235080718994, 'logps/rejected_both': -7.325228691101074, 'epoch': 1.83}
 92%|█████████▏| 2290/2500 [1:44:08<19:27,  5.56s/it] 92%|█████████▏| 2291/2500 [1:44:14<20:25,  5.86s/it] 92%|█████████▏| 2292/2500 [1:44:20<19:30,  5.63s/it] 92%|█████████▏| 2293/2500 [1:44:25<19:27,  5.64s/it] 92%|█████████▏| 2294/2500 [1:44:31<19:21,  5.64s/it] 92%|█████████▏| 2295/2500 [1:44:37<19:45,  5.78s/it] 92%|█████████▏| 2296/2500 [1:44:43<20:11,  5.94s/it] 92%|█████████▏| 2297/2500 [1:44:50<20:26,  6.04s/it] 92%|█████████▏| 2298/2500 [1:44:55<20:06,  5.98s/it] 92%|█████████▏| 2299/2500 [1:45:02<20:17,  6.06s/it] 92%|█████████▏| 2300/2500 [1:45:07<19:29,  5.85s/it]                                                     {'loss': 1.9897, 'grad_norm': 0.4101442699817831, 'learning_rate': 7.854209717842231e-07, 'rewards/chosen': -0.7567352056503296, 'rewards/rejected': -2.8842451572418213, 'rewards/accuracies': 1.0, 'rewards/margins': 2.1275100708007812, 'logps/rejected': -7.210613250732422, 'logps/chosen': -1.8918377161026, 'logits/rejected': -1.5944197177886963, 'logits/chosen': -2.960317850112915, 'nll_loss': 1.8777681589126587, 'log_odds_ratio': -0.14220565557479858, 'log_odds_chosen': 5.443779468536377, 'logps/chosen_prompt': -0.8449529409408569, 'logps/rejected_prompt': -0.9285844564437866, 'logits/chosen_prompt': -2.694756507873535, 'logits/rejected_prompt': -2.6843719482421875, 'logps/chosen_both': -1.8780038356781006, 'logps/rejected_both': -7.127508640289307, 'epoch': 1.84}
 92%|█████████▏| 2300/2500 [1:45:07<19:29,  5.85s/it] 92%|█████████▏| 2301/2500 [1:45:13<19:35,  5.91s/it] 92%|█████████▏| 2302/2500 [1:45:19<19:13,  5.83s/it] 92%|█████████▏| 2303/2500 [1:45:24<18:56,  5.77s/it] 92%|█████████▏| 2304/2500 [1:45:30<18:37,  5.70s/it] 92%|█████████▏| 2305/2500 [1:45:35<18:30,  5.70s/it] 92%|█████████▏| 2306/2500 [1:45:41<18:06,  5.60s/it] 92%|█████████▏| 2307/2500 [1:45:47<18:28,  5.74s/it] 92%|█████████▏| 2308/2500 [1:45:53<18:52,  5.90s/it] 92%|█████████▏| 2309/2500 [1:45:59<18:35,  5.84s/it] 92%|█████████▏| 2310/2500 [1:46:06<19:19,  6.10s/it]                                                     {'loss': 2.0707, 'grad_norm': 0.16963416901457068, 'learning_rate': 7.092066771331507e-07, 'rewards/chosen': -0.8087409138679504, 'rewards/rejected': -3.112518310546875, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3037776947021484, 'logps/rejected': -7.781296730041504, 'logps/chosen': -2.0218520164489746, 'logits/rejected': -1.4708083868026733, 'logits/chosen': -2.962782621383667, 'nll_loss': 2.006934881210327, 'log_odds_ratio': -0.07142205536365509, 'log_odds_chosen': 5.893454074859619, 'logps/chosen_prompt': -0.8719010353088379, 'logps/rejected_prompt': -1.1384111642837524, 'logits/chosen_prompt': -2.6731419563293457, 'logits/rejected_prompt': -2.6606757640838623, 'logps/chosen_both': -2.0073187351226807, 'logps/rejected_both': -7.6947808265686035, 'epoch': 1.85}
 92%|█████████▏| 2310/2500 [1:46:06<19:19,  6.10s/it] 92%|█████████▏| 2311/2500 [1:46:11<18:50,  5.98s/it] 92%|█████████▏| 2312/2500 [1:46:20<21:18,  6.80s/it] 93%|█████████▎| 2313/2500 [1:46:25<19:24,  6.23s/it] 93%|█████████▎| 2314/2500 [1:46:30<18:14,  5.88s/it] 93%|█████████▎| 2315/2500 [1:46:36<17:53,  5.80s/it] 93%|█████████▎| 2316/2500 [1:46:44<20:25,  6.66s/it] 93%|█████████▎| 2317/2500 [1:46:50<19:27,  6.38s/it] 93%|█████████▎| 2318/2500 [1:46:55<18:16,  6.02s/it] 93%|█████████▎| 2319/2500 [1:47:01<17:48,  5.90s/it] 93%|█████████▎| 2320/2500 [1:47:06<17:20,  5.78s/it]                                                     {'loss': 2.0898, 'grad_norm': 0.45140784235004927, 'learning_rate': 6.368281803355691e-07, 'rewards/chosen': -0.900164008140564, 'rewards/rejected': -2.8327152729034424, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9325511455535889, 'logps/rejected': -7.081788063049316, 'logps/chosen': -2.2504098415374756, 'logits/rejected': -1.6196407079696655, 'logits/chosen': -2.8609237670898438, 'nll_loss': 2.229222297668457, 'log_odds_ratio': -0.14795678853988647, 'log_odds_chosen': 4.920267581939697, 'logps/chosen_prompt': -0.8699579238891602, 'logps/rejected_prompt': -1.0133532285690308, 'logits/chosen_prompt': -2.6775732040405273, 'logits/rejected_prompt': -2.6593384742736816, 'logps/chosen_both': -2.2304248809814453, 'logps/rejected_both': -6.994397163391113, 'epoch': 1.86}
 93%|█████████▎| 2320/2500 [1:47:06<17:20,  5.78s/it] 93%|█████████▎| 2321/2500 [1:47:12<17:18,  5.80s/it] 93%|█████████▎| 2322/2500 [1:47:18<16:47,  5.66s/it] 93%|█████████▎| 2323/2500 [1:47:23<16:57,  5.75s/it] 93%|█████████▎| 2324/2500 [1:47:30<17:22,  5.92s/it] 93%|█████████▎| 2325/2500 [1:47:37<18:15,  6.26s/it] 93%|█████████▎| 2326/2500 [1:47:44<18:34,  6.40s/it] 93%|█████████▎| 2327/2500 [1:47:49<17:46,  6.17s/it] 93%|█████████▎| 2328/2500 [1:47:55<17:06,  5.97s/it] 93%|█████████▎| 2329/2500 [1:48:01<17:04,  5.99s/it] 93%|█████████▎| 2330/2500 [1:48:06<16:41,  5.89s/it]                                                     {'loss': 2.0677, 'grad_norm': 0.2456069809607515, 'learning_rate': 5.68296910795163e-07, 'rewards/chosen': -0.8049627542495728, 'rewards/rejected': -2.9583113193511963, 'rewards/accuracies': 1.0, 'rewards/margins': 2.153348445892334, 'logps/rejected': -7.395777702331543, 'logps/chosen': -2.012406826019287, 'logits/rejected': -1.5781638622283936, 'logits/chosen': -2.955156087875366, 'nll_loss': 1.9909512996673584, 'log_odds_ratio': -0.1407424509525299, 'log_odds_chosen': 5.509438991546631, 'logps/chosen_prompt': -0.7710096836090088, 'logps/rejected_prompt': -0.9649494886398315, 'logits/chosen_prompt': -2.706146717071533, 'logits/rejected_prompt': -2.6797842979431152, 'logps/chosen_both': -1.9916448593139648, 'logps/rejected_both': -7.277468204498291, 'epoch': 1.86}
 93%|█████████▎| 2330/2500 [1:48:06<16:41,  5.89s/it] 93%|█████████▎| 2331/2500 [1:48:12<16:21,  5.81s/it] 93%|█████████▎| 2332/2500 [1:48:18<16:28,  5.89s/it] 93%|█████████▎| 2333/2500 [1:48:24<16:19,  5.87s/it] 93%|█████████▎| 2334/2500 [1:48:29<15:51,  5.73s/it] 93%|█████████▎| 2335/2500 [1:48:35<15:45,  5.73s/it] 93%|█████████▎| 2336/2500 [1:48:41<15:28,  5.66s/it] 93%|█████████▎| 2337/2500 [1:48:46<15:21,  5.65s/it] 94%|█████████▎| 2338/2500 [1:48:52<15:10,  5.62s/it] 94%|█████████▎| 2339/2500 [1:48:57<14:55,  5.56s/it] 94%|█████████▎| 2340/2500 [1:49:04<15:36,  5.85s/it]                                                     {'loss': 2.1342, 'grad_norm': 9.133380433606282, 'learning_rate': 5.036236903938285e-07, 'rewards/chosen': -0.753743588924408, 'rewards/rejected': -3.4319510459899902, 'rewards/accuracies': 1.0, 'rewards/margins': 2.6782071590423584, 'logps/rejected': -8.579877853393555, 'logps/chosen': -1.8843590021133423, 'logits/rejected': -1.2686409950256348, 'logits/chosen': -2.8951406478881836, 'nll_loss': 1.8690464496612549, 'log_odds_ratio': -0.0016654839273542166, 'log_odds_chosen': 6.8823065757751465, 'logps/chosen_prompt': -0.8593623042106628, 'logps/rejected_prompt': -1.0837408304214478, 'logits/chosen_prompt': -2.678162097930908, 'logits/rejected_prompt': -2.6555025577545166, 'logps/chosen_both': -1.8703386783599854, 'logps/rejected_both': -8.47286319732666, 'epoch': 1.87}
 94%|█████████▎| 2340/2500 [1:49:04<15:36,  5.85s/it] 94%|█████████▎| 2341/2500 [1:49:09<15:15,  5.76s/it] 94%|█████████▎| 2342/2500 [1:49:15<15:06,  5.74s/it] 94%|█████████▎| 2343/2500 [1:49:21<15:08,  5.79s/it] 94%|█████████▍| 2344/2500 [1:49:27<15:14,  5.86s/it] 94%|█████████▍| 2345/2500 [1:49:32<14:55,  5.78s/it] 94%|█████████▍| 2346/2500 [1:49:38<14:42,  5.73s/it] 94%|█████████▍| 2347/2500 [1:49:43<14:24,  5.65s/it] 94%|█████████▍| 2348/2500 [1:49:52<16:27,  6.50s/it] 94%|█████████▍| 2349/2500 [1:49:57<15:25,  6.13s/it] 94%|█████████▍| 2350/2500 [1:50:03<14:53,  5.96s/it]                                                     {'loss': 2.0274, 'grad_norm': 8.125890645231447, 'learning_rate': 4.4281873178278475e-07, 'rewards/chosen': -0.8443654775619507, 'rewards/rejected': -3.0514883995056152, 'rewards/accuracies': 1.0, 'rewards/margins': 2.207122802734375, 'logps/rejected': -7.628720283508301, 'logps/chosen': -2.1109137535095215, 'logits/rejected': -1.5474947690963745, 'logits/chosen': -2.9068408012390137, 'nll_loss': 2.0917389392852783, 'log_odds_ratio': -0.12145135551691055, 'log_odds_chosen': 5.642827033996582, 'logps/chosen_prompt': -0.7461457848548889, 'logps/rejected_prompt': -0.9959444999694824, 'logits/chosen_prompt': -2.6763854026794434, 'logits/rejected_prompt': -2.6614723205566406, 'logps/chosen_both': -2.0927329063415527, 'logps/rejected_both': -7.53784704208374, 'epoch': 1.88}
 94%|█████████▍| 2350/2500 [1:50:03<14:53,  5.96s/it] 94%|█████████▍| 2351/2500 [1:50:09<15:06,  6.08s/it] 94%|█████████▍| 2352/2500 [1:50:15<14:38,  5.93s/it] 94%|█████████▍| 2353/2500 [1:50:20<14:21,  5.86s/it] 94%|█████████▍| 2354/2500 [1:50:26<13:54,  5.72s/it] 94%|█████████▍| 2355/2500 [1:50:31<13:40,  5.66s/it] 94%|█████████▍| 2356/2500 [1:50:37<13:32,  5.64s/it] 94%|█████████▍| 2357/2500 [1:50:43<13:29,  5.66s/it] 94%|█████████▍| 2358/2500 [1:50:48<13:26,  5.68s/it] 94%|█████████▍| 2359/2500 [1:50:54<13:34,  5.78s/it] 94%|█████████▍| 2360/2500 [1:51:00<13:05,  5.61s/it]                                                     {'loss': 2.0357, 'grad_norm': 0.2015164947020062, 'learning_rate': 3.8589163676986674e-07, 'rewards/chosen': -0.7482312917709351, 'rewards/rejected': -3.3261966705322266, 'rewards/accuracies': 1.0, 'rewards/margins': 2.577965021133423, 'logps/rejected': -8.31549072265625, 'logps/chosen': -1.8705781698226929, 'logits/rejected': -1.3643099069595337, 'logits/chosen': -3.0217535495758057, 'nll_loss': 1.8507616519927979, 'log_odds_ratio': -0.007986939512193203, 'log_odds_chosen': 6.619173526763916, 'logps/chosen_prompt': -0.7772539854049683, 'logps/rejected_prompt': -1.0249732732772827, 'logits/chosen_prompt': -2.6994032859802246, 'logits/rejected_prompt': -2.6855533123016357, 'logps/chosen_both': -1.8512824773788452, 'logps/rejected_both': -8.180856704711914, 'epoch': 1.89}
 94%|█████████▍| 2360/2500 [1:51:00<13:05,  5.61s/it] 94%|█████████▍| 2361/2500 [1:51:05<13:03,  5.64s/it] 94%|█████████▍| 2362/2500 [1:51:12<13:39,  5.94s/it] 95%|█████████▍| 2363/2500 [1:51:17<13:09,  5.76s/it] 95%|█████████▍| 2364/2500 [1:51:22<12:33,  5.54s/it] 95%|█████████▍| 2365/2500 [1:51:28<12:24,  5.51s/it] 95%|█████████▍| 2366/2500 [1:51:33<12:00,  5.38s/it] 95%|█████████▍| 2367/2500 [1:51:38<12:01,  5.42s/it] 95%|█████████▍| 2368/2500 [1:51:44<12:08,  5.52s/it] 95%|█████████▍| 2369/2500 [1:51:50<12:01,  5.51s/it] 95%|█████████▍| 2370/2500 [1:51:55<12:02,  5.56s/it]                                                     {'loss': 2.0034, 'grad_norm': 0.21475862564180093, 'learning_rate': 3.328513948032991e-07, 'rewards/chosen': -0.7858099937438965, 'rewards/rejected': -3.062643527984619, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2768330574035645, 'logps/rejected': -7.656608581542969, 'logps/chosen': -1.9645248651504517, 'logits/rejected': -1.551140546798706, 'logits/chosen': -2.952939748764038, 'nll_loss': 1.9450407028198242, 'log_odds_ratio': -0.08105997741222382, 'log_odds_chosen': 5.829693794250488, 'logps/chosen_prompt': -0.7690848708152771, 'logps/rejected_prompt': -0.9684537649154663, 'logits/chosen_prompt': -2.6928491592407227, 'logits/rejected_prompt': -2.681459426879883, 'logps/chosen_both': -1.9458214044570923, 'logps/rejected_both': -7.550889015197754, 'epoch': 1.9}
 95%|█████████▍| 2370/2500 [1:51:55<12:02,  5.56s/it] 95%|█████████▍| 2371/2500 [1:52:02<12:25,  5.78s/it] 95%|█████████▍| 2372/2500 [1:52:07<12:21,  5.79s/it] 95%|█████████▍| 2373/2500 [1:52:14<12:34,  5.94s/it] 95%|█████████▍| 2374/2500 [1:52:19<12:15,  5.84s/it] 95%|█████████▌| 2375/2500 [1:52:25<12:21,  5.93s/it] 95%|█████████▌| 2376/2500 [1:52:31<11:52,  5.75s/it] 95%|█████████▌| 2377/2500 [1:52:37<12:10,  5.94s/it] 95%|█████████▌| 2378/2500 [1:52:44<12:51,  6.32s/it] 95%|█████████▌| 2379/2500 [1:52:50<12:18,  6.10s/it] 95%|█████████▌| 2380/2500 [1:52:55<11:49,  5.92s/it]                                                     {'loss': 2.0445, 'grad_norm': 3.809642053346634, 'learning_rate': 2.8370638155215123e-07, 'rewards/chosen': -0.809485137462616, 'rewards/rejected': -3.3079440593719482, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4984593391418457, 'logps/rejected': -8.26986026763916, 'logps/chosen': -2.0237128734588623, 'logits/rejected': -1.3612765073776245, 'logits/chosen': -2.9039905071258545, 'nll_loss': 2.0056352615356445, 'log_odds_ratio': -0.01686013862490654, 'log_odds_chosen': 6.387116432189941, 'logps/chosen_prompt': -0.8450068235397339, 'logps/rejected_prompt': -0.9601761102676392, 'logits/chosen_prompt': -2.715973377227783, 'logits/rejected_prompt': -2.685485363006592, 'logps/chosen_both': -2.0063564777374268, 'logps/rejected_both': -8.166280746459961, 'epoch': 1.9}
 95%|█████████▌| 2380/2500 [1:52:55<11:49,  5.92s/it] 95%|█████████▌| 2381/2500 [1:53:01<11:36,  5.85s/it] 95%|█████████▌| 2382/2500 [1:53:07<11:22,  5.79s/it] 95%|█████████▌| 2383/2500 [1:53:12<11:10,  5.73s/it] 95%|█████████▌| 2384/2500 [1:53:18<10:45,  5.57s/it] 95%|█████████▌| 2385/2500 [1:53:23<10:41,  5.58s/it] 95%|█████████▌| 2386/2500 [1:53:30<11:10,  5.89s/it] 95%|█████████▌| 2387/2500 [1:53:35<10:46,  5.73s/it] 96%|█████████▌| 2388/2500 [1:53:41<10:50,  5.80s/it] 96%|█████████▌| 2389/2500 [1:53:47<10:51,  5.87s/it] 96%|█████████▌| 2390/2500 [1:53:54<11:19,  6.18s/it]                                                     {'loss': 2.1047, 'grad_norm': 0.18863036527831809, 'learning_rate': 2.384643575837203e-07, 'rewards/chosen': -1.0979379415512085, 'rewards/rejected': -3.3525009155273438, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.2545626163482666, 'logps/rejected': -8.381251335144043, 'logps/chosen': -2.744844675064087, 'logits/rejected': -1.3054828643798828, 'logits/chosen': -2.8088581562042236, 'nll_loss': 2.7194857597351074, 'log_odds_ratio': -0.44992485642433167, 'log_odds_chosen': 5.736932277679443, 'logps/chosen_prompt': -0.8345869779586792, 'logps/rejected_prompt': -1.072677731513977, 'logits/chosen_prompt': -2.6814346313476562, 'logits/rejected_prompt': -2.6639716625213623, 'logps/chosen_both': -2.7204136848449707, 'logps/rejected_both': -8.271730422973633, 'epoch': 1.91}
 96%|█████████▌| 2390/2500 [1:53:54<11:19,  6.18s/it] 96%|█████████▌| 2391/2500 [1:54:00<10:52,  5.99s/it] 96%|█████████▌| 2392/2500 [1:54:07<11:45,  6.54s/it] 96%|█████████▌| 2393/2500 [1:54:14<11:37,  6.51s/it] 96%|█████████▌| 2394/2500 [1:54:20<11:05,  6.28s/it] 96%|█████████▌| 2395/2500 [1:54:25<10:38,  6.09s/it] 96%|█████████▌| 2396/2500 [1:54:31<10:30,  6.06s/it] 96%|█████████▌| 2397/2500 [1:54:37<10:05,  5.88s/it] 96%|█████████▌| 2398/2500 [1:54:44<10:36,  6.24s/it] 96%|█████████▌| 2399/2500 [1:54:50<10:20,  6.14s/it] 96%|█████████▌| 2400/2500 [1:54:55<09:58,  5.99s/it]                                                     {'loss': 1.9581, 'grad_norm': 13.18722977495282, 'learning_rate': 1.9713246713805588e-07, 'rewards/chosen': -0.7447496652603149, 'rewards/rejected': -3.1288697719573975, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 2.384119987487793, 'logps/rejected': -7.822175025939941, 'logps/chosen': -1.861873984336853, 'logits/rejected': -1.413206696510315, 'logits/chosen': -2.993813991546631, 'nll_loss': 1.8463693857192993, 'log_odds_ratio': -0.07236198335886002, 'log_odds_chosen': 6.120110988616943, 'logps/chosen_prompt': -0.7869310975074768, 'logps/rejected_prompt': -1.0256634950637817, 'logits/chosen_prompt': -2.7078299522399902, 'logits/rejected_prompt': -2.6832337379455566, 'logps/chosen_both': -1.8475834131240845, 'logps/rejected_both': -7.719012260437012, 'epoch': 1.92}
 96%|█████████▌| 2400/2500 [1:54:55<09:58,  5.99s/it] 96%|█████████▌| 2401/2500 [1:55:01<09:40,  5.86s/it] 96%|█████████▌| 2402/2500 [1:55:07<09:32,  5.84s/it] 96%|█████████▌| 2403/2500 [1:55:12<09:13,  5.70s/it] 96%|█████████▌| 2404/2500 [1:55:18<09:24,  5.88s/it] 96%|█████████▌| 2405/2500 [1:55:23<08:55,  5.63s/it] 96%|█████████▌| 2406/2500 [1:55:29<08:58,  5.72s/it] 96%|█████████▋| 2407/2500 [1:55:35<08:49,  5.69s/it] 96%|█████████▋| 2408/2500 [1:55:41<08:52,  5.79s/it] 96%|█████████▋| 2409/2500 [1:55:46<08:34,  5.66s/it] 96%|█████████▋| 2410/2500 [1:55:54<09:28,  6.31s/it]                                                     {'loss': 2.0096, 'grad_norm': 1.8397789939899993, 'learning_rate': 1.5971723699979013e-07, 'rewards/chosen': -0.7697963714599609, 'rewards/rejected': -3.3277430534362793, 'rewards/accuracies': 1.0, 'rewards/margins': 2.5579466819763184, 'logps/rejected': -8.319356918334961, 'logps/chosen': -1.9244906902313232, 'logits/rejected': -1.37109375, 'logits/chosen': -2.919804334640503, 'nll_loss': 1.908544898033142, 'log_odds_ratio': -0.007061490323394537, 'log_odds_chosen': 6.564394474029541, 'logps/chosen_prompt': -0.8159144520759583, 'logps/rejected_prompt': -1.053536295890808, 'logits/chosen_prompt': -2.6765904426574707, 'logits/rejected_prompt': -2.665297746658325, 'logps/chosen_both': -1.9095802307128906, 'logps/rejected_both': -8.210798263549805, 'epoch': 1.93}
 96%|█████████▋| 2410/2500 [1:55:54<09:28,  6.31s/it] 96%|█████████▋| 2411/2500 [1:56:00<09:11,  6.20s/it] 96%|█████████▋| 2412/2500 [1:56:06<08:51,  6.03s/it] 97%|█████████▋| 2413/2500 [1:56:11<08:30,  5.86s/it] 97%|█████████▋| 2414/2500 [1:56:17<08:32,  5.96s/it] 97%|█████████▋| 2415/2500 [1:56:23<08:23,  5.92s/it] 97%|█████████▋| 2416/2500 [1:56:29<08:16,  5.91s/it] 97%|█████████▋| 2417/2500 [1:56:35<08:08,  5.88s/it] 97%|█████████▋| 2418/2500 [1:56:41<07:56,  5.81s/it] 97%|█████████▋| 2419/2500 [1:56:46<07:32,  5.58s/it] 97%|█████████▋| 2420/2500 [1:56:52<07:36,  5.71s/it]                                                     {'loss': 1.9758, 'grad_norm': 0.21428780586922244, 'learning_rate': 1.2622457546749567e-07, 'rewards/chosen': -0.8086605072021484, 'rewards/rejected': -3.0946788787841797, 'rewards/accuracies': 1.0, 'rewards/margins': 2.2860183715820312, 'logps/rejected': -7.736697196960449, 'logps/chosen': -2.021651029586792, 'logits/rejected': -1.5242493152618408, 'logits/chosen': -2.9730477333068848, 'nll_loss': 2.000985860824585, 'log_odds_ratio': -0.07496409863233566, 'log_odds_chosen': 5.870514869689941, 'logps/chosen_prompt': -0.8506444096565247, 'logps/rejected_prompt': -1.030146837234497, 'logits/chosen_prompt': -2.7076330184936523, 'logits/rejected_prompt': -2.682469129562378, 'logps/chosen_both': -2.002253532409668, 'logps/rejected_both': -7.621484279632568, 'epoch': 1.94}
 97%|█████████▋| 2420/2500 [1:56:52<07:36,  5.71s/it] 97%|█████████▋| 2421/2500 [1:57:01<08:50,  6.72s/it] 97%|█████████▋| 2422/2500 [1:57:06<08:21,  6.43s/it] 97%|█████████▋| 2423/2500 [1:57:12<07:59,  6.22s/it] 97%|█████████▋| 2424/2500 [1:57:18<07:52,  6.22s/it] 97%|█████████▋| 2425/2500 [1:57:24<07:35,  6.08s/it] 97%|█████████▋| 2426/2500 [1:57:30<07:29,  6.07s/it] 97%|█████████▋| 2427/2500 [1:57:36<07:19,  6.01s/it] 97%|█████████▋| 2428/2500 [1:57:42<07:07,  5.94s/it] 97%|█████████▋| 2429/2500 [1:57:47<06:54,  5.83s/it] 97%|█████████▋| 2430/2500 [1:57:53<06:53,  5.90s/it]                                                     {'loss': 2.0238, 'grad_norm': 0.20416396410750487, 'learning_rate': 9.665977142068738e-08, 'rewards/chosen': -0.8123772740364075, 'rewards/rejected': -2.710655689239502, 'rewards/accuracies': 1.0, 'rewards/margins': 1.8982784748077393, 'logps/rejected': -6.776639461517334, 'logps/chosen': -2.0309431552886963, 'logits/rejected': -1.6799697875976562, 'logits/chosen': -2.902254581451416, 'nll_loss': 2.0125374794006348, 'log_odds_ratio': -0.20837202668190002, 'log_odds_chosen': 4.83801794052124, 'logps/chosen_prompt': -0.7962573766708374, 'logps/rejected_prompt': -0.9658966064453125, 'logits/chosen_prompt': -2.660670518875122, 'logits/rejected_prompt': -2.6579954624176025, 'logps/chosen_both': -2.013542413711548, 'logps/rejected_both': -6.694192409515381, 'epoch': 1.94}
 97%|█████████▋| 2430/2500 [1:57:53<06:53,  5.90s/it] 97%|█████████▋| 2431/2500 [1:58:00<06:49,  5.94s/it] 97%|█████████▋| 2432/2500 [1:58:05<06:38,  5.85s/it] 97%|█████████▋| 2433/2500 [1:58:11<06:36,  5.92s/it] 97%|█████████▋| 2434/2500 [1:58:17<06:31,  5.93s/it] 97%|█████████▋| 2435/2500 [1:58:23<06:18,  5.82s/it] 97%|█████████▋| 2436/2500 [1:58:28<06:01,  5.65s/it] 97%|█████████▋| 2437/2500 [1:58:34<05:55,  5.65s/it] 98%|█████████▊| 2438/2500 [1:58:40<05:55,  5.74s/it] 98%|█████████▊| 2439/2500 [1:58:45<05:40,  5.58s/it] 98%|█████████▊| 2440/2500 [1:58:50<05:29,  5.49s/it]                                                     {'loss': 1.9856, 'grad_norm': 0.18064916751366988, 'learning_rate': 7.102749348465165e-08, 'rewards/chosen': -0.8120771646499634, 'rewards/rejected': -3.2733540534973145, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4612767696380615, 'logps/rejected': -8.183384895324707, 'logps/chosen': -2.0301928520202637, 'logits/rejected': -1.3513176441192627, 'logits/chosen': -2.953155040740967, 'nll_loss': 2.014564275741577, 'log_odds_ratio': -0.07041435688734055, 'log_odds_chosen': 6.284792900085449, 'logps/chosen_prompt': -0.805233359336853, 'logps/rejected_prompt': -0.9243391156196594, 'logits/chosen_prompt': -2.6918091773986816, 'logits/rejected_prompt': -2.6691641807556152, 'logps/chosen_both': -2.0152721405029297, 'logps/rejected_both': -8.090814590454102, 'epoch': 1.95}
 98%|█████████▊| 2440/2500 [1:58:50<05:29,  5.49s/it] 98%|█████████▊| 2441/2500 [1:58:57<05:41,  5.78s/it] 98%|█████████▊| 2442/2500 [1:59:02<05:31,  5.71s/it] 98%|█████████▊| 2443/2500 [1:59:08<05:22,  5.66s/it] 98%|█████████▊| 2444/2500 [1:59:13<05:08,  5.52s/it] 98%|█████████▊| 2445/2500 [1:59:19<05:12,  5.68s/it] 98%|█████████▊| 2446/2500 [1:59:25<05:08,  5.72s/it] 98%|█████████▊| 2447/2500 [1:59:30<05:01,  5.69s/it] 98%|█████████▊| 2448/2500 [1:59:36<04:50,  5.59s/it] 98%|█████████▊| 2449/2500 [1:59:42<04:57,  5.84s/it] 98%|█████████▊| 2450/2500 [1:59:48<04:51,  5.84s/it]                                                     {'loss': 2.0561, 'grad_norm': 12.586375746390575, 'learning_rate': 4.9331789293211026e-08, 'rewards/chosen': -0.9324896931648254, 'rewards/rejected': -2.7241835594177246, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.7916936874389648, 'logps/rejected': -6.810458183288574, 'logps/chosen': -2.3312244415283203, 'logits/rejected': -1.7801692485809326, 'logits/chosen': -2.9023003578186035, 'nll_loss': 2.306539535522461, 'log_odds_ratio': -0.14985592663288116, 'log_odds_chosen': 4.579585075378418, 'logps/chosen_prompt': -0.8197005391120911, 'logps/rejected_prompt': -0.9593888521194458, 'logits/chosen_prompt': -2.698371410369873, 'logits/rejected_prompt': -2.672545909881592, 'logps/chosen_both': -2.307455539703369, 'logps/rejected_both': -6.7077531814575195, 'epoch': 1.96}
 98%|█████████▊| 2450/2500 [1:59:48<04:51,  5.84s/it] 98%|█████████▊| 2451/2500 [1:59:54<04:43,  5.79s/it] 98%|█████████▊| 2452/2500 [1:59:59<04:32,  5.68s/it] 98%|█████████▊| 2453/2500 [2:00:05<04:25,  5.65s/it] 98%|█████████▊| 2454/2500 [2:00:11<04:26,  5.79s/it] 98%|█████████▊| 2455/2500 [2:00:16<04:19,  5.76s/it] 98%|█████████▊| 2456/2500 [2:00:22<04:06,  5.59s/it] 98%|█████████▊| 2457/2500 [2:00:27<03:59,  5.58s/it] 98%|█████████▊| 2458/2500 [2:00:34<04:09,  5.93s/it] 98%|█████████▊| 2459/2500 [2:00:40<04:02,  5.91s/it] 98%|█████████▊| 2460/2500 [2:00:46<03:55,  5.89s/it]                                                     {'loss': 2.0324, 'grad_norm': 0.2033609825485069, 'learning_rate': 3.157608484956332e-08, 'rewards/chosen': -0.7603757381439209, 'rewards/rejected': -2.959747552871704, 'rewards/accuracies': 1.0, 'rewards/margins': 2.199371814727783, 'logps/rejected': -7.399369239807129, 'logps/chosen': -1.9009393453598022, 'logits/rejected': -1.587998628616333, 'logits/chosen': -2.9894793033599854, 'nll_loss': 1.882651925086975, 'log_odds_ratio': -0.12363947927951813, 'log_odds_chosen': 5.642730712890625, 'logps/chosen_prompt': -0.8881078958511353, 'logps/rejected_prompt': -1.0824201107025146, 'logits/chosen_prompt': -2.709346055984497, 'logits/rejected_prompt': -2.6869075298309326, 'logps/chosen_both': -1.8831487894058228, 'logps/rejected_both': -7.2926836013793945, 'epoch': 1.97}
 98%|█████████▊| 2460/2500 [2:00:46<03:55,  5.89s/it] 98%|█████████▊| 2461/2500 [2:00:51<03:42,  5.71s/it] 98%|█████████▊| 2462/2500 [2:00:57<03:40,  5.81s/it] 99%|█████████▊| 2463/2500 [2:01:05<03:54,  6.34s/it] 99%|█████████▊| 2464/2500 [2:01:10<03:40,  6.12s/it] 99%|█████████▊| 2465/2500 [2:01:16<03:26,  5.91s/it] 99%|█████████▊| 2466/2500 [2:01:21<03:19,  5.88s/it] 99%|█████████▊| 2467/2500 [2:01:27<03:13,  5.85s/it] 99%|█████████▊| 2468/2500 [2:01:32<03:02,  5.70s/it] 99%|█████████▉| 2469/2500 [2:01:38<02:53,  5.59s/it] 99%|█████████▉| 2470/2500 [2:01:44<02:48,  5.63s/it]                                                     {'loss': 1.9552, 'grad_norm': 8.308113276147123, 'learning_rate': 1.7763183985269883e-08, 'rewards/chosen': -0.7967125177383423, 'rewards/rejected': -3.1551501750946045, 'rewards/accuracies': 1.0, 'rewards/margins': 2.3584377765655518, 'logps/rejected': -7.887875556945801, 'logps/chosen': -1.991781234741211, 'logits/rejected': -1.3888500928878784, 'logits/chosen': -2.9472203254699707, 'nll_loss': 1.9726940393447876, 'log_odds_ratio': -0.07203836739063263, 'log_odds_chosen': 6.045777797698975, 'logps/chosen_prompt': -0.7761522531509399, 'logps/rejected_prompt': -0.9394097328186035, 'logits/chosen_prompt': -2.7055959701538086, 'logits/rejected_prompt': -2.682710886001587, 'logps/chosen_both': -1.9733655452728271, 'logps/rejected_both': -7.781175136566162, 'epoch': 1.98}
 99%|█████████▉| 2470/2500 [2:01:44<02:48,  5.63s/it] 99%|█████████▉| 2471/2500 [2:01:49<02:42,  5.62s/it] 99%|█████████▉| 2472/2500 [2:01:55<02:37,  5.61s/it] 99%|█████████▉| 2473/2500 [2:02:00<02:32,  5.63s/it] 99%|█████████▉| 2474/2500 [2:02:06<02:24,  5.56s/it] 99%|█████████▉| 2475/2500 [2:02:11<02:18,  5.55s/it] 99%|█████████▉| 2476/2500 [2:02:18<02:20,  5.84s/it] 99%|█████████▉| 2477/2500 [2:02:24<02:13,  5.82s/it] 99%|█████████▉| 2478/2500 [2:02:30<02:08,  5.84s/it] 99%|█████████▉| 2479/2500 [2:02:37<02:11,  6.28s/it] 99%|█████████▉| 2480/2500 [2:02:43<02:07,  6.36s/it]                                                     {'loss': 2.0519, 'grad_norm': 0.18457820599240046, 'learning_rate': 7.895267917501504e-09, 'rewards/chosen': -0.8267644643783569, 'rewards/rejected': -2.756608486175537, 'rewards/accuracies': 1.0, 'rewards/margins': 1.9298439025878906, 'logps/rejected': -6.8915205001831055, 'logps/chosen': -2.066911220550537, 'logits/rejected': -1.666332483291626, 'logits/chosen': -2.897627592086792, 'nll_loss': 2.0479252338409424, 'log_odds_ratio': -0.2084415853023529, 'log_odds_chosen': 4.926052093505859, 'logps/chosen_prompt': -0.7799464464187622, 'logps/rejected_prompt': -1.0256059169769287, 'logits/chosen_prompt': -2.690973997116089, 'logits/rejected_prompt': -2.66591215133667, 'logps/chosen_both': -2.049546718597412, 'logps/rejected_both': -6.804708957672119, 'epoch': 1.98}
 99%|█████████▉| 2480/2500 [2:02:43<02:07,  6.36s/it] 99%|█████████▉| 2481/2500 [2:02:49<01:57,  6.21s/it] 99%|█████████▉| 2482/2500 [2:02:55<01:48,  6.00s/it] 99%|█████████▉| 2483/2500 [2:03:00<01:40,  5.91s/it] 99%|█████████▉| 2484/2500 [2:03:07<01:35,  5.98s/it] 99%|█████████▉| 2485/2500 [2:03:12<01:28,  5.90s/it] 99%|█████████▉| 2486/2500 [2:03:18<01:22,  5.86s/it] 99%|█████████▉| 2487/2500 [2:03:24<01:16,  5.86s/it]100%|█████████▉| 2488/2500 [2:03:30<01:09,  5.80s/it]100%|█████████▉| 2489/2500 [2:03:36<01:04,  5.84s/it]100%|█████████▉| 2490/2500 [2:03:41<00:57,  5.73s/it]                                                     {'loss': 2.106, 'grad_norm': 1.0608578985196984, 'learning_rate': 1.973894904597207e-09, 'rewards/chosen': -0.9016851186752319, 'rewards/rejected': -3.310760498046875, 'rewards/accuracies': 1.0, 'rewards/margins': 2.4090752601623535, 'logps/rejected': -8.276901245117188, 'logps/chosen': -2.2542128562927246, 'logits/rejected': -1.2952916622161865, 'logits/chosen': -2.887951135635376, 'nll_loss': 2.2340729236602783, 'log_odds_ratio': -0.07078351080417633, 'log_odds_chosen': 6.140549659729004, 'logps/chosen_prompt': -0.8237534761428833, 'logps/rejected_prompt': -1.0140676498413086, 'logits/chosen_prompt': -2.6822524070739746, 'logits/rejected_prompt': -2.67390775680542, 'logps/chosen_both': -2.235067844390869, 'logps/rejected_both': -8.170358657836914, 'epoch': 1.99}
100%|█████████▉| 2490/2500 [2:03:41<00:57,  5.73s/it]100%|█████████▉| 2491/2500 [2:03:48<00:53,  5.98s/it]100%|█████████▉| 2492/2500 [2:03:53<00:46,  5.80s/it]100%|█████████▉| 2493/2500 [2:03:58<00:39,  5.67s/it]100%|█████████▉| 2494/2500 [2:04:04<00:34,  5.70s/it]100%|█████████▉| 2495/2500 [2:04:10<00:28,  5.64s/it]100%|█████████▉| 2496/2500 [2:04:16<00:23,  5.78s/it]100%|█████████▉| 2497/2500 [2:04:21<00:17,  5.70s/it]100%|█████████▉| 2498/2500 [2:04:26<00:11,  5.57s/it]100%|█████████▉| 2499/2500 [2:04:32<00:05,  5.50s/it]100%|██████████| 2500/2500 [2:04:37<00:00,  5.48s/it]                                                     {'loss': 2.0629, 'grad_norm': 11.0753861738894, 'learning_rate': 0.0, 'rewards/chosen': -0.7603691816329956, 'rewards/rejected': -3.4739468097686768, 'rewards/accuracies': 1.0, 'rewards/margins': 2.7135775089263916, 'logps/rejected': -8.684867858886719, 'logps/chosen': -1.9009230136871338, 'logits/rejected': -1.2105084657669067, 'logits/chosen': -2.9673712253570557, 'nll_loss': 1.8840863704681396, 'log_odds_ratio': -0.0021641450002789497, 'log_odds_chosen': 6.951698303222656, 'logps/chosen_prompt': -0.8989127278327942, 'logps/rejected_prompt': -1.0075560808181763, 'logits/chosen_prompt': -2.6878581047058105, 'logits/rejected_prompt': -2.65846848487854, 'logps/chosen_both': -1.8840863704681396, 'logps/rejected_both': -8.555959701538086, 'epoch': 2.0}
100%|██████████| 2500/2500 [2:04:37<00:00,  5.48s/it][INFO|trainer.py:3410] 2024-06-02 20:48:13,142 >> Saving model checkpoint to /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|configuration_utils.py:733] 2024-06-02 20:48:13,349 >> loading configuration file config.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/config.json
[INFO|configuration_utils.py:796] 2024-06-02 20:48:13,350 >> Model config MistralConfig {
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.1",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2513] 2024-06-02 20:48:13,547 >> tokenizer config file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-06-02 20:48:13,553 >> Special tokens file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500/special_tokens_map.json
[2024-06-02 20:48:13,898] [INFO] [logging.py:96:log_dist] [Rank 0] [Torch] Checkpoint global_step2500 is about to be saved!
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
[2024-06-02 20:48:13,933] [INFO] [logging.py:96:log_dist] [Rank 0] Saving model checkpoint: /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt
[2024-06-02 20:48:13,933] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt...
[2024-06-02 20:48:13,962] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500/global_step2500/zero_pp_rank_0_mp_rank_00_model_states.pt.
[2024-06-02 20:48:13,968] [INFO] [torch_checkpoint_engine.py:21:save] [Torch] Saving /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt...
[2024-06-02 20:48:14,237] [INFO] [torch_checkpoint_engine.py:23:save] [Torch] Saved /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt.
[2024-06-02 20:48:14,263] [INFO] [engine.py:3393:_save_zero_checkpoint] zero checkpoint saved /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/checkpoint-2500/global_step2500/bf16_zero_pp_rank_0_mp_rank_00_optim_states.pt
[2024-06-02 20:48:14,291] [INFO] [torch_checkpoint_engine.py:33:commit] [Torch] Checkpoint global_step2500 is ready now!
[INFO|tokenization_utils_base.py:2513] 2024-06-02 20:48:14,638 >> tokenizer config file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-06-02 20:48:14,642 >> Special tokens file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/special_tokens_map.json
[INFO|trainer.py:2329] 2024-06-02 20:48:14,686 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                     {'train_runtime': 7489.3414, 'train_samples_per_second': 2.67, 'train_steps_per_second': 0.334, 'train_loss': 1.0193936111450195, 'epoch': 2.0}
100%|██████████| 2500/2500 [2:04:47<00:00,  5.48s/it]100%|██████████| 2500/2500 [2:04:47<00:00,  2.99s/it]
[INFO|trainer.py:4170] 2024-06-02 20:48:14,690 >> Waiting for the current checkpoint push to be finished, this might take a couple of minutes.
***** train metrics *****
  epoch                    =        2.0
  total_flos               =        0GF
  train_loss               =     1.0194
  train_runtime            = 2:04:49.34
  train_samples            =      10000
  train_samples_per_second =       2.67
  train_steps_per_second   =      0.334
2024-06-02 20:48:26 - INFO - __main__ - *** Training complete ***
2024-06-02 20:48:26 - INFO - __main__ - *** Save model ***
[INFO|trainer.py:3410] 2024-06-02 20:48:34,558 >> Saving model checkpoint to /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr
/home/ctpham_umass_edu/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[INFO|configuration_utils.py:733] 2024-06-02 20:48:34,638 >> loading configuration file config.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/config.json
[INFO|configuration_utils.py:796] 2024-06-02 20:48:34,638 >> Model config MistralConfig {
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.1",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2513] 2024-06-02 20:48:34,882 >> tokenizer config file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-06-02 20:48:34,886 >> Special tokens file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/special_tokens_map.json
[INFO|trainer.py:3410] 2024-06-02 20:48:42,962 >> Saving model checkpoint to /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr
[INFO|configuration_utils.py:733] 2024-06-02 20:48:43,035 >> loading configuration file config.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/config.json
[INFO|configuration_utils.py:796] 2024-06-02 20:48:43,036 >> Model config MistralConfig {
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.1",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2513] 2024-06-02 20:48:43,200 >> tokenizer config file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-06-02 20:48:43,205 >> Special tokens file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/special_tokens_map.json
2024-06-02 20:48:44 - INFO - __main__ - Model saved to /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr
[INFO|modelcard.py:450] 2024-06-02 20:48:44,106 >> Dropping the following result as it does not have all the necessary fields:
{'dataset': {'name': 'chtmp223/suri', 'type': 'chtmp223/suri'}}
[INFO|configuration_utils.py:472] 2024-06-02 20:48:44,121 >> Configuration saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/config.json
2024-06-02 20:48:44 - INFO - __main__ - Pushing to hub...
[INFO|trainer.py:3410] 2024-06-02 20:48:55,167 >> Saving model checkpoint to /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr
[INFO|configuration_utils.py:733] 2024-06-02 20:48:55,242 >> loading configuration file config.json from cache at /project/pi_miyyer_umass_edu/ctpham/.cache/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873/config.json
[INFO|configuration_utils.py:796] 2024-06-02 20:48:55,243 >> Model config MistralConfig {
  "architectures": [
    "MistralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mistral",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.41.1",
  "use_cache": true,
  "vocab_size": 32000
}

[INFO|tokenization_utils_base.py:2513] 2024-06-02 20:48:55,670 >> tokenizer config file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/tokenizer_config.json
[INFO|tokenization_utils_base.py:2522] 2024-06-02 20:48:55,673 >> Special tokens file saved in /scratch/workspace/ctpham_umass_edu-ft/orpo-lora-curr/special_tokens_map.json
[INFO|modelcard.py:450] 2024-06-02 20:48:56,192 >> Dropping the following result as it does not have all the necessary fields:
{'dataset': {'name': 'chtmp223/suri', 'type': 'chtmp223/suri'}}
2024-06-02 20:48:56 - INFO - __main__ - *** Training complete! ***
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.046 MB uploadedwandb: / 0.047 MB of 0.047 MB uploadedwandb: 
wandb: Run history:
wandb:                  train/epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███
wandb:              train/grad_norm ▁▁▁▇▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▅▁█▇▁▅▁▇▁▁▁
wandb:          train/learning_rate ██▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb:        train/log_odds_chosen ▂▂▄▃▄▃▄▄▁▃▅▅▅▅▃▅▆▁▄▅▆█▇▇▆▆▇▄▅▅▆▄█▅▇▅▆▃▅▆
wandb:         train/log_odds_ratio ▇▆▇███▇▇▅▇▇██▇▆▇█▅▇▇████▇██▇▇▇▇▁█▆█▇▇▆▇▇
wandb:          train/logits/chosen ▃▁▃▄▁▅▁▂▄▃▂▃▂▄▂▄▂▆▂▅▄▃▃▂▃▄▃▄▅▃▃█▂▂▅▃▁▅▁▅
wandb:   train/logits/chosen_prompt ▃▅▆▂▁▃▄▄▄▆▆▅▇▆▄▇▆▆▅▇▅▆▆▇▇▇▇▇▇█▇▇█▇▇▇▆█▆▇
wandb:        train/logits/rejected ▁▁▃▂▂▂▃▃▁▃▄▄▅▅▃▅▆▂▄▅▆▇▆▇▆▇▇▅▆▆▇▅█▅▇▅▆▅▅▇
wandb: train/logits/rejected_prompt ▃▅▆▂▁▃▄▄▃▅▅▄▆▇▅▇▇▆▅▆▅▆▇▆▆▇▇▇▇▇▇▇█▆▇▆▆▇▆▆
wandb:           train/logps/chosen ▆▇▇▂▇▅▇▆▅▄█▇▆▆▆▅▄▅▆▅▆▇▆▆▇▆▅▆▆▆▆▁▆▇▇▆▇▅▇▃
wandb:      train/logps/chosen_both ▆▇▇▂▇▅▇▆▅▄█▇▆▆▆▅▄▅▆▅▆▇▆▆▇▆▅▆▆▆▆▁▆▇▇▆▇▅▇▃
wandb:    train/logps/chosen_prompt ▅▅▄▄▄▆▅▃▄▂▇▆▅▆▅▄▄█▆▄█▆▄▅▁▅▄▅▄▆▇▆▂▄▄▆▆▅▃▅
wandb:         train/logps/rejected ▇▇▅▅▅▆▅▆█▆▅▅▄▄▆▃▃█▅▄▃▁▂▂▃▃▂▅▄▄▃▅▁▅▂▄▃▆▄▃
wandb:    train/logps/rejected_both ▇▇▅▅▅▆▅▆█▆▅▅▄▄▆▃▃█▅▄▃▁▂▂▃▃▂▅▄▄▃▅▁▅▂▄▄▆▄▃
wandb:  train/logps/rejected_prompt ▃▅▃▃▄▅▅▅▃▁▄▆▄▄▄▃▁█▆▃▅▃▃▃▁▃▃▆▅▅▄▄▂▆▂▅▃▅▂▄
wandb:                   train/loss ▄▁▅▃▂▄▄▂▃▅▁▂▃▆▃▄▇▃▂█▁▃▃▃▃▄▂▆▁▅▃▅▅▂▆▂▁▃▃▅
wandb:               train/nll_loss ▃▂▂▇▂▄▂▃▄▅▁▂▃▃▃▄▅▄▃▄▃▂▃▃▂▃▄▃▃▃▃█▃▂▂▃▂▄▂▆
wandb:     train/rewards/accuracies ██▄██████████████▄███████████▄▄▁████▄███
wandb:         train/rewards/chosen ▆▇▇▂▇▅▇▆▅▄█▇▆▆▆▅▄▅▆▅▆▇▆▆▇▆▅▆▆▆▆▁▆▇▇▆▇▅▇▃
wandb:        train/rewards/margins ▂▂▄▃▄▃▄▄▁▃▄▅▅▅▃▅▆▁▄▅▆█▇▇▆▆▇▄▅▅▇▄█▅▇▅▆▃▅▆
wandb:       train/rewards/rejected ▇▇▅▅▅▆▅▆█▆▅▅▄▄▆▃▃█▅▄▃▁▂▂▃▃▂▅▄▄▃▅▁▅▂▄▃▆▄▃
wandb: 
wandb: Run summary:
wandb:                   total_flos 0.0
wandb:                  train/epoch 2.0
wandb:            train/global_step 2500
wandb:              train/grad_norm 11.07539
wandb:          train/learning_rate 0.0
wandb:        train/log_odds_chosen 6.9517
wandb:         train/log_odds_ratio -0.00216
wandb:          train/logits/chosen -2.96737
wandb:   train/logits/chosen_prompt -2.68786
wandb:        train/logits/rejected -1.21051
wandb: train/logits/rejected_prompt -2.65847
wandb:           train/logps/chosen -1.90092
wandb:      train/logps/chosen_both -1.88409
wandb:    train/logps/chosen_prompt -0.89891
wandb:         train/logps/rejected -8.68487
wandb:    train/logps/rejected_both -8.55596
wandb:  train/logps/rejected_prompt -1.00756
wandb:                   train/loss 2.0629
wandb:               train/nll_loss 1.88409
wandb:     train/rewards/accuracies 1.0
wandb:         train/rewards/chosen -0.76037
wandb:        train/rewards/margins 2.71358
wandb:       train/rewards/rejected -3.47395
wandb:                   train_loss 1.01939
wandb:                train_runtime 7489.3414
wandb:     train_samples_per_second 2.67
wandb:       train_steps_per_second 0.334
wandb: 
wandb: 🚀 View run orpo-lora-curr at: https://wandb.ai/chtmp223/huggingface/runs/aaq3gynb
wandb: ⭐️ View project at: https://wandb.ai/chtmp223/huggingface
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240602_184326-aaq3gynb/logs
